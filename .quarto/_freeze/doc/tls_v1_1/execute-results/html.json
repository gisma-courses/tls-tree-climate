{
  "hash": "9646ceb2cca5931aae11e51189efa0a1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants\"\nauthor: \"Chris Reudenbach\"\ndate: \"2025-07-16\"\nformat:\n  html:\n    self-contained: true\n    toc: true\n    number-sections: false\n    math: mathjax\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n\n\n\n\n::: {layout-ncol=\"2\"}\n![Tree No. 8 original not projected TLS Data](tls_tree8.gif){width=\"400\"}\n\n![Tree No. 8 in Envimet 3D Plant representation](envimet08tree.gif){width=\"580\"}\n::: \n\n\n---\n\n# Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.\n\n## Background and Method\n\nThis section explains the theoretical principles of leaf area density (LAD) and describes how it can be determined using terrestrial laser scanning (TLS). Leaf area density is an important parameter in environmental modeling, for example for radiation balance and microclimate simulations. It indicates the leaf area per volume (m²/m³) and is therefore a decisive factor for microclimate simulations, radiation models, and energy flows in vegetation stands.\n\n| **Approach Type** | **Name / Description** | **Nature** |\n|-------------------|------------------------------------|------------------|\n| Pulse-count based | Simple linear normalization of return counts or voxel hits | Empirical, direct |\n| **Linear normalization** | Straightforward normalization of pulse counts by voxel volume or max LAD | Empirical, basic |\n| Pulse-density normalization | Adjusts for occlusion and scan geometry | Semi-empirical |\n| Gap fraction models | Estimate LAD/LAI from canopy openness statistics | Semi-empirical |\n| **Beer–Lambert conversion conversion** | Uses exponential light attenuation to infer LAD | **Physically-based** |\n| Voxel-based inverse modeling | Optimizes 3D LAD to match observed light attenuation or reflectance | Physically-based |\n| Allometric / geometric reconstruction | Reconstructs crown volume and distributes LAD using QSM or shape fitting | Geometric, structural |\n\n-   **Linear normalization** is a practical baseline: simple, fast, and reproducible.\n-   **Beer–Lambert conversion** introduces realism via physical light attenuation.\n\nMore advanced models (e.g. voxel inverse or QSM-based) aim for higher biophysical fidelity at the cost of complexity.\n\nThe present analysis is based on TLS with a medium-range RIEGL scanner (e.g., VZ-400). This captures millions of 3D points of the vegetation structure with high angular resolution. The point cloud is divided into uniform voxels, from which the leaf area density is estimated in two ways.\n\n### Linear normalization (straightforwad)\n\n$$\n\\text{LAD}_i = \\frac{N_i}{N_{\\max}} \\cdot \\text{LAD}_{\\max}\n$$ - $N_i$: Number of laser points in voxel $i$\\\n- $N_{\\max}$: Maximum across all voxels\\\n- $\\text{LAD}_{\\max}$: Maximum LAD value from the literature (e.g., 5 m²/m³)\\\n\n### Beer–Lambert conversion\n\n$$\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n$$\n\n-   $k$: Extinction coefficient (typically 0.3–0.5)\n-   $\\Delta z$: vertical voxel height\n\n### Overall Workflow\n\nWhat happens in the script?\n\n| **Step** | **Description** | **Relevant Code** |\n|------------------|------------------------|------------------------------|\n| **1. Read & Filter LAS** | Load TLS data, optionally crop and clean it | `readLAS()` and `las = filter_poi(...)` |\n| **2. Voxel Grid Setup** | Set up 3D grid at defined `grain.size` | passed to `pixel_metrics(..., res = grain.size)` |\n| **3. Count Pulses** | Count returns in each voxel height bin | `pointsByZSlice()` function |\n| **4. Normalise Pulse Counts** | Divide by global max (relative LAD) | in `convert_to_LAD()`: `lad = (count / max) * LADmax` |\n| **5. Export Raster** | Convert metrics to raster stack | `terra::rast()` from `voxel_df` |\n| **6. Visualization** | Plot LAD profiles | see plotting section |\n| **7. Export to Plant3D** | Exports the LAD to ENVI-met | see export section |\n\n## Implemetation\n\nTo use this ENVI-met tree modeling workflow in R, follow these steps to load and initialize the project correctly:\n\nProject Setup: Loading the R Project and Environment\nDownload the project from next.hessenbox\nhttps://gds.hessen.de/INTERSHOP/web/WFS/HLBG-Geodaten-Site/de_DE/-/EUR/ViewDownloadcenter-Start\n##### Download and Unzip the Project Archive\n\n-  \n\n-   Unzip the folder to your desired location.\n\n-   The folder should contain at least:\n\n    -   An `*.Rproj` file (e.g. `envimet_tree_workflow.Rproj`)\n    -   A `data/` folder with input files like `tree_08.las`\n    -   One or more `R/` scripts\n\n##### Open the Project in RStudio\n\n-   Go to **File → Open Project**\n-   Select the `*.Rproj` file (e.g. `microclimate_TLS.Rproj`)\n-   This ensures that the project directory is treated as the root for all file paths.\n\n> The use of the `{here}` package depends on having a valid RStudio project. Without this, file paths may not resolve correctly.\n\n##### Data Input Parameters and Paths\n\n::: {.callout-tip appearance=\"minimal\"}\nThe input data set tree_08.las is a cleaned terrestrial laser scan of a single, isolated tree. All surrounding vegetation and ground points have been removed, so the file contains only the tree’s structure—trunk, branches, and foliage. Stored in standard LAS format, it provides high-resolution 3D point data suitable for voxelization, LAD calculation, or input into microclimate and radiative models. This detailed structural data is essential for generating true 3D tree entities in ENVI-met; without it, only simplified vegetation (SimplePlants) can be used.\n:::\n\nSet global parameters for the workflow, such as file paths, voxel resolution, and maximum LAD value for normalization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nlibrary(lidR)\nlibrary(sf)\nlibrary(here)\nlibrary(data.table)\n\nzmax <- 40  \ngrain.size <- 1  \nproject_root <- here::here()  \n\n# Choose LAD method: \"linear\" or \"beer\"\n# Beer–Lambert conversion Notes:\n# - Avoids log(0) and 1 by clipping near-extreme values\n# - Use when cumulative light absorption or occlusion is relevant\n# - Suitable if extinction coefficient is known or estimated from prior studies\nlad_method <- \"beer\"  # Set to \"linear\" or \"beer\"\n\n# Optional: extinction coefficient (used only for Beer–Lambert conversion)\nk_extinction <- 0.25\n\n\nlas_file <- file.path(project_root, \"data/TLS/tree_08.laz\")  \noutput_voxels <- file.path(project_root, \"data/TLS/LAD_voxDF.rds\")  \noutput_array <- file.path(project_root, \"data/TLS/lad_array_m2m3.rds\")  \noutput_profile_plot <- file.path(project_root, \"data/TLS/lad_vertical_profile.pdf\")  \n```\n:::\n\n\n\n### Voxelization of TLS data\n\nVoxelisation turns a 3D TLS point cloud into a grid of cubes (voxels), where each voxel holds structural information. The number of points per voxel is used to estimate Leaf Area Density (LAD), typically normalized relative to the voxel with the most returns.\n\n-   Each voxel = a 1×1×1 m³ cube\n-   Count the laser hits per voxel\n-   Normalize to maximum\n-   Multiply by a literature-based LAD_max (e.g. 5 m²/m³)\n\nThis gives a spatially distributed LAD profile suitable for further analysis or models like ENVI-met.\n\n::: {.callout-tip title=\"View Code\" appearance=\"minimal\" collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n\n las <- lidR::readLAS(las_file)  # Read the LAS/LAZ file (point cloud data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[===========================================>      ] 87% ETA: 0s     \n[===========================================>      ] 87% ETA: 0s     \n[===========================================>      ] 87% ETA: 0s     \n[===========================================>      ] 87% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 88% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[============================================>     ] 89% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 90% ETA: 0s     \n[=============================================>    ] 91% ETA: 0s     \n[=============================================>    ] 91% ETA: 0s     \n[=============================================>    ] 91% ETA: 0s     \n[=============================================>    ] 91% ETA: 0s     \n[=============================================>    ] 91% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 92% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[==============================================>   ] 93% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 94% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[===============================================>  ] 95% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 96% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[================================================> ] 97% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 98% ETA: 0s     \n[=================================================>] 99% ETA: 0s     \n[=================================================>] 99% ETA: 0s     \n[=================================================>] 99% ETA: 0s     \n[=================================================>] 99% ETA: 0s     \n[=================================================>] 99% ETA: 0s     \n                                                                                \n```\n\n\n:::\n\n```{.r .cell-code}\n  las@data$Z <- las@data$Z - min(las@data$Z, na.rm = TRUE)  \n  maxZ <- min(floor(max(las@data$Z, na.rm = TRUE)), zmax)  \n  las@data$Z[las@data$Z > maxZ] <- maxZ  \npointsByZSlice = function(Z, maxZ){\n  heightSlices = as.integer(Z) # Round down\n  zSlice = data.table::data.table(Z=Z, heightSlices=heightSlices) # Create a data.table (Z, slices))\n  sliceCount = stats::aggregate(list(V1=Z), list(heightSlices=heightSlices), length) # Count number of returns by slice\n  \n  ##############################################\n  # Add columns to equalize number of columns\n  ##############################################\n  colRange = 0:maxZ\n  addToList = setdiff(colRange, sliceCount$heightSlices)\n  n = length(addToList)\n  if (n > 0) {\n    bindDt = data.frame(heightSlices = addToList, V1=integer(n))\n    sliceCount = rbind(sliceCount, bindDt)\n    # Order by height\n    sliceCount = sliceCount[order(sliceCount$heightSlices),]\n  }\n  \n  colNames = as.character(sliceCount$heightSlices)\n  colNames[1] = \"ground_0_1m\"\n  colNames[-1] = paste0(\"pulses_\", colNames[-1], \"_\", sliceCount$heightSlices[-1]+1, \"m\")\n  metrics = list()\n  metrics[colNames] = sliceCount$V1\n  \n  return(metrics)\n  \n} #end function pointsByZSlice\n\n# --- Main function ---\npreprocess_voxels <- function(normlas, grain.size = 1, maxP =zmax, normalize = TRUE, as_raster = TRUE) {  \n  las <- normlas  \n  \n  # Filter height range\n  las <- filter_poi(las, Z >= 0 & Z <= maxP)  \n  if (lidR::is.empty(las)) return(NULL)\n  # Determine Z-slices\n  maxZ <- floor(max(las@data$Z))  \n  maxZ <- min(maxZ, maxP)  \n  \n  \n  # Compute voxel metrics\n  func <- formula(paste0(\"~pointsByZSlice(Z, \", maxZ, \")\"))  \n  voxels <- pixel_metrics(las, func, res = grain.size)  # Calculate metrics in each voxel (3D grid cell)\n  \n  # Optionally normalize values by voxel volume\n  if (normalize) {\n    vvol <- grain.size^3  \n    voxels <- voxels / vvol  \n  }\n  \n  # Return as both terra::SpatRaster and data.frame\n  result <- list()  \n  \n  if (as_raster) {\n    result$raster <- voxels  \n  }\n  \n  # Convert to data.frame\n  xy <- terra::xyFromCell(voxels, seq_len(ncell(voxels)))  \n  vals <- terra::values(voxels)  \n  df <- cbind(xy, vals)  \n  colnames(df)[1:2] <- c(\"X\", \"Y\")  \n  result$df <- df  \n  \n  return(result)\n}\n\n\n\n\nvox_out <- preprocess_voxels(las, grain.size = 1, maxP = zmax)  \n```\n:::\n\n\n:::\n\n#### Conversion to LAD (m²/m³)\n\nThe **conversion to LAD** (Leaf Area Density, in m²/m³) from TLS-based voxel pulse counts is done using a **relative normalization heuristic** which is adopted as a practical approximation in voxel-based canopy structure analysis using TLS (Terrestrial Laser Scanning) data.:\n\nFor each voxel layer (e.g. `pulses_2_3m`), the LAD is calculated as:\n\n$$\n\\text{LAD}_{\\text{voxel}} = \\left( \\frac{\\text{pulse count in voxel}}{\\text{maximum pulse count over all voxels}} \\right) \\times \\text{LAD}_{\\text{max}}\n$$\n\nWhere:\n\n-   `pulse count in voxel` = number of returns in this voxel layer (from TLS)\n-   `max_pulse` = the maximum pulse count found in *any* voxel (used for normalization)\n-   `LAD_max` = a fixed normalization constant (e.g. 5.0 m²/m³) chosen from literature or calibration\n\n::: {.callout-note title=\"Typical LADₘₐₓ Values by Species\" collapse=\"true\"}\n\n| Species / Structure Type             | LADₘₐₓ (m²/m³) | Source / Notes                                                 |\n| ------------------------------------ | -------------- | -------------------------------------------------------------- |\n| **Fagus sylvatica** (European beech) | 3.5–5.5        | Calders et al. (2015), Chen et al. (2018)                      |\n| **Quercus robur** (English oak)      | 3.0–6.0        | Hosoi & Omasa (2006), field studies with TLS voxelization      |\n| **Coniferous trees** (e.g. pine)     | 4.0–7.0        | Wilkes et al. (2017), higher LAD due to needle density         |\n| **Mixed broadleaf forest**           | 3.0–6.0        | Flynn et al. (2023), canopy averaged estimates                 |\n| **Shrubs / understorey**             | 1.5–3.0        | Chen et al. (2018),lower vertical structure density |\n| **Urban street trees**               | 2.0–4.0        | Simon et al. (2020), depending on pruning and species          |\n\n*LAD values refer to maximum expected per 1 m vertical voxel. Values depend on species, seasonality, and scanning conditions.*\n\n:::\n\n**What this means conceptually**\n\nYou're not measuring absolute LAD, but instead:\n\n-   Using the number of TLS returns per voxel as a proxy for leaf density\n-   Then normalization all voxels relatively to the most \"leaf-dense\" voxel\n-   The `LAD_max` defines what value the \"densest\" voxel should reach in terms of LAD\n\nThis is fast, simple, and works well when:\n\n-   You want relative structure across the canopy\n-   You don’t have absolute calibration (e.g. with destructive sampling or hemispheric photos)\n\n**Caveats and assumptions**\n\n-   This approach assumes the TLS beam returns are proportional to leaf area, which is a simplification\n-   It's sensitive to occlusion and TLS positioning\n-   The choice of `LAD_max` is crucial—common values from literature range from 3–7 m²/m³ for dense canopies\n\nThe LAD conversion in the following code is a **relative, normalized mapping** of TLS pulse counts to LAD values, normalized by the highest voxel return and normalized using a fixed `LAD_max`. This gives a plausible LAD field usable for analysis, visualization, or simulation input (e.g. for ENVI-met).\n\n::: {.callout-tip title=\"View Code\" appearance=\"minimal\" collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nconvert_matrix_to_df <- function(mat) {  \n  df <- as.data.frame(mat)  \n  colnames(df) <- attr(mat, \"dimnames\")[[2]]  \n  return(df)\n}\n\n# --- Preprocess LiDAR data into voxel metrics -------------------------------\nvox_out <- preprocess_voxels(las, grain.size = 1, maxP = zmax)  # Calculate vertical pulse metrics\nvox_df <- convert_matrix_to_df(vox_out$df)                      # Convert voxel array to data.frame\n\n#' Convert TLS voxel pulse data to LAD using Beer–Lambert conversion conversion with post-normalization\n#'\n#' @param df A data.frame with pulse columns (from TLS voxelization)\n#' @param grainsize Numeric, vertical voxel height (e.g., 1 m)\n#' @param k Extinction coefficient (default: 0.3)\n#' @param scale_factor Optional multiplicative scale factor (default: 1.2)\n#' @param lad_max Optional maximum LAD clamp (e.g. 2.5); set to NULL to disable\n#' @param lad_min Optional minimum LAD threshold (e.g. 0.05); set to NULL to disable\n#' @param keep_pulses Logical, whether to retain pulse columns (default: FALSE)\n#'\n#' @return Data.frame with LAD columns added\n#' @export\nconvert_to_LAD_beer <- function(df,\n                                grainsize = 1,\n                                k = 0.3,\n                                scale_factor = 1.2,\n                                lad_max = 2.5,\n                                lad_min = 0.05,\n                                keep_pulses = FALSE) {\n  df_lad <- df\n  pulse_cols <- grep(\"^pulses_\", names(df_lad), value = TRUE)\n  \n  for (col in pulse_cols) {\n    lad_col <- paste0(\"lad_\", sub(\"pulses_\", \"\", col))\n    p_rel <- df_lad[[col]] / max(df_lad[[col]], na.rm = TRUE)\n    \n    # Avoid log(0) and 1\n    p_rel[p_rel >= 1] <- 0.9999\n    p_rel[p_rel <= 0] <- 1e-5\n    \n    # Apply Beer–Lambert conversion\n    lad_vals <- -log(1 - p_rel) / (k * grainsize)\n    \n    # Apply normalization\n    lad_vals <- lad_vals * scale_factor\n    \n    # Clamp LAD values if needed\n    if (!is.null(lad_max)) {\n      lad_vals <- pmin(lad_vals, lad_max)\n    }\n    if (!is.null(lad_min)) {\n      lad_vals <- pmax(lad_vals, lad_min)\n    }\n    \n    df_lad[[lad_col]] <- lad_vals\n    \n    if (!keep_pulses) {\n      df_lad[[col]] <- NULL\n    }\n  }\n  \n  return(df_lad)\n}\n\n\n#' Convert TLS Pulse Counts to Leaf Area Density (LAD)\n#'\n#' Transforms vertically binned pulse counts (from voxelized TLS data) into Leaf Area Density (LAD, m²/m³)\n#' by normalizing pulse values to a specified LAD maximum.\n#'\n#' @param df A `data.frame` containing voxelized TLS pulse data. Must include columns starting with `\"pulses_\"`, \n#'           each representing pulse returns per vertical layer (e.g. `pulses_1_2m`, `pulses_2_3m`, ...).\n#' @param grainsize Numeric. The voxel edge length in meters (assumed cubic). Default is `1`.\n#' @param LADmax Numeric. The maximum LAD value in m²/m³ for relative normalization. Common values: `4.0`–`6.0`. Default is `5.0`.\n#' @param keep_pulses Logical. If `FALSE` (default), the original pulse columns are removed from the output. If `TRUE`, they are retained alongside the LAD columns.\n#'\n#' @return A modified `data.frame` with new LAD columns (`lad_1_2m`, `lad_2_3m`, ...) in m²/m³, normalized relatively to `LADmax`.\n#'\n#' @details\n#' - Each `pulses_*` column is linearly normalized by the overall maximum value across all vertical bins and locations.\n#' - The result is a relative LAD estimate, useful for ecological modeling, input to microclimate simulations (e.g., ENVI-met), or structural analysis.\n#' - Voxel volume is implicitly considered constant due to cubic assumption (via `grainsize`) but is not explicitly used here.\n#'\n#' @examples\n#' \\dontrun{\n#'   df_vox <- readRDS(\"TLS/voxel_metrics.rds\")\n#'   lad_df <- convert_to_LAD(df_vox, grainsize = 1, LADmax = 5)\n#'   head(names(lad_df))  # Should show lad_* columns\n#' }\n#'\n#' @export\nconvert_to_LAD <- function(df, grainsize = 1, LADmax = 5.0, keep_pulses = FALSE) {  \n  # df: Data frame mit voxelisierten TLS-Daten\n# grainsize: Voxelgröße in m (würfelförmig angenommen)\n# LADmax: maximaler LAD-Wert (Literaturbasiert, z. B. 5.0 m²/m³)\n  df_lad <- df  \n  pulse_cols <- grep(\"^pulses_\", names(df_lad), value = TRUE)  \n  \n  # Schichtanzahl = Anzahl Pulse-Spalten\n  n_layers <- length(pulse_cols)  \n  \n  # Optional: originales Maximum zur linearen Skalierung (relativ)\n  max_pulse <- max(df_lad[, pulse_cols], na.rm = TRUE)  \n  \n  # Umwandlung in LAD (m²/m³) – Skaliert auf LADmax oder absolut (siehe Kommentar)\n  for (col in pulse_cols) {\n    lad_col <- paste0(\"lad_\", sub(\"pulses_\", \"\", col))  \n    \n    # Hier wird RELATIV zu max_pulse skaliert → einfache Normalisierung\n    df_lad[[lad_col]] <- (df_lad[[col]] / max_pulse) * LADmax  \n    \n    # Optional: löschen der Pulse-Spalten\n    if (!keep_pulses) {\n      df_lad[[col]] <- NULL  \n    }\n  }\n  \n  return(df_lad)\n}\n\n\n\n# method selection\nif (lad_method == \"beer\") {\n  message(\"✔ Using Beer–Lambert conversion LAD conversion...\")\n  df_lad <- convert_to_LAD_beer(\n    vox_df,\n    grainsize = 1,\n    k = k_extinction,\n    scale_factor = 0.4,\n    lad_max = 2.5,\n    lad_min = 0.0\n  )\n} else if (lad_method == \"linear\") {\n  message(\"Using linear LAD conversion...\")\n  df_lad <- convert_to_LAD(\n    vox_df,\n    grainsize = 1,\n    LADmax = 5.0\n  )\n} else {\n  stop(\"Unknown LAD conversion method: choose 'linear' or 'beer'\")\n}\n```\n:::\n\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDT::datatable(head(df_lad, 5))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-3f45b47de34a5f13c5d4\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3f45b47de34a5f13c5d4\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\"],[51.5,52.5,53.5,54.5,55.5],[-81.5,-81.5,-81.5,-81.5,-81.5],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null],[null,null,null,null,null]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>X<\\/th>\\n      <th>Y<\\/th>\\n      <th>ground_0_1m<\\/th>\\n      <th>lad_1_2m<\\/th>\\n      <th>lad_2_3m<\\/th>\\n      <th>lad_3_4m<\\/th>\\n      <th>lad_4_5m<\\/th>\\n      <th>lad_5_6m<\\/th>\\n      <th>lad_6_7m<\\/th>\\n      <th>lad_7_8m<\\/th>\\n      <th>lad_8_9m<\\/th>\\n      <th>lad_9_10m<\\/th>\\n      <th>lad_10_11m<\\/th>\\n      <th>lad_11_12m<\\/th>\\n      <th>lad_12_13m<\\/th>\\n      <th>lad_13_14m<\\/th>\\n      <th>lad_14_15m<\\/th>\\n      <th>lad_15_16m<\\/th>\\n      <th>lad_16_17m<\\/th>\\n      <th>lad_17_18m<\\/th>\\n      <th>lad_18_19m<\\/th>\\n      <th>lad_19_20m<\\/th>\\n      <th>lad_20_21m<\\/th>\\n      <th>lad_21_22m<\\/th>\\n      <th>lad_22_23m<\\/th>\\n      <th>lad_23_24m<\\/th>\\n      <th>lad_24_25m<\\/th>\\n      <th>lad_25_26m<\\/th>\\n      <th>lad_26_27m<\\/th>\\n      <th>lad_27_28m<\\/th>\\n      <th>lad_28_29m<\\/th>\\n      <th>lad_29_30m<\\/th>\\n      <th>lad_30_31m<\\/th>\\n      <th>lad_31_32m<\\/th>\\n      <th>lad_32_33m<\\/th>\\n      <th>lad_33_34m<\\/th>\\n      <th>lad_34_35m<\\/th>\\n      <th>lad_35_36m<\\/th>\\n      <th>lad_36_37m<\\/th>\\n      <th>lad_37_38m<\\/th>\\n      <th>lad_38_39m<\\/th>\\n      <th>lad_39_40m<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"X\",\"targets\":1},{\"name\":\"Y\",\"targets\":2},{\"name\":\"ground_0_1m\",\"targets\":3},{\"name\":\"lad_1_2m\",\"targets\":4},{\"name\":\"lad_2_3m\",\"targets\":5},{\"name\":\"lad_3_4m\",\"targets\":6},{\"name\":\"lad_4_5m\",\"targets\":7},{\"name\":\"lad_5_6m\",\"targets\":8},{\"name\":\"lad_6_7m\",\"targets\":9},{\"name\":\"lad_7_8m\",\"targets\":10},{\"name\":\"lad_8_9m\",\"targets\":11},{\"name\":\"lad_9_10m\",\"targets\":12},{\"name\":\"lad_10_11m\",\"targets\":13},{\"name\":\"lad_11_12m\",\"targets\":14},{\"name\":\"lad_12_13m\",\"targets\":15},{\"name\":\"lad_13_14m\",\"targets\":16},{\"name\":\"lad_14_15m\",\"targets\":17},{\"name\":\"lad_15_16m\",\"targets\":18},{\"name\":\"lad_16_17m\",\"targets\":19},{\"name\":\"lad_17_18m\",\"targets\":20},{\"name\":\"lad_18_19m\",\"targets\":21},{\"name\":\"lad_19_20m\",\"targets\":22},{\"name\":\"lad_20_21m\",\"targets\":23},{\"name\":\"lad_21_22m\",\"targets\":24},{\"name\":\"lad_22_23m\",\"targets\":25},{\"name\":\"lad_23_24m\",\"targets\":26},{\"name\":\"lad_24_25m\",\"targets\":27},{\"name\":\"lad_25_26m\",\"targets\":28},{\"name\":\"lad_26_27m\",\"targets\":29},{\"name\":\"lad_27_28m\",\"targets\":30},{\"name\":\"lad_28_29m\",\"targets\":31},{\"name\":\"lad_29_30m\",\"targets\":32},{\"name\":\"lad_30_31m\",\"targets\":33},{\"name\":\"lad_31_32m\",\"targets\":34},{\"name\":\"lad_32_33m\",\"targets\":35},{\"name\":\"lad_33_34m\",\"targets\":36},{\"name\":\"lad_34_35m\",\"targets\":37},{\"name\":\"lad_35_36m\",\"targets\":38},{\"name\":\"lad_36_37m\",\"targets\":39},{\"name\":\"lad_37_38m\",\"targets\":40},{\"name\":\"lad_38_39m\",\"targets\":41},{\"name\":\"lad_39_40m\",\"targets\":42}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n#### Raster Stack Representation of 3D Vegetation (Voxel-Based)\n\nWe represent 3D vegetation using a **voxel-based raster stack**:\n\n-   Space is divided into cubic voxels (e.g. 1 × 1 × 1 m).\n-   Each raster layer represents a height slice (e.g. 0–1 m, 1–2 m, …).\n-   Voxels store values like pulse counts or *Leaf Area Density (LAD)*.\n\nThis 2D stack structure enables:\n\n-   Vertical profiling of vegetation per XY column.\n-   Layer-wise analysis (e.g. median, entropy).\n-   Integration with raster data like topography or irradiance.\n-   Use in raster-based ecological and microclimate models.\n\nIt supports both analysis and visualization of vertical structure with standard geospatial tools.\n\nENVI-met supports custom vegetation input via the SimplePlant method, which requires a vertical LAD profile per grid column. A raster stack derived from TLS data provides exactly this: each layer represents LAD in a specific height slice, and each XY cell corresponds to one vertical profile. This structure can be exported as CSV, ASCII rasters, or custom profile files.\n\nFor 3D vegetation parameterization in ENVI-met 5.8+, the raster stack enables preprocessing of spatially explicit LAD or LAI profiles, even if some reformatting is needed.\n\nThe raster stack also supports canopy clustering and prototyping. It allows classification of structural types, simplification of complex vegetation, and the creation of representative profiles for simulation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n# In SpatRasterStack umwandeln\nxy <- df_lad[, c(\"X\", \"Y\")]  \nlad_vals <- df_lad[, grep(\"^lad_\", names(df_lad), value = TRUE)]  \n\nlad_raster <- rast(cbind(xy, lad_vals), type = \"xyz\")  \nplot(lad_raster)\n```\n\n::: {.cell-output-display}\n![](tls_v1_1_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nIn a more 3D version it looks like below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# #| eval: false\n# #| include: false\n# library(terra)\n# library(rgl)\n# \n# # Threshold value for LAD\n# threshold <- 0.1 # change as needed\n# \n# # Step 1: Convert raster to voxel data frame\n# rast_cube <- lad_raster  # your raster stack\n# voxel_df <- as.data.frame(rast_cube, xy = TRUE, na.rm = TRUE)\n# names(voxel_df) <- c(\"x\", \"y\", paste0(\"z\", seq_len(nlyr(rast_cube))))\n# \n# # Step 2: Reshape to long format\n# voxel_long <- reshape(\n#   voxel_df,\n#   direction = \"long\",\n#   varying = paste0(\"z\", seq_len(nlyr(rast_cube))),\n#   v.names = \"val\",\n#   timevar = \"z\",\n#   times = seq_len(nlyr(rast_cube))\n# )\n# \n# # Step 3: Clean up and filter by threshold\n# voxel_long <- voxel_long[!is.na(voxel_long$val) & voxel_long$val > threshold, ]\n# voxel_long$z <- as.numeric(voxel_long$z)\n# \n# # Step 4: Normalize colors\n# colors <- terrain.colors(100)[cut(voxel_long$val, breaks = 100)]\n# \n# # Step 5: Draw voxel cubes\n# open3d(useNULL = TRUE)\n# for (i in seq_len(nrow(voxel_long))) {\n#   shade3d(\n#     translate3d(cube3d(scale = 1), \n#                 voxel_long$x[i], \n#                 voxel_long$y[i], \n#                 voxel_long$z[i]),\n#     color = colors[i],\n#     alpha = 0.8\n#   )\n# }\n# \n# # Step 6: Render in browser\n# # Determine the bounds of your voxel space\n# xlim <- range(voxel_long$x)\n# ylim <- range(voxel_long$y)\n# zlim <- range(voxel_long$z)\n# \n# # Draw bounding box\n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[1], zlim[1])\n# ), col = \"black\", lwd = 2)\n# \n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[1], zlim[2])\n# ), col = \"black\", lwd = 2)\n# \n# for (i in 1:4) {\n#   lines3d(\n#     rbind(\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[1]),\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[2])\n#     ), col = \"black\", lwd = 2\n#   )\n# }\n# \n# # Optional: Add coordinate axes\n# axes3d(edges = c(\"x--\", \"y--\", \"z--\"), col = \"gray40\")\n# title3d(xlab = \"X\", ylab = \"Y\", zlab = \"Z\")\n# widget <- rglwidget()\n# htmlwidgets::saveWidget(widget, \"tree_voxel_viewer.html\", selfcontained = TRUE)\n```\n:::\n\n\n\n#### Visualization\n\n##### **LAD Profile Visualizations from TLS Data**\n\n\n\nThe `plot_lad_profiles()` function visualizes vertical *leaf area density* (LAD) profiles derived from voxelized TLS (terrestrial laser scanning) data. LAD represents leaf surface area per unit volume (m²/m³). The function provides three main plot styles:\n\n\n##### **1. XY Matrix Plot (`plotstyle = \"each_median\"`)**\n\n* Displays a grid of **mini-profiles**, each representing a 0.5 × 0.5 m (x/y) ground column.\n* Within each cell, a **normalized vertical LAD profile** is plotted:\n\n  * **Y-axis** (height) is normalized from 0 to 1 per column.\n  * **X-axis** shows LAD values normalized relative to the global LAD maximum.\n* Useful for comparing structural patterns across space.\n\n\n\n##### **2. Overall Median Profile (`plotstyle = \"all_median\"`)**\n\n* Aggregates LAD values across all (x/y) locations by height bin.\n* Produces a **typical vertical profile** using the median and smoothed with a moving average.\n* **Height is shown in absolute units** (e.g. meters).\n* Captures the dominant vertical canopy structure.\n\n\n\n##### **3. Single Profile (`plotstyle = \"single_profile\"`)**\n\n* Extracts and plots the LAD profile at a **specific (x, y) coordinate**.\n* Both **LAD and height are shown in absolute units**.\n* Plots the true vertical structure at one location.\n\nThe matrix plot shows multiple vertical LAD profiles arranged in a grid, with each small plot corresponding to a specific spatial location. This allows the vertical vegetation structure to be viewed in relation to its position on the ground. To make the individual profiles comparable, both height and LAD values are normalized within the plot. A reference profile on the side shows the overall median LAD distribution by height, which helps interpret the scale and shape of the individual profiles.\n\n::: {.callout-tip title=\"View Code\" appearance=\"minimal\" collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Reshape LAD data to long format ----------------------------------------\n\nlad_df <- as.data.frame(lad_raster, xy = TRUE, na.rm = TRUE)     # Convert raster to data.frame\n\n# 1. Extract LAD columns and XY coordinates\npulse_cols <- grep(\"^lad_\", names(lad_df), value = TRUE)\nxy_cols <- c(\"x\", \"y\")  # Adjust to \"X\", \"Y\" if needed\n\n# 2. Reshape to long format (one row per LAD layer)\nlad_df <- reshape(\n  data = lad_df[, c(xy_cols, pulse_cols)],\n  varying = pulse_cols,\n  v.names = \"LAD\",\n  timevar = \"layer\",\n  times = pulse_cols,\n  direction = \"long\"\n)\n\n# 3. Extract z-layer information from column names\nlad_df$z_low  <- as.numeric(sub(\"lad_(\\\\d+)_.*\", \"\\\\1\", lad_df$layer))  \nlad_df$z_high <- as.numeric(sub(\"lad_\\\\d+_(\\\\d+)m\", \"\\\\1\", lad_df$layer))  \n\n# 4. Compute mid-point height of each voxel layer\nlad_df$Height <- (lad_df$z_low + lad_df$z_high) / 2  \n\n# 5. Round to whole meters to create height classes\nlad_df$Height_bin <- round(lad_df$Height)  \n\n# --- Aggregate median LAD per 0.5 × 0.5 m column ----------------------------\nsetDT(lad_df)  # Use data.table for efficient aggregation\n\nlad_by_column <- lad_df[  \n  , .(LAD_median = median(LAD, na.rm = TRUE)), \n  by = .(x, y, Height_bin)\n]\n\n# Convert back to regular data.frame\nlad_df <- as.data.frame(lad_by_column)\n\nplot_lad_profiles <- function(lad_df, plotstyle = c(\"each_median\", \"all_median\", \"single_profile\"),  \n                              single_coords = c(NA, NA)) {\n  plotstyle <- match.arg(plotstyle)  \n  \n  # Combine x and y coordinates into a unique column ID\n  lad_df$col_id <- paste(lad_df$x, lad_df$y, sep = \"_\")  \n  x_levels <- sort(unique(lad_df$x))  \n  y_levels <- sort(unique(lad_df$y))  \n  # Convert x/y coordinates to factor variables for matrix layout\n  lad_df$x_f <- factor(lad_df$x, levels = x_levels)  \n  lad_df$y_f <- factor(lad_df$y, levels = y_levels)  \n  n_x <- length(x_levels)  \n  n_y <- length(y_levels)  \n  \n  # Determine the maximum LAD value for relative normalization\n  lad_max <- max(lad_df$LAD_median, na.rm = TRUE)  \n  height_range <- range(lad_df$Height_bin, na.rm = TRUE)  \n  dx <- 0.8  \n  dy <- 0.8  \n  \n  par(mar = c(5, 5, 4, 5), xpd = TRUE)\n  \n \n\n  \n  # Differentiate by plot type: all profiles, overall profile, or single profile\n  if (plotstyle == \"each_median\") {\n # Load PNG legend\nlegend_img <- png::readPNG(\"output.png\")\n\n# Define aspect-preserving image placement\nimg_height_units <- 20\nimg_width_units <- img_height_units * dim(legend_img)[2] / dim(legend_img)[1]  # preserve ratio\n\n# Define position\nimg_x_left <- n_x + 1.5\nimg_x_right <- img_x_left + img_width_units\nimg_y_bottom <- 0\nimg_y_top <- img_y_bottom + img_height_units\n\n# Begin plot\nplot(NA, xlim = c(1, n_x + img_width_units + 4), ylim = c(1, n_y),\n     type = \"n\", axes = FALSE, xlab = \"\", ylab = \"\",\n     main = \"Vertical LAD Profiles in XY Matrix\", asp = 1.2)\n\n\n# Draw all LAD profiles\nfor (i in seq_along(x_levels)) {\n  for (j in seq_along(y_levels)) {\n    profile <- subset(lad_df, x == x_levels[i] & y == y_levels[j])\n    if (nrow(profile) == 0) next\n    lad_scaled <- profile$LAD_median / lad_max\n    height_scaled <- (profile$Height_bin - min(height_range)) / diff(height_range)\n    lines(x = lad_scaled * dx + i,\n          y = height_scaled * dy + j,\n          col = \"darkgreen\", lwd = 1)\n  }\n}\n\n# Axis labels for ground position\naxis(1, at = 1:n_x, labels = round(x_levels, 1), las = 2)\naxis(2, at = 1:n_y, labels = round(y_levels, 1), las = 2)\n\n# Add the image\nrasterImage(legend_img,\n            xleft = img_x_left,\n            xright = img_x_right,\n            ybottom = img_y_bottom,\n            ytop = img_y_top)\n\n    \n  } else if (plotstyle == \"all_median\") {\n    unique_heights <- sort(unique(lad_df$Height_bin))  \n    lad_median <- numeric(length(unique_heights))  \n    for (i in seq_along(unique_heights)) {\n      h <- unique_heights[i]  \n      lad_median[i] <- median(lad_df$LAD[lad_df$Height_bin == h], na.rm = TRUE)  \n    }\n    lad_smooth <- stats::filter(lad_median, rep(1/3, 3), sides = 2)  \n    \n    plot(\n      lad_smooth, unique_heights,\n      type = \"l\",\n      col = \"darkgreen\",\n      lwd = 2,\n      xlab = \"Leaf Area Density (m²/m³)\",\n      ylab = \"Height (m)\",\n      main = \"Vertical LAD Profile (smoothed)\",\n      xlim = c(0, max(lad_smooth, na.rm = TRUE)),\n      ylim = range(unique_heights)\n    )\n    \n    text(\n      x = as.numeric(lad_smooth),\n      y = unique_heights,\n      labels = round(as.numeric(lad_smooth), 1),\n      pos = 4,\n      cex = 0.7,\n      col = \"black\"\n    )\n    grid()\n    \n    \n  } else if (plotstyle == \"single_profile\") {\n    x_target <- single_coords[1]  \n    y_target <- single_coords[2]  \n    tol <- 1e-6  \n    \n    profile <- subset(lad_df, abs(x - x_target) < tol & abs(y - y_target) < tol)  \n    \n    if (nrow(profile) == 0) {\n      # Show warning if no profile exists for selected coordinates\n      warning(\"No data for the selected coordinates.\")\n      plot.new()\n      title(main = paste(\"No profile at\", x_target, \"/\", y_target))\n      return(invisible(NULL))\n    }\n    \n    # Normalize height and LAD\n    height_range <- range(profile$Height_bin, na.rm = TRUE)  \n    # Determine the maximum LAD value for relative normalization\n    lad_max <- max(profile$LAD_median, na.rm = TRUE)  \n    \n    height_scaled <- (profile$Height_bin - min(height_range)) / diff(height_range)  \n    height_unscaled <- profile$Height_bin\n    # Determine the maximum LAD value for relative normalization\n    lad_scaled <- profile$LAD_median / lad_max  \n    \n    plot(\n      x = lad_scaled,\n      y = height_unscaled, #height_scaled,\n      type = \"l\",\n      lwd = 2,\n      col = \"darkgreen\",\n      xlab = \"LAD (normalized)\",\n      ylab = \"Height (m)\",\n      main = paste(\"Profile at\", x_target, \"/\", y_target)\n    )\n  }\n}\n# --- Visualize LAD profiles -------------------------------------------------\n```\n:::\n\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Option 1: Profile in each column\nplot_lad_profiles(lad_df, plotstyle = \"each_median\")\n```\n\n::: {.cell-output-display}\n![](tls_v1_1_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Option 2: Overall vertical LAD profile (median of all)\nplot_lad_profiles(lad_df, plotstyle = \"all_median\")\n```\n\n::: {.cell-output-display}\n![](tls_v1_1_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Option 3: Single profile at specified coordinates\nplot_lad_profiles(lad_df, plotstyle = \"single_profile\", single_coords = c(57.5, -94.5))\n```\n\n::: {.cell-output-display}\n![](tls_v1_1_files/figure-html/unnamed-chunk-7-3.png){width=672}\n:::\n:::\n\n\n\n## ENVI-met 3D Tree Export \n\nThe next section describes more detailed how the key input values in the R function export_lad_to_envimet3d() are computed, derived or selected, and provides the rationale for each. The function converts a voxel-based Leaf Area Density (LAD) profile, typically obtained from Terrestrial Laser Scanning (TLS) data, into a structured XML file compatible with ENVI-met’s 3D tree model (.pld or PLANT3D).\n\nGiven the sensitivity of ENVI-met simulations to tree morphology and LAD distribution, the function ensures that the spatial dimensions, vertical layering and LAD intensity values are all correctly represented. Some parameters are optional, but can be derived from the data if not explicitly set.\n\nThe table below details each argument of the function, including its purpose, how it is determined and its necessity.\n\n| Code Line | Meaning | Reason |\n|--------------------|-------------------------|---------------------------|\n| `lad_df <-`<br>`lad_df[!is.na(lad_df$LAD_median), ]` | Removes entries with missing LAD values | Ensures only valid data is used in the LAD calculation and XML export |\n| `lad_df$i <-`<br>`as.integer(factor(lad_df$x))` | Converts x-coordinates to integer voxel column indices (i) | Required for ENVI-met LAD matrix indexing |\n| `lad_df$j <-`<br>`as.integer(factor(lad_df$y))` | Converts y-coordinates to integer voxel row indices (j) | Same as above, for the y-direction |\n| `z_map <-`<br>`setNames( ...)` | Maps unique height bins to sequential vertical indices (k) | Translates height levels into voxel layers compatible with ENVI-met |\n| `lad_df$k <-`<br>`z_map[as.character(lad_df$Height_bin)]` | Applies the vertical index to the LAD data | Aligns LAD values with ENVI-met vertical layer system |\n| `lad_df$lad_value <-`<br>`round(lad_df$LAD_median * scale_factor, 5)` | Scales LAD values and rounds to 5 digits | Brings LAD values to a usable range for ENVI-met and ensures precision |\n| `dataI <-`<br>`max(lad_df$i)` | Gets the number of horizontal grid cells in i-direction (width) | Required as matrix size input for ENVI-met |\n| `dataJ <-`<br>`max(lad_df$j)` | Gets the number of horizontal grid cells in j-direction (depth) | Required as matrix size input for ENVI-met |\n| `zlayers <-`<br>`max(lad_df$k)` | Gets the number of vertical layers | Sets the height resolution of the LAD matrix |\n\n------------------------------------------------------------------------\n\n## Automatic Grid Dimensions transformation\n\nCalculates the voxel grid dimensions in X, Y, and Z from the TLS-derived LAD profile.\n\nThe table below outlines how the core spatial and structural parameters of the tree model are computed from the input LAD_DF data frame. These derived values define the three-dimensional structure of the tree in terms of its horizontal extent, vertical layering and canopy dimensions.\n\nData I and data J represent the size of the voxel grid in the i and j dimensions, respectively, based on unique horizontal (x and y) and vertical (height bin) bins in the LAD profile.\n\n'Width' and 'Depth' describe the physical spread of the tree crown, inferred from the voxel grid extent if not manually set.\n\nHeight is computed by multiplying the number of vertical layers (zlayers) by the voxel resolution (cellSize), providing the total modelled height of the canopy.\n\nThese computed values are essential for correctly normalization and locating the 3D LAD matrix within the ENVI-met simulation domain to ensure visual and physiological realism.\n\n| Code Line | Meaning | Reason |\n|-------------------|------------------------|-----------------------------|\n| `Width  <- if (is.null(Width)) dataI else Width` | Uses the number of i-cells if Width is not provided | Automatically estimates tree width from voxel spread in x-direction |\n| `Depth  <- if (is.null(Depth)) dataJ else Depth` | Uses the number of j-cells if Depth is not provided | Automatically estimates tree depth from voxel spread in y-direction |\n| `Height <- zlayers * cellsize` | Converts number of vertical layers to metric height using cellsize | Computes physical tree height in meters for ENVI-met |\n\n``` r\n# 1. Remove NA values from the LAD column\nlad_df <- lad_df[!is.na(lad_df$LAD_median), ]\n\n# 2. Create discrete i and j indices for the horizontal position\n# (converts x and y coordinates into consecutive index values)\nlad_df$i <- as.integer(factor(lad_df$x))\nlad_df$j <- as.integer(factor(lad_df$y))\n\n# 3. Assign each Height_bin (z direction) a consecutive layer ID k\n# (z_map assigns an index layer to each unique height)\nz_map <- setNames(seq_along(sort(unique(lad_df$Height_bin))), sort(unique(lad_df$Height_bin)))\nlad_df$k <- z_map[as.character(lad_df$Height_bin)]\n\n# 4. Scale LAD values, e.g. to get from 0.02 to more realistic values such as 0.5–1.5\nlad_df$lad_value <- round(lad_df$LAD_median * scale_factor, 5)\n\n# 5. Calculate the maximum dimensions of the grid (for XML specifications)\ndataI <- max(lad_df$i) # Width in cells (x-direction)\ndataJ <- max(lad_df$j) # Depth in cells (y-direction)\nzlayers <- max(lad_df$k) # Number of vertical layers (z-direction)\n```\n\n## Transmittance and Albedo\n\n``` r\nAlbedo = 0.18\nTransmittance = 0.3\n```\n\n**`Albedo = 0.18`**: Albedo is the fraction of incoming solar radiation reflected by the canopy surface. For deciduous trees, values usually range between **0.15 and 0.20**. `0.18` is a commonly used default for broadleaved species like *Fagus sylvatica* or *Quercus robur* in many ecological models (e.g., ENVI-met, MAESPA). It affects surface energy balance and radiation reflection in ENVI-met simulations.\n\n**`Transmittance = 0.3`**: Transmittance represents the proportion of shortwave radiation that passes through the canopy without being absorbed or reflected. Deciduous trees in full leaf have transmittance values between **0.1 and 0.4** depending on species and LAI. `0.3` reflects moderate canopy density, consistent with empirical observations for mid-summer crowns. It controls how much light reaches the ground and sub-canopy vegetation; affects microclimate and shading.\n\nBoth values can be adjusted to match field measurements or literature for specific species or leaf phenology. However you can use them as robust fallback defaults when exact species traits are unavailable.\n\n## Season-Profile\n\nDefines monthly LAD normalization.\n\n`SeasonProfile = c(0.2, 0.2, 0.4, 0.7, 1.0, 1.0, 1.0, 0.8, 0.6, 0.3, 0.2, 0.2)`\n\nThe `SeasonProfile` is a vector of 12 numeric values (one per month) weighting the *relative Leaf Area Density (LAD)* throughout the year. It models *seasonal leaf development and senescence*, controlling how much foliage is present in each month:\n\n-   Values range from `0.0` (no foliage) to `1.0` (full foliage).\n-   For deciduous trees like *Fagus sylvatica* or *Quercus robur*, foliage develops in **spring (April–May)**, peaks in **summer (June–August)**, and declines in **autumn (September–October)**.\n\n**Profile Breakdown**:\n\n| Months           | Value | Interpretation        |\n|------------------|-------|-----------------------|\n| Jan–Feb, Nov–Dec | 0.2   | Dormant / leafless    |\n| March            | 0.4   | Budburst begins       |\n| April            | 0.7   | Leaf expansion        |\n| May–July         | 1.0   | Full canopy           |\n| August           | 0.8   | Leaf maturity decline |\n| September        | 0.6   | Senescence onset      |\n| October          | 0.3   | Strong senescence     |\n\nThe `SeasonProfile` directly influences LAD in ENVI-met’s dynamic vegetation simulation — affecting transpiration, shading, and energy balance across the simulation year. Adjusting this vector allows tailoring of phenology to site-specific or species-specific data.\n\n## `L-SystemBased` trees in ENVI-met (Experimetal)\n\nENVI-met optionally allows procedural generation of tree architecture using *Lindenmayer Systems (L-Systems)* — a formal grammar originally used to simulate plant growth patterns. When `L-SystemBased = 1`, the geometry of the tree is not derived from a static LAD matrix alone, but supplemented or replaced by rule-based 3D branching structures which supplement or replace the matrix. This is **independent** of the LAD profile but may affect shading and visualisation in the Albero interface of ENVI-met.\n\n``` r\nL-SystemBased = 1\nAxiom = \"F(2)V\\V\\\\V/////B\"\nIterationDepth = 3\n```\n\n### Explanation of Key Parameters\n\n| Parameter | Meaning |\n|--------------------|----------------------------------------------------|\n| `L-SystemBased` | If `1`, enables L-system generation (uses rules to grow plant structure) |\n| `Axiom` | Starting string (\"seed\") for the L-system; defines base growth |\n| `IterationDepth` | How many times to apply production rules; higher means more detail |\n| `TermLString` | Optional: Final symbol to be drawn/rendered (e.g. \"L\") |\n| `ApplyTermLString` | If `1`, interprets the `TermLString`; otherwise, renders entire string |\n\n### Default Settings\n\n![L-System Branching as implemented by default](L-tree.png){width=\"30%\"}\n\n``` xml\n<L-SystemBased>1</L-SystemBased>\n<Axiom>F(2)V\\V\\\\V/////B</Axiom>\n<IterationDepth>3</IterationDepth>\n<TermLString>L</TermLString>\n<ApplyTermLString>1</ApplyTermLString>\n```\n\n-   **`F(2)`**: Move forward with length 2 (main trunk)\n-   **`V\\\\V/////B`**: Branching pattern with rotations (backslashes and slashes encode rotation commands); `B` may denote a terminal leaf or bud\n-   **`IterationDepth = 3`**: The production rules (if defined) will be applied 3 times to this axiom, generating a fractal-like tree structure.\n\n> Note: In ENVI-met, the **actual grammar rules are hard-coded** and not customizable in `.pld` — only the axiom and iteration depth are user-defined. It is highly experimental and poorly documented\n\nUse `L-SystemBased = 1` if:\n\n-   You want **visual structure** added to otherwise sparse or low-resolution LAD matrices\n\n-   The tree lacks realistic shape (for Albero visualization)\n\n-   Use `L-SystemBased = 0` (default) if:\n\n    -   You already provide a **dense voxel-based LAD** (from TLS or similar)\n    -   You want **strict control** over the 3D structure via LAD profile only\n\n### Import TLS-based `.pld` into ENVI-met via Albero Clipboard\n\n**Requirements**\\\n- ENVI-met 5.8+\\\n- `.pld` file (e.g. `oak_tls_envimet.pld`)\\\n- Albero editor (via Leonardo)\n\n**Steps**\\\n1. **Open Albero**\\\n→ Leonardo → Database → Plant Database\\\n2. **Open Clipboard**\\\n→ Click Clipboard (top-right)\\\n3. **Import `.pld`**\\\n→ Clipboard → Import → Load file\\\n4. **Edit (optional)**\\\n→ Adjust LAD, albedo, transmittance, name, etc.\\\n5. **Send to Library**\\\n→ Click “Send to Library”\\\n6. **Use in ENVI-met**\\\n→ In Leonardo/Spaces assign plant to your 3D model\n\n**Notes**\\\n- `.pld` contains LAD(z) values (m²/m³)\\\n- Use Advanced Settings to fine-tune visualization\\\n- Custom plants stored in your personal Albero library\n\n## Key Benefits\n\n- **Efficient and scalable**: The method avoids destructive sampling by using TLS return counts as proxies for leaf density. This makes it suitable for large-scale or repeated surveys without the need for time-consuming ground calibration.\n\n- **Captures structural patterns**: Normalizing the LAD values retains the vertical and spatial structure of vegetation, enabling meaningful comparison of crown shape, canopy layering, and vegetation density across space or time.\n\n- **Directly usable in ENVI-met**: The output is structured as a raster stack with height-specific layers, aligning with the input requirements of ENVI-met's *SimplePlant* or *3D vegetation* modules. This enables seamless integration into microclimate simulations.\n\n## Limitations\n\n- **Simplified assumptions**: The linear mapping of TLS returns to LAD assumes a proportional relationship, which simplifies the complex interaction between laser pulses and vegetation surfaces.\n\n- **Scan geometry dependency**: Occlusion, scan angle, and varying point densities can distort the return distribution, especially in dense or multi-layered vegetation.\n\n- **Generic LAD normalization**: The maximum LAD value used for normalization is taken from literature-based estimates rather than site-specific measurements, which can introduce bias in absolute LAD magnitudes.\n\n## Conclusion\n\nThis workflow offers a robust and accessible approach for analyzing vegetation structure and generating model-ready LAD profiles from TLS data. It is especially useful for **relative comparisons and ecological modeling**, but is **not intended for absolute LAD quantification without additional calibration**.\n\n\n\n# ENVI-met Pseudo-3DPLANT Profile Generation from ALS Data\n\nFor a realitic sourounding we need voxelized ALS (Airborne Laser Scanning) data which needs to be usable as ENVI-met compatible 3DPLANT profiles. It includes LAD (Leaf Area Density) computation, profile clustering, and export to both GIS and XML formats for ENVI-met integration.\n\nTo provide a realistic but computationally tractable vegetation structure, we apply a **pseudo-3D columnar tree approach**: each voxel column of ALS returns is interpreted as a simplified vertical tree profile. These profiles are clustered to reduce complexity, then exported as ENVI-met 3DPLANT objects.\n\n## Why ALS Requires a Specific LAD Approach\n\nUnlike TLS (Terrestrial Laser Scanning), which scans from the bottom-up and suffers from occlusion in upper layers, ALS samples vegetation top-down. This means:\n\n- **ALS oversamples upper canopy layers**\n- **ALS undersamples lower canopy due to occlusion**\n\nTo correct for this sampling bias, we estimate LAD using a modified form of Beer's Law, based on the *normalized proportion of hits* per voxel layer. The key difference lies in the way \"gap probability\" is estimated: rather than tracking cumulative occlusion, ALS uses the **maximum return count per column** as a proxy for full canopy closure.\n\n## LAD Estimation Using Beer's Law\n\nWe model LAD using:\n\n$$\nLAD = -\\frac{\\ln(1 - p)}{k \\cdot dz}\n$$\n\nWhere:\n- \\( p \\) is the normalized proportion of hits per voxel column (\\( 0 < p < 1 \\))\n- \\( k \\) is the light extinction coefficient\n- \\( dz \\) is the vertical resolution (voxel height)\n\nIn our script, we set:\n- \\( k = 0.3 \\) (typical value)\n- LAD values are scaled using a multiplicative factor (default 1.2)\n\n### TLS Variant of LAD\n\nIn TLS-based LAD estimation, we assume that the LiDAR sensor is located near ground level and that returns are accumulated from bottom to top. In this setup, each voxel's return count \\( N_i \\) is interpreted as contributing to the cumulative **transmittance** through the canopy.\n\nThe Beer–Lambert law is applied as:\n\n$$\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n$$\n\nHere:\n- \\( N_i \\): number of returns in voxel layer \\( i \\)\n- \\( N_{\\max} \\): maximum number of returns in any voxel in the column (used to normalize return density)\n- \\( \\Delta z \\): voxel height\n- \\( k \\): extinction coefficient\n\n#### Physical Interpretation\n\nThe ratio \\( \\frac{N_i}{N_{\\max}} \\) estimates the **fraction of light intercepted** at layer \\( i \\), assuming the densest layer represents near-total occlusion. Thus, the term \\( 1 - \\frac{N_i}{N_{\\max}} \\) represents the **gap fraction** — i.e., the **probability that a beam of light traveling *from the ground upward* has not yet been occluded by vegetation up to that layer**.\n\nThis interpretation fits the TLS scanning geometry, where lower layers are sampled first and occlusion increases with height.\n\n### ALS Variant Used Here\n\nWe assume that the highest return count in the column corresponds to full canopy closure (i.e., near-zero gap fraction). This allows us to use the maximum as a local normalization factor:\n\n- \\( p_i = \\frac{N_i}{N_{\\max}} \\)\n- \\( LAD_i = -\\ln(1 - p_i) / (k \\cdot dz) \\)\n\nThis **does not model occlusion directly**, but gives a consistent LAD profile for column-wise clustering.\n\n## Full Workflow: Voxelization to ENVI-met 3D Trees\n\n### Normalize ALS Height and Filter Ground\n\n```r\nlas <- readLAS(las_file)\nlas <- normalize_height(las, knnidw(k = 6, p = 2))\nlas <- filter_poi(las, Z > 0)\n```\n\n### Voxelize ALS Point Cloud\n\n```r\nvoxels <- voxel_metrics(las, ~length(Z), res = res_xy, dz = res_z)\n```\n\n### Convert Voxel Counts to LAD using ALS-based Beer's Law\n\n```r\nlad_df <- convert_voxel_lad_long(voxels, res_z = res_z, k = k, scale_factor = scale_factor)\n```\n\n### Cluster Similar LAD Profiles\n\nWe reduce the number of ENVI-met profiles by grouping similar LAD profiles using k-means clustering. LAD profiles are pivoted to a wide matrix (z-layers as columns):\n\n```r\nlad_df$xy_key <- paste(lad_df$x, lad_df$y)\nlad_matrix <- lad_df %>% \n  tidyr::pivot_wider(names_from = z, values_from = lad, values_fill = 0) %>%\n  column_to_rownames(\"xy_key\") %>%\n  as.matrix()\nclustering <- kmeans(lad_matrix, centers = n_clusters, nstart = 10)\nlad_df$cluster <- clustering$cluster[match(lad_df$xy_key, rownames(lad_matrix))]\n```\n\n### Assign 6-Character ENVIMET_IDs\n\nEach LAD cluster is assigned a unique identifier that begins with \"S\" and uses base36 encoding (0–9, A–Z):\n\n```r\nint_to_base36 <- function(n, width = 5) {\n  chars <- c(0:9, LETTERS)\n  base <- length(chars)\n  result <- character()\n  while (n > 0) {\n    result <- c(chars[(n %% base) + 1], result)\n    n <- n %/% base\n  }\n  result <- paste(result, collapse = \"\")\n  padded <- sprintf(paste0(\"%0\", width, \"s\"), result)\n  paste0(\"S\", substr(gsub(\" \", \"0\", padded), 1, width))\n}\n```\n\n### Export Point Locations as GIS Layer\n\nEach unique LAD column becomes a point in a GeoPackage, tagged with its ENVIMET_ID.\n\n```r\nsf_points <- st_as_sf(point_df, coords = c(\"x\", \"y\"), crs = crs_code)\nst_write(sf_points, output_gpkg, delete_layer = TRUE)\n```\n\n### Export Clustered LAD Profiles as ENVI-met 3DPLANT XML\n\nThe LAD profile per cluster is exported to a `.pld` file using XML.\n\n```r\nexport_lad_to_envimet3d(lad_df, file_out = xml_output_file)\n```\n\n## Concept of Pseudo-3D Tree Columns\n\nEach clustered LAD profile is interpreted as a **pseudo-3D vegetation column**. These are not derived from segmented individual trees but represent aggregated vertical structure typical for a 2 × 2 m area.\n\nThis approach provides a balance between realism and simplicity:\n\n- It allows **realistic vertical vegetation profiles** from ALS\n- Reduces complexity through **clustering**\n- Provides **efficient integration into ENVI-met** via both:\n  - GIS point layers with `ENVIMET_ID`\n  - XML-based 3DPLANT definitions\n\nPseudo-3D trees enable **realistic microclimate domains** with vegetation heterogeneity without requiring full 3D reconstruction.\n\n## TLS vs ALS LAD Computation Summary\n\n| Aspect              | TLS                                 | ALS                               |\n|---------------------|--------------------------------------|-----------------------------------|\n| View Direction      | Bottom-up                           | Top-down                          |\n| Occlusion Bias      | Undersamples upper canopy           | Undersamples lower canopy         |\n| LAD Estimation      | Cumulative bottom-up (Beer)         | Normalized per column (max count) |\n| Typical Use Case    | Detailed single tree analysis       | Large-area structure sampling     |\n\n## Conclusion and Limitations\n\nThis pipeline offers an efficient method to integrate voxelized ALS data into ENVI-met's 3DPLANT framework by:\n\n- Estimating LAD profiles via a Beer–Lambert-based approximation\n- Clustering voxel columns into representative pseudo-3D vegetation types\n- Exporting both point geometries and XML-based plant profiles\n\n**Advantages:**\n- Scalable to large ALS datasets\n- Preserves key structural heterogeneity\n- Compatible with ENVI-met simulation domains\n\n**Limitations:**\n- Assumes that the maximum voxel return represents full canopy cover, which may not hold in sparse stands\n- LAD estimation is empirical; it does not model true light attenuation or occlusion\n- The pseudo-3D approach does not represent individual trees or crown geometry\n- Clustering may smooth out fine-scale vertical variability\n\nFuture improvements could include stratified LAD normalization, occlusion-aware corrections, or hybrid ALS-TLS fusion for enhanced realism.\n\n## References\n\n- Béland, M., et al. (2014). *Remote Sensing of Environment*\n- Calders, K., et al. (2015). *Methods in Ecology and Evolution*\n- Jupp, D. L. B., et al. (2009). *Remote Sensing of Environment*\n\n## Script Reference\n\n```r\nsource(\"src/microclimate_ALS.R\")\n```\n\nThis source contains the complete processing workflow from voxel metrics to XML generation.\n\n## References\n\n-   Calders et al. (2015). Nondestructive biomass estimation via TLS. *Methods Ecol Evol*, 6:198–208.<https://doi.org/10.1111/2041-210X.12301>\n- Chen et al. (2018): Estimation of LAI in open-canopy forests using TLS and path length models. *Agric. For. Meteorol.* 263, 323–333. [https://doi.org/10.1016/j.agrformet.2018.09.006](https://doi.org/10.1016/j.agrformet.2018.09.006)\n-   ENVI-met *PLANT3D* specification: <https://www.envi-met.net/documents/papers/overview30.pdf>\n-   ENVI-met *Albero* overview: <https://envi-met.com/tutorials/albero-overview>\n-   ENVI-met KB – *Obtaining Leaf Area Density*: <https://envi-met.info/doku.php?id=kb:lad#obtaining_leaf_area_density_data>\n-   ENVI-met *dbmanager* documentation: <https://envi-met.info/doku.php?id=apps:dbmanager:start>\n-   ENVI-met Vegetation Tutorial (YouTube): <https://www.youtube.com/watch?v=KGRLnXAXZds>\n-   Flynn et al. (2023) – TLS-based vegetation index estimation; compares methods and highlights complexities in Mediterranean forest. *Biogeosciences*, 20(13), 2769–2784. [doi:10.5194/bg-20-2769-2023](https://doi.org/10.5194/bg-20-2769-2023)\n-   Hosoi & Omasa (2006). Voxel-based 3D tree modeling. *IEEE TGRS*, 44(12), 3610–3618. <https://doi.org/10.1109/TGRS.2006.881743>\n-   Prusinkiewicz & Lindenmayer (1990). *The Algorithmic Beauty of Plants*. Springer. <https://doi.org/10.1007/978-1-4613-8476-2>\n-   Oshio & Asawa (2016). Solar transmittance of urban trees. *IEEE TGRS*, 54(9), 5483–5492. <https://doi.org/10.1109/TGRS.2016.2565699>\n-   Simon, Sinsel & Bruse (2020). Fractal trees in ENVI-met. *Forests*, 11(8), 869. <https://doi.org/10.3390/f11080869>\n-   Wilkes et al. (2017). TLS acquisition strategies. *Remote Sens Environ*, 196, 140–153. <https://doi.org/10.1016/j.rse.2017.04.030>\n-   Chen et al. (2018). LAI from TLS. *Agr Forest Meteorol*, 263, 323–333. <https://doi.org/10.1016/j.agrformet.2018.09.006>\n-   Yin et al. (2019). Shading and thermal comfort. *Sustainability*, 11(5), 1355. <https://doi.org/10.3390/su11051355>\n-   Zhang (2024). Green layouts in ENVI-met. *Informatica*, 48(23). <https://doi.org/10.31449/inf.v48i23.6881>\nCertainly. Here's the reference adapted to match your current compact style:\n\n\n\n",
    "supporting": [
      "tls_v1_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}