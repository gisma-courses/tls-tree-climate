[
  {
    "objectID": "modeling/script-00-interpolation.html",
    "href": "modeling/script-00-interpolation.html",
    "title": "Spatial Interpolation",
    "section": "",
    "text": "Script: Spatial Interpolation\n\n#------------------------------------------------------------------------------\n# Name: FR_soilmoist.R\n# Type: control script \n# Author: Chris Reudenbach, creuden@gmail.com\n# Description:  calculates the soil moisture from Lacanau point data\n# Copyright:GPL (&gt;= 3) \n# Date: 2022-11-10 \n# V-2022-11-12; \n#------------------------------------------------------------------------------\n# 0 - project setup\n#------------------------------------------------------------------------------\n# geoAI course basic setup\n# Type: script\n# Name: geoAI_setup.R\n# Author: Chris Reudenbach, creuden@gmail.com\n# Description:  create/read project folder structure and returns pathes as list\n#               load all necessary packages \n#               sources all functions in a defined function folder\n# Dependencies:   \n# Output: list containing the folder strings as shortcuts\n# Copyright: Chris Reudenbach, thomas Nauss 2019-2021, GPL (&gt;= 3)\n# git clone https://github.com/gisma-courses/geoAI-scripts.git\n#------------------------------------------------------------------------------\n\n\n\n# basic packages\nlibrary(\"mapview\")\nlibrary(\"tmap\")\nlibrary(\"tmaptools\")\nlibrary(\"raster\")\nlibrary(\"terra\")\nlibrary(\"sf\")\nlibrary(\"dplyr\")\nlibrary(\"lidR\")\nlibrary(\"future\")\nlibrary(\"lwgeom\")\nlibrary(\"tmap\")\nlibrary(\"mapview\")\nlibrary(rprojroot)\n\nroot_folder = find_rstudio_root_file()\n#root_folder = getwd()\nndvi.col = function(n) {\n  rev(colorspace::sequential_hcl(n, \"Green-Yellow\"))\n}\n\nano.col = colorspace::diverging_hcl(7, palette = \"Red-Green\",  register = \"rg\")\n\n\n\n\n# # suppres gdal warnings\n# rgdal::set_thin_PROJ6_warnings(TRUE)\n# \n# \n# \n# # workaround subfolder\n# loc_name = \"harz\"\n# \n# # harz\n# epsg=25833\n# \n# attributename = c(\"Moisture_1_17Nov\",\"Moisture_2_17Nov\",\"Moisture_1_19Nov\",\"Moisture_2_19Nov\")\n# varname = c(\"soilmoist2022_08_17\",\"soilmoist2022_08_19\")\n# fnDTM = \"DTM_v3.vrt\"\n# fnsm_data = \"lacanau_moisture_measurements.csv\"\n# fnpos_data= \"ltrees.gpkg\"\n# \n# # read DTM\n# DTM = terra::rast(fnDTM)\n# # cast to SpatialPixelsDataFrame\n# DTM.spdf &lt;- as(raster(DTM),\n#                        'SpatialPixelsDataFrame')\n# colnames(DTM.spdf@data) &lt;- \"altitude\"\n# # read moist data \n# sm=read.csv2(fnsm_data,sep = \",\")\n# # read tree data\n# pos=st_read(fnpos_data)\n# # merge\n# sm$Point = paste0(\"TREE\",str_split_fixed(sm$TargetID, \"_\", 3)[,3])\n# m=merge(pos,sm)\n# \n# # extract altitudes for positions\n# em= exactextractr::exact_extract(DTM,st_buffer(m,1),\"mean\")\n# m$altitude=em\n# \n# # start kriging \n# for (i in 1:length(varname) ){\n#   z=i*2\n#   # mean\n#   m$var = (as.numeric(m[[attributename[z-1]]]) + as.numeric(m[[attributename[z]]]))/2\n#   # to sp\n#   m2 = as(m,\"Spatial\")    \n#   tm2 = spTransform(m2,\n#                     crs(\"+proj=utm +zone=30 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"))\n# \n#   # autofit variogramm for kriging \n#   vm.auto = automap::autofitVariogram(formula = as.formula(paste(\"var\", \"~ 1\")),\n#                                       input_data = tm2)\n#   plot(vm.auto)\n#   \n#   # kriging   \n#   print(paste0(\"kriging \", varname[i]))\n#   var.pred &lt;- gstat::krige(formula = as.formula(paste(\"var\", \"~ altitude\")),\n#                            locations = tm2,\n#                            newdata = DTM.spdf,\n#                            model = vm.auto$var_model,\n#                            debug.level=0,)\n#   \n#   r=rasterFromXYZ(as.data.frame(var.pred)[, c(\"x\", \"y\", \"var1.pred\")])\n#   \n#   # reclassify erratic values \n#   reclass_df &lt;- c(-Inf, 0, NA)\n#   # reshape the object into a matrix with columns and rows\n#   reclass_m &lt;- matrix(reclass_df,\n#                       ncol = 3,\n#                       byrow = TRUE)\n#   r_c &lt;- reclassify(r,reclass_m)\n# \n#   plot(r_c)\n#   # re assign crs\n#   crs(r_c) = crs(paste0(\"EPSG:\",epsg))\n#   raster::writeRaster(r_c,paste0(\"data/gis/France_Lacanau_PP_Gis/data_lev0/\",varname[i],\".tif\"),overwrite=TRUE)\n#   \n# }"
  },
  {
    "objectID": "modeling/qgis-tutorials.html",
    "href": "modeling/qgis-tutorials.html",
    "title": "Data and Software",
    "section": "",
    "text": "Please find all Data Downloads at theCourse Data Server Data folder for any file exchange and data related purposes."
  },
  {
    "objectID": "modeling/qgis-tutorials.html#data-set-for-training-purposes",
    "href": "modeling/qgis-tutorials.html#data-set-for-training-purposes",
    "title": "Data and Software",
    "section": "",
    "text": "Please find all Data Downloads at theCourse Data Server Data folder for any file exchange and data related purposes."
  },
  {
    "objectID": "modeling/qgis-tutorials.html#specific-modeling-software",
    "href": "modeling/qgis-tutorials.html#specific-modeling-software",
    "title": "Data and Software",
    "section": "Specific modeling software",
    "text": "Specific modeling software\nPlease find all Downloads according to ENVI-met at the ENVI-met landing page"
  },
  {
    "objectID": "modeling/qgis-tutorials.html#common-software",
    "href": "modeling/qgis-tutorials.html#common-software",
    "title": "Data and Software",
    "section": "Common Software",
    "text": "Common Software\nShell ‚Äî any command line environment will do for the exercises. For Linux we recommend the bash shell. For Windows the Windows command line can be used.\n\nQGIS has become one of the most promising and most integrative open source GIS systems over the last years. Through the processing plugin, it additionally integrates modules from the other leading free GIS solutions. We will need it (if necessary) to prepare or manipulate some of the data.\n\nRegarding installation, for Ubuntu Linux, the Ubuntu GIS package is a good choice. For Windows, we strongly recommend installing everything via the OSGeo4W environment and not the standalone QGIS installation tool."
  },
  {
    "objectID": "modeling/qgis-tutorials.html#additional-data-sources",
    "href": "modeling/qgis-tutorials.html#additional-data-sources",
    "title": "Data and Software",
    "section": "Additional data sources",
    "text": "Additional data sources"
  },
  {
    "objectID": "base/impressum.html#content-responsibility",
    "href": "base/impressum.html#content-responsibility",
    "title": "Impressum",
    "section": "Content Responsibility",
    "text": "Content Responsibility\nThe responsibility for the content rests with the instructors. Statements, opinions and/or conclusions are the ones from the instructors and do not necessarily reflect the opinion of the representatives of Marburg University."
  },
  {
    "objectID": "base/impressum.html#content-license",
    "href": "base/impressum.html#content-license",
    "title": "Impressum",
    "section": "Content License",
    "text": "Content License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\nPrivacy Policy\n\n\nAs of 21. October 2021\n\n\nIntroduction\n\n\nWith the following data protection declaration, we would like to inform you about the types of your personal data (hereinafter also referred to as ‚Äúdata‚Äù for short) that we process, for what purposes and to what extent. The privacy policy applies to all processing of personal data carried out by us, both in the context of the provision of our services and in particular on our websites, in mobile applications and within external online presences, such as our social media profiles (hereinafter collectively referred to as ‚ÄúOnline Offerings‚Äù).\n\n\nThe terms used are not gender-specific.\n\n\nResponsible\n\n\nDr Christoph ReudenbachDeutschhaustr 1035037 Marburg\n\n\nEmail address: reudenbach@uni-marburg.de.\n\n\nImprint: https://www.uni-marburg.de/de/impressum.\n\n\nOverview of Processing\n\n\nThe following overview summarizes the types of data processed and the purposes of their processing, and refers to the data subjects.\n\n\nTypes of Data Processed\n\n\n\nContent data (e.g.¬†input in online forms).\n\n\nContact data (e.g.¬†email, phone numbers).\n\n\nMeta/communication data (e.g.¬†device information, IP addresses).\n\n\nUse data (e.g.¬†websites visited, interest in content, access times).\n\n\n\nCategories of data subjects\n\n\n\nCommunication partners.\n\n\nUsers (e.g.. Website visitors, users of online services).\n\n\n\nPurposes of processing\n\n\n\nDirect marketing (e.g., by email or postal mail).\n\n\nContact requests and communications.\n\n\n\nRelevant legal basis\n\n\nThe following is an overview of the legal basis of the GDPR on the basis of which we process personal data. Please note that in addition to the provisions of the GDPR, national data protection regulations may apply in your or our country of residence or domicile. Furthermore, should more specific legal bases be decisive in individual cases, we will inform you of these in the data protection declaration.\n\n¬†\n\n\nConsent (Art. 6 para. 1 p.¬†1 lit. a. DSGVO) - The data subject has given his or her consent to the processing of personal data concerning him or her for a specific purpose or purposes.\n\n\nRegistered interests (Art. 6 para. 1 p.¬†1 lit. f.¬†DSGVO) - Processing is necessary to protect the legitimate interests of the controller or a third party, unless such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require the protection of personal data.\n\n\n\nNational data protection regulations in Germany: In addition to the data protection regulations of the General Data Protection Regulation, national regulations on data protection apply in Germany. These include, in particular, the Act on Protection against Misuse of Personal Data in Data Processing (Federal Data Protection Act - BDSG). In particular, the BDSG contains special regulations on the right to information, the right to erasure, the right to object, the processing of special categories of personal data, processing for other purposes and transmission, as well as automated decision-making in individual cases, including profiling. Furthermore, it regulates data processing for employment purposes (Section 26 BDSG), in particular with regard to the establishment, implementation or termination of employment relationships as well as the consent of employees. Furthermore, state data protection laws of the individual federal states may apply.\n\n¬†\n\nSecurity measures\n\n\nWe take appropriate technical and organizational measures in accordance with the legal requirements, taking into account the state of the art, the implementation costs and the nature, scope, circumstances and purposes of the processing, as well as the different probabilities of occurrence and the extent of the threat to the rights and freedoms of natural persons, in order to ensure a level of protection appropriate to the risk.\n\n.\n\nMeasures include, in particular, ensuring the confidentiality, integrity, and availability of data by controlling physical and electronic access to data as well as access to, entry into, disclosure of, assurance of availability of, and segregation of data concerning them. Furthermore, we have established procedures to ensure the exercise of data subjects‚Äô rights, the deletion of data, and responses to data compromise. Furthermore, we take the protection of personal data into account as early as the development or selection of hardware, software as well as procedures in accordance with the principle of data protection, through technology design and through data protection-friendly default settings.\n\n¬†\n\nDeletion of data\n\n\nThe data processed by us will be deleted in accordance with legal requirements as soon as their consents permitted for processing are revoked or other permissions cease to apply (e.g.¬†if the purpose of processing this data has ceased to apply or it is not necessary for the purpose).\n\n¬†\n\nIf the data are not deleted because they are required for other and legally permissible purposes, their processing will be limited to these purposes. That is, the data will be blocked and not processed for other purposes. This applies, for example, to data that must be retained for reasons of commercial or tax law or whose storage is necessary for the assertion, exercise or defense of legal claims or for the protection of the rights of another natural person or legal entity.\n\n¬†\n\nOur privacy notices may also include further information on the retention and deletion of data that takes precedence for the processing operations in question.\n\n¬†\n\nUse of cookies\n\n\nCookies are text files that contain data from websites or domains visited and are stored by a browser on the user‚Äôs computer. The primary purpose of a cookie is to store information about a user during or after their visit within an online site. Stored information may include, for example, language settings on a website, login status, a shopping cart, or where a video was watched. We further include in the term cookies other technologies that perform the same functions as cookies (e.g., when user details are stored using pseudonymous online identifiers, also referred to as ‚Äúuser IDs‚Äù)\n\n.\n\nThe following cookie types and functions are distinguished:\n\n\n\nTemporary cookies (also: session or session cookies):¬†Temporary cookies are deleted at the latest after a user has left an online offer and closed his browser.\n\n\nPermanent cookies:¬†Permanent cookies remain stored even after closing the browser. For example, the login status can be saved or preferred content can be displayed directly when the user revisits a website. Likewise, the interests of users used for range measurement or marketing purposes can be stored in such a cookie.\n\n\nFirst-party cookies:¬†First-party cookies are set by ourselves.\n\n\nThird-party cookies (also: third-party cookies): Third-party cookies are mainly used by advertisers (so-called third parties) to process user information.\n\n\nNecessary (also: essential or absolutely necessary) cookies: Cookies may be absolutely necessary for the operation of a website (e.g.¬†to store logins or other user input or for security reasons).\n\n\nStatistics, marketing and personalization cookies: Furthermore, cookies are usually also used in the context of range measurement and when the interests of a user or his behavior (e.g.¬†viewing certain content, use of functions, etc.) on individual web pages are stored in a user profile. Such profiles are used, for example, to show users content that matches their potential interests. This process is also referred to as ‚Äútracking‚Äù, i.e., tracking the potential interests of users. Insofar as we use cookies or ‚Äútracking‚Äù technologies, we will inform you separately in our privacy policy or in the context of obtaining consent.\n\n\n\nNotes on legal bases: On which legal basis we process your personal data using cookies depends on whether we ask you for consent. If this is the case and you consent to the use of cookies, the legal basis for the processing of your data is the declared consent. Otherwise, the data processed with the help of cookies is processed on the basis of our legitimate interests (e.g.¬†in a business operation of our online offer and its improvement) or, if the use of cookies is necessary to fulfill our contractual obligations.\n\n.\n\nDuration of storage: If we do not provide you with explicit information about the storage period of permanent cookies (e.g.¬†in the context of a so-called cookie opt-in), please assume that the storage period can be up to two years.\n\n.\n\nGeneral information on revocation and objection (opt-out):  Depending on whether the processing is based on consent or legal permission, you have the option at any time to revoke any consent given or to object to the processing of your data by cookie technologies (collectively referred to as ‚Äúopt-out‚Äù). You can initially declare your objection by means of your browser settings, e.g.¬†by deactivating the use of cookies (whereby this may also restrict the functionality of our online offer). An objection to the use of cookies for online marketing purposes can also be declared by means of a variety of services, especially in the case of tracking, via the websites https://optout.aboutads.info and https://www.youronlinechoices.com/. In addition, you can receive further objection notices in the context of the information on the service providers and cookies used.\n\n.\n\nProcessing of cookie data on the basis of consent: We use a cookie consent management procedure, in the context of which the consent of users to the use of cookies, or the processing and providers mentioned in the cookie consent management procedure can be obtained and managed and revoked by users. Here, the declaration of consent is stored in order not to have to repeat its query and to be able to prove the consent in accordance with the legal obligation. The storage can take place on the server side and/or in a cookie (so-called opt-in cookie, or with the help of comparable technologies), in order to be able to assign the consent to a user or their device. Subject to individual information on the providers of cookie management services, the following information applies: The duration of the storage of consent can be up to two years. Here, a pseudonymous user identifier is formed and stored with the time of consent, information on the scope of consent (e.g., which categories of cookies and/or service providers) as well as the browser, system and end device used.\n\n.\n\n\nTypes of data processed: Usage data (e.g.¬†websites visited, interest in content, access times), meta/communication data (e.g.¬†device information, IP addresses).\n\n\nPersons concerned: Users (e.g.¬†website visitors, users of online services).\n\n\nLegal basis: Consent (Art. 6 para. 1 p.¬†1 lit. a. DSGVO), Legitimate Interests (Art. 6 para. 1 p.¬†1 lit. f.¬†DSGVO).\n\n\n\nSurveys and polls\n\n\nThe surveys and polls (hereinafter ‚Äúsurveys‚Äù) conducted by us are evaluated anonymously. Personal data is only processed insofar as this is necessary for the provision and technical implementation of the surveys (e.g.¬†processing of the IP address to display the survey in the user‚Äôs browser or to enable a resumption of the survey with the help of a temporary cookie (session cookie)) or users have consented.\n\n.\n\nNotes on legal basis: If we ask participants for consent to process their data, this is the legal basis of the processing, otherwise the processing of participants‚Äô data is based on our legitimate interests in conducting an objective survey.\n\n¬†\n\n\nTypes of data processed: Contact data (e.g.¬†email, phone numbers), content data (e.g.¬†input in online forms), usage data (e.g.¬†web pages visited, interest in content, access times), meta/communication data (e.g.¬†device information, IP addresses).\n\n\nParticipants concerned: Communication partners.\n\n\nPurposes of processing: Contact requests and communication, direct marketing (e.g.¬†by e-mail or postal mail).\n\n\nLegal basis: Consent (Art. 6 para. 1 p.¬†1 lit. a. DSGVO), Legitimate Interests (Art. 6 para. 1 p.¬†1 lit. f.¬†DSGVO).\n\n\n\nChange and Update Privacy Policy\n\n\nWe encourage you to periodically review the contents of our Privacy Policy. We adapt the Privacy Policy as soon as the changes in the data processing activities we carry out make it necessary. We will inform you as soon as the changes require an act of cooperation on your part (e.g.¬†consent) or other individual notification.\n\n.\n\nWhere we provide addresses and contact information for companies and organizations in this Privacy Policy, please note that addresses may change over time and please check the information before contacting us.\n\n.\n\nRights of data subjects\n\n\nAs a data subject, you are entitled to various rights under the GDPR, which arise in particular from Art. 15 to 21 DSGVO:\n\n\n\nRight to object: You have the right to object at any time, on grounds relating to your particular situation, to the processing of personal data relating to you which is carried out on the basis of Art. 6(1)(e) or (f) DSGVO; this also applies to profiling based on these provisions. If the personal data concerning you is processed for the purpose of direct marketing, you have the right to object at any time to the processing of personal data concerning you for the purpose of such marketing; this also applies to profiling, insofar as it is associated with such direct marketing.\n\n\nRight of withdrawal in the case of consent: You have the right to withdraw any consent you have given at any time.\n\n\nRight of access: You have the right to request confirmation as to whether data in question is being processed and to information about this data, as well as further information and copy of the data in accordance with the legal requirements.\n\n\nRight of rectification: You have the right, in accordance with the legal requirements, to request the completion of the data concerning you or the correction of incorrect data concerning you.\n\n\nRight to erasure and restriction of processing: You have, in accordance with the law, the right to request that data concerning you be erased without undue delay, or alternatively, in accordance with the law, to request restriction of the processing of the data.\n\n\nRight to data portability: You have the right to receive data concerning you, which you have provided to us, in a structured, common and machine-readable format in accordance with the legal requirements, or to demand its transfer to another responsible party.\n\n\nComplaint to supervisory authority: Without prejudice to any other administrative or judicial remedy, you have the right to lodge a complaint with a supervisory authority, in particular in the Member State of your habitual residence, place of work or the place of the alleged infringement, if you consider that the processing of personal data concerning you infringes the requirements of the GDPR.\n\n\n.\n\nDefinitions of Terms\n\n\nThis section provides you with an overview of the terms used in this Privacy Policy. Many of the terms are taken from the law and defined primarily in Article 4 of the GDPR. The legal definitions are binding. The following explanations, on the other hand, are primarily intended to aid understanding. The terms are sorted alphabetically.\n\n¬†\n\n\nPersonal data: ‚ÄúPersonal data‚Äù means any information relating to an identified or identifiable natural person (hereinafter ‚Äúdata subject‚Äù); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier (eg. e.g.¬†cookie) or to one or more special characteristics that are an expression of the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.\n\n\nController: The ‚Äúcontroller‚Äù is the natural or legal person, public authority, agency or other body which alone or jointly with others determines the purposes and means of the processing of personal data.\n\n\nProcessing: ‚ÄúProcessing‚Äù means any operation or set of operations which is performed upon personal data, whether or not by automatic means. The term is broad and includes virtually any handling of data, whether collecting, evaluating, storing, transmitting or deleting.\n\n\n\nCreated with free Datenschutz-Generator.de by Dr.¬†Thomas Schwenke"
  },
  {
    "objectID": "base/impressum.html#comments-suggestions",
    "href": "base/impressum.html#comments-suggestions",
    "title": "Impressum",
    "section": "Comments & Suggestions",
    "text": "Comments & Suggestions"
  },
  {
    "objectID": "base/about.html",
    "href": "base/about.html",
    "title": "About this site",
    "section": "",
    "text": "About this site\nThis page summarizes the essential workflows , basic literature and web resources from the distributed course systems , documents and field protocols into a knowledge base.\nAlthough the web space is topic-centered any keyword can be searched using the full text search.\nThe creation of new pages, the editing of existing pages can be triggered directly via the right column online.\nOffline there are several visual editors and full integration with Rstudio etc."
  },
  {
    "objectID": "doc/microclimate_predictor_stack_commented.html",
    "href": "doc/microclimate_predictor_stack_commented.html",
    "title": "Microclimate Predictor Stack Tutorial",
    "section": "",
    "text": "1 Introduction\nThis tutorial documents the modular processing chain for deriving microclimate-relevant predictors from ALS (Airborne Laser Scanning) data.\nIt is based on the script 20_microclimate_predictor_stack.R, which builds a raster predictor stack used in microclimate or ecological modeling.\n\n\n\n2 1. Overall Workflow Diagram\n\n\n\n\n\nflowchart TD\n    LAS[\"LAS Input Data\"]\n    DEM[\"Normalize & Create DEM/DSM/CHM\"]\n    PM[\"Pixel-Level Metrics\"]\n    SEG[\"Tree Segmentation\"]\n\n    TOPO[\"Topographic Variables\"]\n    VOX[\"Voxel Metrics: VCI, LAD, Entropy\"]\n    LAD[\"LAD Profiles\"]\n    CLU[\"Tree Cluster Analysis\"]\n\n    MERGE[\"Merge: Predictor Stack\"]\n    OUT[\"Final Raster Predictor Stack\"]\n\n    LAS --&gt; DEM\n    LAS --&gt; PM\n    LAS --&gt; SEG\n\n    DEM --&gt; TOPO\n    PM --&gt; VOX\n    SEG --&gt; LAD\n    LAD --&gt; CLU\n\n    TOPO --&gt; MERGE\n    VOX --&gt; MERGE\n    CLU --&gt; MERGE\n\n    MERGE --&gt; OUT\n\n\n\n\n\n\nThis diagram shows the data flow:\n\nThe LAS file is used in 3 parallel branches.\nTopographic, voxel, and tree-based metrics are computed independently.\nFinally, all are merged into one raster predictor stack.\n\n\n\n\n3 2. Project Setup\n# Load required packages and environment\nrequire(envimaR)\nrequire(rprojroot)\n\n# Determine root directory of project (requires .Rproj or .here file)\nroot_folder &lt;- find_rstudio_root_file()\n\n# Load envrmt list with all folder paths and EPSG settings\nsource(file.path(root_folder, \"src/000-rspatial-setup.R\"), echo = TRUE)\n\nenvimaR handles dynamic folder structures.\nenvrmt contains paths like path_lidar_raster, path_topo, etc.\nepsg_number, bbox and other global spatial variables are set here.\n\n\n\n\n4 3. Normalizing the LAS Catalog\nctg &lt;- readLAScatalog(las_fileFN)\nctg_base &lt;- normalize_height(ctg, knnidw(k = 6L, p = 2))\n\nA LAS catalog is loaded and normalized.\nGround points are removed to prepare for CHM and DSM creation.\n\n\n\n\n5 4. Terrain Models\ndem &lt;- rasterize_terrain(ctg, res = 1, knnidw(k = 6L, p = 2))\ndsm &lt;- rasterize_canopy(ctg, res = 1, algorithm = pitfree())\nchm &lt;- rasterize_canopy(ctg_base, res = 1, pitfree(c(0,2,5,10,15)))\n\nDEM (Digital Elevation Model) is created from ground returns.\nDSM (Surface Model) and CHM (Canopy Height Model) from canopy points.\n\n\n\n\n6 5. Topographic Derivatives\nslope &lt;- terrain(dem, \"slope\")\naspect &lt;- terrain(dem, \"aspect\")\nTPI &lt;- terrain(dsm, \"TPI\")\n\nDerived terrain parameters used for modeling light, moisture, and temperature.\n\n\n\n\n7 6. Pixel-Level Metrics\npixel_stdmetrics &lt;- pixel_metrics(ctg_base, .stdmetrics, res = 1)\npixel_LAD &lt;- pixel_metrics(ctg_base, ~as.numeric(cv(LAD(Z, dz = 1, k = 0.87)$lad)), res = 1)\npixel_entropy &lt;- pixel_metrics(ctg_base, ~as.numeric(entropy(Z, by = 1.0)), res = 1)\npixel_VCI &lt;- pixel_metrics(ctg_base, ~as.numeric(VCI(Z, zmax = 40, by = 1.0)), res = 1)\nThese voxel-based metrics represent vertical structure:\n\nLAD = Leaf Area Density\nVCI = Vertical Complexity Index\nEntropy = point height diversity\nipground = intensity of ground points (optional)\n\n\n\n\n8 7. Tree Segmentation and Metrics\nctg_seg &lt;- segment_trees(ctg_base, li2012())\nhulls &lt;- catalog_apply(ctg_seg, tree_fn)\nlad_vox &lt;- lad.voxels(ctg_base, grain.size = 1, k = 0.87, maxP = 40)\n\nTrees are segmented using the Li et al.¬†(2012) method.\ntree_fn generates convex hulls or crown shapes.\nLAD profiles are voxelized and linked to hulls.\n\n\n\n\n9 8. Clustering Tree Profiles\nclust_model &lt;- KMeans_arma(data_clust, clusters = 10, n_iter = 500)\ntrees_lad$cluster &lt;- predict_KMeans(data_clust, clust_model)\n\nLAD metrics are dimensionally reduced (PCA or manually).\nClustering assigns structural class per tree.\nResult is written as vector layer and rasterized.\n\n\n\n\n10 9. Predictor Stack Creation\nforest_structure_metrics &lt;- c(rast(topoFN), rast(pmetricsFN), rast(tree_clus_rasFN))\nwriteRaster(forest_structure_metrics, predstack_forest_metricsFN, overwrite = TRUE)\n\nCombines topography, pixel metrics, and clusters into one multiband raster.\n\n\n\n\n11 10. Optional: Solar Irradiance via GRASS\nlinkGRASS7(dem, gisdbase = root_folder, location = \"MOF2\")\nexecGRASS(\"r.sun.hourly\", parameters = list(...))\n\nOptionally runs r.sun.hourly from GRASS to model solar radiation.\nResulting hourly radiation maps can be included in predictor stacks.\n\n\n\n\n12 Output Summary\n\n\n\n\n\n\n\n\nLayer\nType\nDescription\n\n\n\n\ntopo.tif\nRaster\nTerrain-derived variables\n\n\nall_pixel_metrics.tif\nRaster\nStructural voxel statistics\n\n\nlad_hull_raster.tif\nRaster\nLAD metrics aggregated to tree hulls\n\n\ntree_cluster.tif\nRaster\nCluster class per tree segment\n\n\npred_forest_structure.tif\nRaster\nFull predictor stack for modeling\n\n\ntrees_lad_clean.rds\nDataFrame\nTree-level statistics for analysis\n\n\n\n\n\n\n13 Questions or Extensions\n\nAdd modeling scripts (e.g.¬†Random Forest, GLM, XGBoost)\nVisualize clusters with tmap or leaflet\nCombine with microclimate sensors or UAV data"
  },
  {
    "objectID": "doc/evaluation.html",
    "href": "doc/evaluation.html",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "Understanding microclimatic and ecological processes at high spatial resolution requires integrated modeling approaches that couple atmospheric dynamics with plant and vegetation processes. The models compared here span a wide range of capabilities, from fluid dynamics solvers to ecophysiological simulators. This document introduces the evaluation criteria, explains the scoring approach, and provides literature references for further exploration.\n\n\nThis model comparison aims to evaluate and categorize existing modeling platforms that simulate atmosphere-vegetation interactions, emphasizing realistic deployment, dimensional and structural detail, and biophysical relevance. While many models offer advanced features in isolation, such as turbulence modeling, vegetation physiology, or 3D structural input, only a few integrate these capabilities in a usable and accessible way. This evaluation considers not only modeling power but also technical complexity, scientific maturity, and practical deployability.\n\nFull 3D support with high spatial resolution\nIntegration of real-world vegetation structure from TLS, QSM, or ALS\nExplicit representation of plant‚Äìatmosphere feedback (e.g., transpiration effects on local climate)\nAvailability of user interfaces, documentation, licensing, and feasibility on common research workstations\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"theme\": \"default\", \"themeVariables\": { \"fontSize\": \"9px\", \"nodePadding\": \"20\", \"width\": \"300\" }}}%%\ngraph TD\n    A[Model Evaluation]\n\n    A --&gt; C[Flag Classification]\n    C --&gt; C1[üü© High capability + usability&lt;br&gt;Score: 7.0‚Äì10.0&lt;br&gt;GUI, docs, user base]\n    C --&gt; C2[üüß High capability, low usability&lt;br&gt;Score: 7.0‚Äì10.0&lt;br&gt;Expert-only, low maturity]\n    C --&gt; C3[üü¶ Moderate & well-integrated&lt;br&gt;Score: 5.0‚Äì6.9&lt;br&gt;Lacks coupling, usable]\n    C --&gt; C4[üü® Specialized + usable&lt;br&gt;Score: 4.0‚Äì6.9&lt;br&gt;Limited scope, accessible]\n    C --&gt; C5[üü• Experimental / niche&lt;br&gt;Score: 4.0‚Äì6.9&lt;br&gt;Non-generalizable use]\n    C --&gt; C6[‚ùå Legacy / not usable&lt;br&gt;Any score&lt;br&gt;No dev, no workflow]\n    A --&gt; D[Microscale Applicability]\n    D --&gt; D1[‚úÖ Fully applicable&lt;br&gt;‚â§10‚ÄØm, 3D veg‚Äìair coupling]\n    D --&gt; D2[üü® Conditionally applicable&lt;br&gt;Partial 3D or physics]\n    D --&gt; D3[‚ùå Not applicable&lt;br&gt;Too\n coarse or schematic]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style C fill:#ccf\n    style D fill:#ffc\n    style C1 fill:#cfc\n    style C2 fill:#ffebcc\n    style C3 fill:#e0f0ff\n    style C4 fill:#ffffcc\n    style C5 fill:#ffe0e0\n    style C6 fill:#ddd\n    style D1 fill:#cfc\n    style D2 fill:#ffffcc\n    style D3 fill:#eee\n\n\n\n\n\n\n\n\n\n\n\n\nWhen selecting a suitable model for simulating interactions between the atmosphere and vegetation, more aspects than just scientific completeness must be taken into account in the context of operationalization. Models differ considerably in their structure, focus, technical maturity, and accessibility. What does this mean? Some models achieve excellent physical accuracy (e.g., LES-based turbulence and complete feedback between plants and the atmosphere) but require in-depth technical knowledge or high-performance computers. Other models, on the other hand, sacrifice physical completeness in favor of practicality and easy integration into planning or monitoring processes.\nOur attempt is to enable this multi-criteria assessment and make it comprehensible by means of an evaluation framework in order to arrive at a pre-selection. This is done by combining quantitative assessments with a qualitative classification system, in particular:\n\nscientific completeness based on various categories\noperational usability\n\nThe evaluation is based on clearly defined criteria such as model physics, plant physiology, plant structure, model dimensionality and scales, and user-friendliness. However, the relative weights reflect value-based assessments ‚Äì what is considered more important depends on the context (urban planning vs.¬†ecohydrology vs.¬†forest micrometeorology). In concrete terms, this means:\n\nIn urban planning, user-friendliness and realistic 3D air flows may be paramount.\nIn plant science, biophysics and physiology may be paramount.\nIn forestry, compatibility with TLS or QSM inputs may be required.\n\nThis is not a weakness, but a strength, as it allows adaptation to the user‚Äôs goals ‚Äì as long as the weighting and criteria are transparent.\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion\nWeight\nSub-Capabilities / Description\nScoring Guidelines\n\n\n\n\nAtmosphere\n3.0\nLES/RANS, radiative transfer, soil‚Äìvegetation coupling\n1.5‚Äì3.0: Full LES or RANS / radiation / soil 0.6‚Äì1.4: Partial (e.g., radiation only) &lt; 0.6: Basic or missing physics\n\n\nStructure\n1.0\nRealistic vegetation structure (e.g., QSM/LAD, voxel, TLS-derived)\n0.8‚Äì1.0: Full 3D voxel/QSM/tree geometry 0.4‚Äì0.7: Schematic trees &lt; 0.4: No or empirical structure\n\n\nFeedback\n1.0\nBiophysical feedback transpiration ‚ÜîÔ∏é air\n0.8‚Äì1.0: Full coupling 0.4‚Äì0.7: Drag or partial interaction &lt; 0.4: One-way/static\n\n\nPhysiology\n1.0\nTranspiration, photosynthesis, stomata, water flow\n0.8‚Äì1.0: Full physiology 0.4‚Äì0.7: Simplified &lt; 0.4: None\n\n\nUsability\n2.0\nGUI/CLI, documentation, install, license, hardware\n1.5‚Äì2.0: Documented, user-friendly 0.6‚Äì1.4: CLI/complex &lt; 0.6: Legacy/unusable\n\n\n3D\n2.0\nFull 3D resolution and within-canopy gradients\n1.0‚Äì1.9: Full 3D 0.6‚Äì0.9: Pseudo-3D 0.3‚Äì0.5: Layered &lt; 0.3: None\n\n\n\n\n\n\n\nMicroscale applicable models can resolve processes on spatial scales of ‚â§ 10 m. At this scale, air flows, radiation, and microclimate dynamics become relevant at the tree level. These models are typically characterized by the following features:\n\nThey work with high-resolution 3D grids.\nVegetation is explicitly represented (e.g., voxel- or TLS-based).\nLocalized simulations of plots, tree groups, or urban areas are possible.\n\nMicroscale capability is essential for LiDAR-based modeling, urban forestry, and the investigation of microclimates in tree canopies.\n\n\n\n\n\n\n\n\nSymbol\nMicroscale Capability Description\n\n\n\n\n‚úÖ\nFully applicable: Designed for a resolution of ‚â§‚ÄØ10‚ÄØm with 3D vegetation‚Äìatmosphere coupling.\n\n\nüü®\nConditionally applicable: Partial support for high resolutions, but limited physics or geometry.\n\n\n‚ùå\nNot applicable: Coarse resolution or missing spatial details.\n\n\n\n\nThe following characteristics are flagged with an ‚ùå for experimental or obsolete models:\n\nno longer maintained or widely used.\nthey were developed for niche applications or obsolete use cases.\nthere is a complete lack of user-friendly workflows or adequate documentation.\n\nThis leads to the following classification scheme:\n\n\n\n\n\n\n\n\n\n\nFlag\nLabel\nImplied Score\nExplanation¬†of¬†the¬†Classification\n\n\n\n\nüü©\nHigh capability, high usability\n7.0‚Äì10.0\nFully featured and deployable with reasonable effort (GUI, docs, user base)\n\n\nüüß\nHigh capability, low usability\n7.0‚Äì10.0\nPowerful but difficult to use; expert-only setup, low maturity\n\n\nüü¶\nModerate capability, well-integrated\n5.0‚Äì6.9\nSolid for many tasks; lacks advanced coupling but usable and balanced\n\n\nüü®\nSpecialized model, high usability\n4.0‚Äì6.9\nLimited scope (e.g.¬†radiation only), but very accessible and documented\n\n\nüü•\nExperimental or niche\n4.0‚Äì6.9\nLimited audience or non-generalizable application\n\n\n‚ùå\nLegacy/unmaintained/ not usable\nany\nNo active development or practical use case today\n\n\n\n\nNote: This classification does not always correspond to the ranking by score, which is intentional. For example, a model with a high score may still be marked with üüß or ‚ùå if it is technically difficult to implement, is not documented or maintained, or is simply no longer available. This helps to put the pure scoring performance into perspective, which would otherwise lead to the selection of models that prove to be unusable in practice.\n\n\n\n\nFifteen models were systematically evaluated based on the assessment framework presented above. The models were selected on an exploratory basis using Google searches, specialist literature (e.g., GMD Geoscientific Model Development, ScienceDirect), well-known model comparisons, and open-source repositories. The selection is therefore well-founded but not entirely systematic. The following tables shows the results of this evaluation. It not only shows the weighted overall score, but also differentiates between the underlying individual criteria. In addition, the applicability in the microscale range is indicated and each model is classified using a color-coded classification system. This makes the performance of a model in terms of the atmosphere-vegetation coupling transparent and shows the extent to which a model can be realistically integrated into scientific or operational processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nScore\nAtmosphere¬†Physics\nStructure\nFeedback\nPhysiology\nUsability\n3D\nMicroscale¬†Capabilities\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0Full LES and radiative transfer; no soil‚Äìwater coupling\n0.8Static 3D vegetation model\n0.7Air‚Äìvegetation drag interaction\n0.3No explicit physiology\n0.4Complex install, Linux only; well documented\n1.0Fully resolved CFD\nLES solver at meter-scale; used in urban microclimate studies &lt;10‚ÄØm; limited physiology, strong flow‚Äìstructure resolution\nüüß\nüü©\n\n\n2\nMuSICA\n7.4\n0.8Soil‚Äìplant-atmosphere exchange; no LES or radiative transfer\n0.6Layered cohort model, not voxel-based\n1.0Detailed biophysical feedback\n1.0Includes transpiration, photosynthesis, stomata, water dynamics\n0.3Legacy Fortran, hard to install\n1.01D canopy model\netailed canopy and physiology; vertical 1D, not voxel; grid spacing cohort-based\nüü• ‚ùå\nüü®\n\n\n3\nOpenFOAM\n7.3\n2.5LES/RANS CFD; partial radiation support\n1.0Porosity/drag approach for tree structure\n0.5Customizable feedback via coding\n0.0No vegetation physiology\n0.2Expert use only, CLI\n1.9Full 3D CFD\nCFD model with &lt;1‚ÄØm resolution; porosity drag; physiology via coding\nüüß\nüü©\n\n\n4\nENVI-met\n6.9\n0.8RANS turbulence and radiation; no soil coupling\n0.6Blocky trees, parametric structure\n0.4Basic one-way coupling\n0.3Simplified energy‚Äìwater exchange\n0.6GUI, documented, PC-compatible\n1.0Pseudo-3D (layered)\nGrid 0.5‚Äì2‚ÄØm; urban canopy focus; simplified structure\nüü©\nüü©\n\n\n5\nWRF-Urban\n6.5\n0.9Urban-scale RANS + radiation; coarse resolution\n0.7Urban and vegetation layering\n0.6Bulk vegetation‚Äìatmosphere interactions\n0.2No individual physiology model\n0.3HPC-heavy, complex setup\n1.0Grid-based, some canopy effects\nUrban RANS, VEGE3D coupling; no true &lt;10‚ÄØm flow+veg\nüüß\nüü®\n\n\n6\nForestED\n6.1\n0.9Radiation balance only\n0.8TLS-derived trees, but limited structural detail\n0.5Weak air interaction\n0.3No detailed physiology\n0.4Prototype, no GUI\n1.0Real 3D from TLS\nFull 3D via TLS; radiation only, no flow coupling\nüü• ‚ùå\nüü©\n\n\n7\nDART\n5.7\n0.6Radiative transfer simulation, no air dynamics\n1.0Voxel-based structural import\n0.0No air‚Äìplant feedback\n0.2No physiology\n0.3Complex setup, technical barrier\n1.0Radiative 3D\nRadiative voxel model &lt;1‚ÄØm; no airflow or feedback\nüü• ‚ùå\nüü©\n\n\n8\nED2\n5.6\n0.7Surface energy and hydrology; no LES\n0.5Functional cohort-based\n0.6Partial feedback, not dynamic\n1.0Rich physiology, plant hydraulics\n0.4Command-line only, heavy model\n0.5Vertical layers, no 3D\nCohort-based; no individual trees or microclimate\nüü¶\n‚ùå\n\n\n9\nMAESPA\n5.3\n0.4No LES or full RANS\n0.5Elliptic crown geometries\n0.5Simple coupling (transpiration ‚ÜîÔ∏é air temp)\n1.0Includes water and stomatal response\n0.4CLI, old Fortran\n0.8Layered or semi-3D\nTree-level radiation, no fluid; stand-scale design\nüü¶\n‚ùå\n\n\n10\nPyDOM\n5.0\n0.5Solar irradiance modeling using discrete ordinates method; no fluid dynamics\n0.6Uses simplified canopy layers or volumes; structure inferred\n0.0No biophysical feedback\n0.3No physiology model\n0.5Script-based usage; moderately usable\n1.0Volumetric but low-resolution\nVoxelized solar DOM; no air coupling\nüü® ‚ùå\nüü®\n\n\n11\nCOMOKIT\n4.9\n0.4No atmosphere simulation; only agent-level heat/energy accounting\n0.3Simplified static vegetation\n0.5Agent-based feedback loops via scenario definition\n0.5No continuous transpiration or photosynthesis, only thermal behavior\n0.7Accessible GUI, easy scenario logic, extensive documentation\n0.5Visual pseudo-3D, no physical gradients\nAgent-based; no physical coupling; coarse graphics\nüü®\n‚ùå\n\n\n12\nLPJ-GUESS\n4.4\n0.7Energy and gas exchange with climate integration; no internal 3D resolution or LES\n0.4Functional PFTs with vertical profiles, no explicit geometry\n0.4Climate‚Äìvegetation coupling, but coarse\n0.9Complex physiology model with stomatal control, photosynthesis\n0.3CLI-based ecosystem model, config-heavy\n0.0No 3D, grid-cell aggregated PFT composition\nDGVM, no 3D, coarse PFT representation\nüü¶ ‚ùå\n‚ùå\n\n\n13\nMicroclimc\n4.2\n0.6Radiative energy balance and temperature with simple terrain effects; no CFD or LES\n0.3Schematic trees only, no voxel or lidar structure\n0.4One-way: vegetation affects energy balance, no feedback from air\n0.4Simple transpiration and energy fluxes only\n0.8R-based, documented, GUI-like interface\n0.5Layered canopy modules, semi-3D\n1‚Äì5‚ÄØm radiation/temp; schematic trees; no LES\nüü®\nüü®\n\n\n14\niTREETools\n3.1\n0.3No atmosphere model; static inventory system\n0.2Tree inventory tables only; no geometry\n0.2None; no feedback, no fluxes\n0.0No physiology modeling\n0.9Very accessible GUI, well supported\n0.0No 3D; inventory only\nEmpirical inventory; no spatial simulation\nüü® ‚ùå\n‚ùå\n\n\n15\nFluspect\n1.9\n0.1Leaf-scale radiative simulation; no atmosphere\n0.0No spatial structure\n0.0None\n1.0Detailed leaf spectral and biochemical simulation\n0.3Niche tool, standalone use; requires integration\n0.0No 3D; single-leaf model\nLeaf-level only; no domain or airflow\nüü• ‚ùå\n‚ùå\n\n\n\n\nBased on the upper table, the below graph helps visualize the trade-off between model capability and usability, making the multi-dimensional classification system intuitively accessible at a glance.\n\n\n\nModel usability vs.¬†total score across classified microclimate models. The inverse relationship reflects a common trade-off: high-performing models (right) often require expert-level setup (low usability, bottom), while user-friendly models (top) tend to be simplified. Colored points reflect model classification: üü© usable and capable, üüß powerful but complex, üü¶ balanced, üü® specialized, and üü• experimental. Models above the trend line (e.g., ENVI-met) offer better usability than expected for their score; those below (e.g., MuSICA) require disproportionately high effort.\n\n\n\n\n\nIf we narrow the selection by removing models that are either classified as legacy systems (‚ùå ) or that lack both microscale applicability (‚ùå) and fully resolved 3D spatial representation (&lt;1.0), the set of viable modeling platforms is drastically reduced. This filtering excludes tools that are either outdated, lack dimensional realism, or are designed for coarse-scale applications incompatible with high-resolution vegetation‚Äìatmosphere modeling. What remains is a focused set of platforms that combine scientific robustness with operational feasibility for modeling processes at the tree or plot level. These remaining models offer realistic support for implementation in urban microclimate design, LiDAR-informed ecological studies, and vegetation-based climate adaptation strategies where 3D feedbacks and spatial structure matter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nScore\nAtmosphere\nStructure\nFeedback\nPhysiology\nUsability\n3D\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0 ‚Äì Full LES, radiation, no soil\n0.8 ‚Äì Static vegetation models\n0.7 ‚Äì Basic interaction\n0.3 ‚Äì No physiology\n0.4 ‚Äì Complex setup, Linux only, docs\n1.0 ‚Äì True 3D\nüüß\nüü©\n\n\n2\nOpenFOAM\n7.3\n2.5 ‚Äì Full LES/RANS, partial radiation\n1.0 ‚Äì Porosity/drag approach\n0.5 ‚Äì Feedback via coding\n0.0 ‚Äì None\n0.2 ‚Äì CLI, expert only\n1.9 ‚Äì Full CFD\nüüß\nüü©\n\n\n3\nENVI-met\n6.9\n0.8 ‚Äì RANS, radiation\n0.6 ‚Äì Block trees only\n0.4 ‚Äì Weak one-way coupling\n0.3 ‚Äì Simplified transpiration\n0.6 ‚Äì GUI, docs, runs on PC\n1.0 ‚Äì Pseudo-3D layering\nüü©\nüü©\n\n\n4\nWRF-Urban\n6.5\n0.9 ‚Äì RANS, radiation\n0.7 ‚Äì Layered urban/vegetation\n0.6 ‚Äì Bulk interaction\n0.2 ‚Äì None\n0.3 ‚Äì HPC, not easily usable\n1.0 ‚Äì Grid-based\nüüß\nüü®\n\n\n5\nMicroclimc\n4.2\n0.6 ‚Äì Radiation and temp model, no LES\n0.3 ‚Äì Schematic trees\n0.4 ‚Äì Indirect surface coupling\n0.4 ‚Äì Empirical transpiration\n0.8 ‚Äì GUI, documentation, R integration\n0.5 ‚Äì Semi-3D canopy layer\nüü®\nüü®\n\n\n\nSorting applied:\nPrimary: Microscale applicability (‚úÖ &gt; üü® &gt; ‚ùå)\nSecondary: Total Score (descending)\n\n\n\n\n\nto be completed\nENVI-met\n\nBruse, M., & Fleer, H. (1998). Simulating surface‚Äìplant‚Äìair interactions inside urban environments with a three-dimensional numerical model. Environmental Modelling & Software, 13(3‚Äì4), 373‚Äì384.\nENVI-met Documentation: https://envi-met.info/\n\nPALM-4U\n\nMaronga, B., et al.¬†(2020). Overview of the PALM model system 6.0. Geoscientific Model Development, 13, 1335‚Äì1372. https://doi.org/10.5194/gmd-13-1335-2020\nhttps://palm-model.org/\n\nMuSICA\n\nOg√©e, J., et al.¬†(2003). MuSICA, a CO2, water and energy multilayer, multileaf model for the analysis of function of vegetation at the canopy scale. Ecological Modelling, 156(2‚Äì3), 181‚Äì204.\n\nOpenFOAM (custom vegetation)\n\nGromke, C., & Blocken, B. (2015). CFD simulation of near-field pollutant dispersion including vegetation effects. Atmospheric Environment, 100, 238‚Äì249.\nThe OpenFOAM Foundation Hom\n\nWRF-Urban\n\nChen, F., Yu, B., Wu, M., Yang, X., et‚ÄØal.¬†(2021). Improved urban finescale forecasting during a heat wave by using high-resolution urban canopy parameters. Frontiers in Climate, 3, 771441. https://doi.org/10.3389/fclim.2021.771441\nMartilli, A., Nazarian, N., Krayenhoff, E.‚ÄØS., Lachapelle, J., Lu, J., Rivas, E., Rodriguez‚ÄëSanchez, A., Sanchez, B., & Santiago, J.‚ÄØL. (2024). WRF‚ÄëComfort: Simulating microscale variability in outdoor heat stress at the city scale with a mesoscale model. Geoscientific Model Development, 17, 5023‚Äì5039. https://doi.org/10.5194/gmd-17-5023-2024",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#objective-of-the-evaluation",
    "href": "doc/evaluation.html#objective-of-the-evaluation",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "This model comparison aims to evaluate and categorize existing modeling platforms that simulate atmosphere-vegetation interactions, emphasizing realistic deployment, dimensional and structural detail, and biophysical relevance. While many models offer advanced features in isolation, such as turbulence modeling, vegetation physiology, or 3D structural input, only a few integrate these capabilities in a usable and accessible way. This evaluation considers not only modeling power but also technical complexity, scientific maturity, and practical deployability.\n\nFull 3D support with high spatial resolution\nIntegration of real-world vegetation structure from TLS, QSM, or ALS\nExplicit representation of plant‚Äìatmosphere feedback (e.g., transpiration effects on local climate)\nAvailability of user interfaces, documentation, licensing, and feasibility on common research workstations",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#model-evaluation-structure",
    "href": "doc/evaluation.html#model-evaluation-structure",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "%%{init: {\"theme\": \"default\", \"themeVariables\": { \"fontSize\": \"9px\", \"nodePadding\": \"20\", \"width\": \"300\" }}}%%\ngraph TD\n    A[Model Evaluation]\n\n    A --&gt; C[Flag Classification]\n    C --&gt; C1[üü© High capability + usability&lt;br&gt;Score: 7.0‚Äì10.0&lt;br&gt;GUI, docs, user base]\n    C --&gt; C2[üüß High capability, low usability&lt;br&gt;Score: 7.0‚Äì10.0&lt;br&gt;Expert-only, low maturity]\n    C --&gt; C3[üü¶ Moderate & well-integrated&lt;br&gt;Score: 5.0‚Äì6.9&lt;br&gt;Lacks coupling, usable]\n    C --&gt; C4[üü® Specialized + usable&lt;br&gt;Score: 4.0‚Äì6.9&lt;br&gt;Limited scope, accessible]\n    C --&gt; C5[üü• Experimental / niche&lt;br&gt;Score: 4.0‚Äì6.9&lt;br&gt;Non-generalizable use]\n    C --&gt; C6[‚ùå Legacy / not usable&lt;br&gt;Any score&lt;br&gt;No dev, no workflow]\n    A --&gt; D[Microscale Applicability]\n    D --&gt; D1[‚úÖ Fully applicable&lt;br&gt;‚â§10‚ÄØm, 3D veg‚Äìair coupling]\n    D --&gt; D2[üü® Conditionally applicable&lt;br&gt;Partial 3D or physics]\n    D --&gt; D3[‚ùå Not applicable&lt;br&gt;Too\n coarse or schematic]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style C fill:#ccf\n    style D fill:#ffc\n    style C1 fill:#cfc\n    style C2 fill:#ffebcc\n    style C3 fill:#e0f0ff\n    style C4 fill:#ffffcc\n    style C5 fill:#ffe0e0\n    style C6 fill:#ddd\n    style D1 fill:#cfc\n    style D2 fill:#ffffcc\n    style D3 fill:#eee",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#the-evaluation-framework",
    "href": "doc/evaluation.html#the-evaluation-framework",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "When selecting a suitable model for simulating interactions between the atmosphere and vegetation, more aspects than just scientific completeness must be taken into account in the context of operationalization. Models differ considerably in their structure, focus, technical maturity, and accessibility. What does this mean? Some models achieve excellent physical accuracy (e.g., LES-based turbulence and complete feedback between plants and the atmosphere) but require in-depth technical knowledge or high-performance computers. Other models, on the other hand, sacrifice physical completeness in favor of practicality and easy integration into planning or monitoring processes.\nOur attempt is to enable this multi-criteria assessment and make it comprehensible by means of an evaluation framework in order to arrive at a pre-selection. This is done by combining quantitative assessments with a qualitative classification system, in particular:\n\nscientific completeness based on various categories\noperational usability\n\nThe evaluation is based on clearly defined criteria such as model physics, plant physiology, plant structure, model dimensionality and scales, and user-friendliness. However, the relative weights reflect value-based assessments ‚Äì what is considered more important depends on the context (urban planning vs.¬†ecohydrology vs.¬†forest micrometeorology). In concrete terms, this means:\n\nIn urban planning, user-friendliness and realistic 3D air flows may be paramount.\nIn plant science, biophysics and physiology may be paramount.\nIn forestry, compatibility with TLS or QSM inputs may be required.\n\nThis is not a weakness, but a strength, as it allows adaptation to the user‚Äôs goals ‚Äì as long as the weighting and criteria are transparent.\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion\nWeight\nSub-Capabilities / Description\nScoring Guidelines\n\n\n\n\nAtmosphere\n3.0\nLES/RANS, radiative transfer, soil‚Äìvegetation coupling\n1.5‚Äì3.0: Full LES or RANS / radiation / soil 0.6‚Äì1.4: Partial (e.g., radiation only) &lt; 0.6: Basic or missing physics\n\n\nStructure\n1.0\nRealistic vegetation structure (e.g., QSM/LAD, voxel, TLS-derived)\n0.8‚Äì1.0: Full 3D voxel/QSM/tree geometry 0.4‚Äì0.7: Schematic trees &lt; 0.4: No or empirical structure\n\n\nFeedback\n1.0\nBiophysical feedback transpiration ‚ÜîÔ∏é air\n0.8‚Äì1.0: Full coupling 0.4‚Äì0.7: Drag or partial interaction &lt; 0.4: One-way/static\n\n\nPhysiology\n1.0\nTranspiration, photosynthesis, stomata, water flow\n0.8‚Äì1.0: Full physiology 0.4‚Äì0.7: Simplified &lt; 0.4: None\n\n\nUsability\n2.0\nGUI/CLI, documentation, install, license, hardware\n1.5‚Äì2.0: Documented, user-friendly 0.6‚Äì1.4: CLI/complex &lt; 0.6: Legacy/unusable\n\n\n3D\n2.0\nFull 3D resolution and within-canopy gradients\n1.0‚Äì1.9: Full 3D 0.6‚Äì0.9: Pseudo-3D 0.3‚Äì0.5: Layered &lt; 0.3: None\n\n\n\n\n\n\n\nMicroscale applicable models can resolve processes on spatial scales of ‚â§ 10 m. At this scale, air flows, radiation, and microclimate dynamics become relevant at the tree level. These models are typically characterized by the following features:\n\nThey work with high-resolution 3D grids.\nVegetation is explicitly represented (e.g., voxel- or TLS-based).\nLocalized simulations of plots, tree groups, or urban areas are possible.\n\nMicroscale capability is essential for LiDAR-based modeling, urban forestry, and the investigation of microclimates in tree canopies.\n\n\n\n\n\n\n\n\nSymbol\nMicroscale Capability Description\n\n\n\n\n‚úÖ\nFully applicable: Designed for a resolution of ‚â§‚ÄØ10‚ÄØm with 3D vegetation‚Äìatmosphere coupling.\n\n\nüü®\nConditionally applicable: Partial support for high resolutions, but limited physics or geometry.\n\n\n‚ùå\nNot applicable: Coarse resolution or missing spatial details.\n\n\n\n\nThe following characteristics are flagged with an ‚ùå for experimental or obsolete models:\n\nno longer maintained or widely used.\nthey were developed for niche applications or obsolete use cases.\nthere is a complete lack of user-friendly workflows or adequate documentation.\n\nThis leads to the following classification scheme:\n\n\n\n\n\n\n\n\n\n\nFlag\nLabel\nImplied Score\nExplanation¬†of¬†the¬†Classification\n\n\n\n\nüü©\nHigh capability, high usability\n7.0‚Äì10.0\nFully featured and deployable with reasonable effort (GUI, docs, user base)\n\n\nüüß\nHigh capability, low usability\n7.0‚Äì10.0\nPowerful but difficult to use; expert-only setup, low maturity\n\n\nüü¶\nModerate capability, well-integrated\n5.0‚Äì6.9\nSolid for many tasks; lacks advanced coupling but usable and balanced\n\n\nüü®\nSpecialized model, high usability\n4.0‚Äì6.9\nLimited scope (e.g.¬†radiation only), but very accessible and documented\n\n\nüü•\nExperimental or niche\n4.0‚Äì6.9\nLimited audience or non-generalizable application\n\n\n‚ùå\nLegacy/unmaintained/ not usable\nany\nNo active development or practical use case today\n\n\n\n\nNote: This classification does not always correspond to the ranking by score, which is intentional. For example, a model with a high score may still be marked with üüß or ‚ùå if it is technically difficult to implement, is not documented or maintained, or is simply no longer available. This helps to put the pure scoring performance into perspective, which would otherwise lead to the selection of models that prove to be unusable in practice.",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#atmospherevegetation-model-comparison-of-models",
    "href": "doc/evaluation.html#atmospherevegetation-model-comparison-of-models",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "Fifteen models were systematically evaluated based on the assessment framework presented above. The models were selected on an exploratory basis using Google searches, specialist literature (e.g., GMD Geoscientific Model Development, ScienceDirect), well-known model comparisons, and open-source repositories. The selection is therefore well-founded but not entirely systematic. The following tables shows the results of this evaluation. It not only shows the weighted overall score, but also differentiates between the underlying individual criteria. In addition, the applicability in the microscale range is indicated and each model is classified using a color-coded classification system. This makes the performance of a model in terms of the atmosphere-vegetation coupling transparent and shows the extent to which a model can be realistically integrated into scientific or operational processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nScore\nAtmosphere¬†Physics\nStructure\nFeedback\nPhysiology\nUsability\n3D\nMicroscale¬†Capabilities\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0Full LES and radiative transfer; no soil‚Äìwater coupling\n0.8Static 3D vegetation model\n0.7Air‚Äìvegetation drag interaction\n0.3No explicit physiology\n0.4Complex install, Linux only; well documented\n1.0Fully resolved CFD\nLES solver at meter-scale; used in urban microclimate studies &lt;10‚ÄØm; limited physiology, strong flow‚Äìstructure resolution\nüüß\nüü©\n\n\n2\nMuSICA\n7.4\n0.8Soil‚Äìplant-atmosphere exchange; no LES or radiative transfer\n0.6Layered cohort model, not voxel-based\n1.0Detailed biophysical feedback\n1.0Includes transpiration, photosynthesis, stomata, water dynamics\n0.3Legacy Fortran, hard to install\n1.01D canopy model\netailed canopy and physiology; vertical 1D, not voxel; grid spacing cohort-based\nüü• ‚ùå\nüü®\n\n\n3\nOpenFOAM\n7.3\n2.5LES/RANS CFD; partial radiation support\n1.0Porosity/drag approach for tree structure\n0.5Customizable feedback via coding\n0.0No vegetation physiology\n0.2Expert use only, CLI\n1.9Full 3D CFD\nCFD model with &lt;1‚ÄØm resolution; porosity drag; physiology via coding\nüüß\nüü©\n\n\n4\nENVI-met\n6.9\n0.8RANS turbulence and radiation; no soil coupling\n0.6Blocky trees, parametric structure\n0.4Basic one-way coupling\n0.3Simplified energy‚Äìwater exchange\n0.6GUI, documented, PC-compatible\n1.0Pseudo-3D (layered)\nGrid 0.5‚Äì2‚ÄØm; urban canopy focus; simplified structure\nüü©\nüü©\n\n\n5\nWRF-Urban\n6.5\n0.9Urban-scale RANS + radiation; coarse resolution\n0.7Urban and vegetation layering\n0.6Bulk vegetation‚Äìatmosphere interactions\n0.2No individual physiology model\n0.3HPC-heavy, complex setup\n1.0Grid-based, some canopy effects\nUrban RANS, VEGE3D coupling; no true &lt;10‚ÄØm flow+veg\nüüß\nüü®\n\n\n6\nForestED\n6.1\n0.9Radiation balance only\n0.8TLS-derived trees, but limited structural detail\n0.5Weak air interaction\n0.3No detailed physiology\n0.4Prototype, no GUI\n1.0Real 3D from TLS\nFull 3D via TLS; radiation only, no flow coupling\nüü• ‚ùå\nüü©\n\n\n7\nDART\n5.7\n0.6Radiative transfer simulation, no air dynamics\n1.0Voxel-based structural import\n0.0No air‚Äìplant feedback\n0.2No physiology\n0.3Complex setup, technical barrier\n1.0Radiative 3D\nRadiative voxel model &lt;1‚ÄØm; no airflow or feedback\nüü• ‚ùå\nüü©\n\n\n8\nED2\n5.6\n0.7Surface energy and hydrology; no LES\n0.5Functional cohort-based\n0.6Partial feedback, not dynamic\n1.0Rich physiology, plant hydraulics\n0.4Command-line only, heavy model\n0.5Vertical layers, no 3D\nCohort-based; no individual trees or microclimate\nüü¶\n‚ùå\n\n\n9\nMAESPA\n5.3\n0.4No LES or full RANS\n0.5Elliptic crown geometries\n0.5Simple coupling (transpiration ‚ÜîÔ∏é air temp)\n1.0Includes water and stomatal response\n0.4CLI, old Fortran\n0.8Layered or semi-3D\nTree-level radiation, no fluid; stand-scale design\nüü¶\n‚ùå\n\n\n10\nPyDOM\n5.0\n0.5Solar irradiance modeling using discrete ordinates method; no fluid dynamics\n0.6Uses simplified canopy layers or volumes; structure inferred\n0.0No biophysical feedback\n0.3No physiology model\n0.5Script-based usage; moderately usable\n1.0Volumetric but low-resolution\nVoxelized solar DOM; no air coupling\nüü® ‚ùå\nüü®\n\n\n11\nCOMOKIT\n4.9\n0.4No atmosphere simulation; only agent-level heat/energy accounting\n0.3Simplified static vegetation\n0.5Agent-based feedback loops via scenario definition\n0.5No continuous transpiration or photosynthesis, only thermal behavior\n0.7Accessible GUI, easy scenario logic, extensive documentation\n0.5Visual pseudo-3D, no physical gradients\nAgent-based; no physical coupling; coarse graphics\nüü®\n‚ùå\n\n\n12\nLPJ-GUESS\n4.4\n0.7Energy and gas exchange with climate integration; no internal 3D resolution or LES\n0.4Functional PFTs with vertical profiles, no explicit geometry\n0.4Climate‚Äìvegetation coupling, but coarse\n0.9Complex physiology model with stomatal control, photosynthesis\n0.3CLI-based ecosystem model, config-heavy\n0.0No 3D, grid-cell aggregated PFT composition\nDGVM, no 3D, coarse PFT representation\nüü¶ ‚ùå\n‚ùå\n\n\n13\nMicroclimc\n4.2\n0.6Radiative energy balance and temperature with simple terrain effects; no CFD or LES\n0.3Schematic trees only, no voxel or lidar structure\n0.4One-way: vegetation affects energy balance, no feedback from air\n0.4Simple transpiration and energy fluxes only\n0.8R-based, documented, GUI-like interface\n0.5Layered canopy modules, semi-3D\n1‚Äì5‚ÄØm radiation/temp; schematic trees; no LES\nüü®\nüü®\n\n\n14\niTREETools\n3.1\n0.3No atmosphere model; static inventory system\n0.2Tree inventory tables only; no geometry\n0.2None; no feedback, no fluxes\n0.0No physiology modeling\n0.9Very accessible GUI, well supported\n0.0No 3D; inventory only\nEmpirical inventory; no spatial simulation\nüü® ‚ùå\n‚ùå\n\n\n15\nFluspect\n1.9\n0.1Leaf-scale radiative simulation; no atmosphere\n0.0No spatial structure\n0.0None\n1.0Detailed leaf spectral and biochemical simulation\n0.3Niche tool, standalone use; requires integration\n0.0No 3D; single-leaf model\nLeaf-level only; no domain or airflow\nüü• ‚ùå\n‚ùå\n\n\n\n\nBased on the upper table, the below graph helps visualize the trade-off between model capability and usability, making the multi-dimensional classification system intuitively accessible at a glance.\n\n\n\nModel usability vs.¬†total score across classified microclimate models. The inverse relationship reflects a common trade-off: high-performing models (right) often require expert-level setup (low usability, bottom), while user-friendly models (top) tend to be simplified. Colored points reflect model classification: üü© usable and capable, üüß powerful but complex, üü¶ balanced, üü® specialized, and üü• experimental. Models above the trend line (e.g., ENVI-met) offer better usability than expected for their score; those below (e.g., MuSICA) require disproportionately high effort.\n\n\n\n\n\nIf we narrow the selection by removing models that are either classified as legacy systems (‚ùå ) or that lack both microscale applicability (‚ùå) and fully resolved 3D spatial representation (&lt;1.0), the set of viable modeling platforms is drastically reduced. This filtering excludes tools that are either outdated, lack dimensional realism, or are designed for coarse-scale applications incompatible with high-resolution vegetation‚Äìatmosphere modeling. What remains is a focused set of platforms that combine scientific robustness with operational feasibility for modeling processes at the tree or plot level. These remaining models offer realistic support for implementation in urban microclimate design, LiDAR-informed ecological studies, and vegetation-based climate adaptation strategies where 3D feedbacks and spatial structure matter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nScore\nAtmosphere\nStructure\nFeedback\nPhysiology\nUsability\n3D\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0 ‚Äì Full LES, radiation, no soil\n0.8 ‚Äì Static vegetation models\n0.7 ‚Äì Basic interaction\n0.3 ‚Äì No physiology\n0.4 ‚Äì Complex setup, Linux only, docs\n1.0 ‚Äì True 3D\nüüß\nüü©\n\n\n2\nOpenFOAM\n7.3\n2.5 ‚Äì Full LES/RANS, partial radiation\n1.0 ‚Äì Porosity/drag approach\n0.5 ‚Äì Feedback via coding\n0.0 ‚Äì None\n0.2 ‚Äì CLI, expert only\n1.9 ‚Äì Full CFD\nüüß\nüü©\n\n\n3\nENVI-met\n6.9\n0.8 ‚Äì RANS, radiation\n0.6 ‚Äì Block trees only\n0.4 ‚Äì Weak one-way coupling\n0.3 ‚Äì Simplified transpiration\n0.6 ‚Äì GUI, docs, runs on PC\n1.0 ‚Äì Pseudo-3D layering\nüü©\nüü©\n\n\n4\nWRF-Urban\n6.5\n0.9 ‚Äì RANS, radiation\n0.7 ‚Äì Layered urban/vegetation\n0.6 ‚Äì Bulk interaction\n0.2 ‚Äì None\n0.3 ‚Äì HPC, not easily usable\n1.0 ‚Äì Grid-based\nüüß\nüü®\n\n\n5\nMicroclimc\n4.2\n0.6 ‚Äì Radiation and temp model, no LES\n0.3 ‚Äì Schematic trees\n0.4 ‚Äì Indirect surface coupling\n0.4 ‚Äì Empirical transpiration\n0.8 ‚Äì GUI, documentation, R integration\n0.5 ‚Äì Semi-3D canopy layer\nüü®\nüü®\n\n\n\nSorting applied:\nPrimary: Microscale applicability (‚úÖ &gt; üü® &gt; ‚ùå)\nSecondary: Total Score (descending)",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#literature-and-sources-by-model",
    "href": "doc/evaluation.html#literature-and-sources-by-model",
    "title": "Evaluation of Atmosphere‚ÄìVegetation Interaction Models",
    "section": "",
    "text": "to be completed\nENVI-met\n\nBruse, M., & Fleer, H. (1998). Simulating surface‚Äìplant‚Äìair interactions inside urban environments with a three-dimensional numerical model. Environmental Modelling & Software, 13(3‚Äì4), 373‚Äì384.\nENVI-met Documentation: https://envi-met.info/\n\nPALM-4U\n\nMaronga, B., et al.¬†(2020). Overview of the PALM model system 6.0. Geoscientific Model Development, 13, 1335‚Äì1372. https://doi.org/10.5194/gmd-13-1335-2020\nhttps://palm-model.org/\n\nMuSICA\n\nOg√©e, J., et al.¬†(2003). MuSICA, a CO2, water and energy multilayer, multileaf model for the analysis of function of vegetation at the canopy scale. Ecological Modelling, 156(2‚Äì3), 181‚Äì204.\n\nOpenFOAM (custom vegetation)\n\nGromke, C., & Blocken, B. (2015). CFD simulation of near-field pollutant dispersion including vegetation effects. Atmospheric Environment, 100, 238‚Äì249.\nThe OpenFOAM Foundation Hom\n\nWRF-Urban\n\nChen, F., Yu, B., Wu, M., Yang, X., et‚ÄØal.¬†(2021). Improved urban finescale forecasting during a heat wave by using high-resolution urban canopy parameters. Frontiers in Climate, 3, 771441. https://doi.org/10.3389/fclim.2021.771441\nMartilli, A., Nazarian, N., Krayenhoff, E.‚ÄØS., Lachapelle, J., Lu, J., Rivas, E., Rodriguez‚ÄëSanchez, A., Sanchez, B., & Santiago, J.‚ÄØL. (2024). WRF‚ÄëComfort: Simulating microscale variability in outdoor heat stress at the city scale with a mesoscale model. Geoscientific Model Development, 17, 5023‚Äì5039. https://doi.org/10.5194/gmd-17-5023-2024",
    "crumbs": [
      "Evaluation of Atmosphere‚ÄìVegetation Interaction Models"
    ]
  },
  {
    "objectID": "worksheets/ws-06.html#goals",
    "href": "worksheets/ws-06.html#goals",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Goals",
    "text": "Goals\nFour model runs were created: 2 for the planned expansion, 2 for the actual state, each with simplified meteorological boundary conditions for a radiation situation with little exchange. These model runs are now to be examined with regard to our question. To do this, we formally formulate a hypothesis, which we then examine and evaluate on the basis of the data."
  },
  {
    "objectID": "worksheets/ws-06.html#things-you-need",
    "href": "worksheets/ws-06.html#things-you-need",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Things you need",
    "text": "Things you need\n\nENVI-met software\nPlease have a look at the following Envi-met tutorials\n\nanalysing simulation data using the Leonardo\ncompare and average data in QGIS\n\nCurrent LTR Qgis Installation\n\nInstallation of Plugins\n\nGeodata to ENVI-met\nOSMDownloader\nQuickOSM\n\n\nSince the simulations are very time-consuming and the resulting Envi-met Hasenkopf GIS and Simulation data sets are very large, they can be downloaded from the external data server (needs VPN network)\n\n\n\n\n\n\n\nPlease note that there are eight directories, a total of four zero-wind simulations and four weak wind simulations, each divided into actual/planned conditions for summer and winter. The data that is of central interest can be found in the subdirectory ‚ÄòAtmosphere‚Äô."
  },
  {
    "objectID": "worksheets/ws-06.html#assignment",
    "href": "worksheets/ws-06.html#assignment",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Assignment",
    "text": "Assignment\n\nFormulation of a hypothesis based on the main motivation that the cold air production will be significantly weakened by the expansion plans for the Hasenkopf residential area.\nIdentification of suitable parameters and methods for qualitative and quantitative processing of the hypothesis.\nCreation of maps and tables"
  },
  {
    "objectID": "worksheets/ws-06.html#hypothesis",
    "href": "worksheets/ws-06.html#hypothesis",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Hypothesis",
    "text": "Hypothesis\nThe following hypotheses are examples and should narrow down the further analysis. They can, of course, also be formulated differently or modified.\n\n\n\n\n\n\nH1: In wind-weak radiation weather conditions (WS &gt; 0.5 m/s), a reduction in the supply of fresh air (&gt; 5 %) is to be expected for the affected district of Marburg, Ockershausen.\nH2: In low-wind radiation weather conditions (WS &lt; 0.5 m/s), no significant reduction in the supply of fresh air (less than 5 %) is to be expected for the affected district of Marburg, Ockershausen."
  },
  {
    "objectID": "worksheets/ws-06.html#workflow-approach",
    "href": "worksheets/ws-06.html#workflow-approach",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Workflow approach",
    "text": "Workflow approach\nAnswering this question requires scientific principles and conceptual approaches. In addition, of course, technical knowledge is required, such as how to extract, visualize, and compare the data of interest.\nThese two problem areas are interrelated, although they are independent of each other.\nIn summary, we need (1) one or more meteorological parameters that describe and quantify the production of fresh air. (2) We have to decide whether we use the area integral over time or a point measurement of these parameters as a proxy variable for our investigation, and then (3) find suitable technical means to carry out these calculations and data extractions. (4) Finally, we have to edit and discuss our hypotheses on this basis."
  },
  {
    "objectID": "worksheets/ws-06.html#identification-of-proxy-parameters",
    "href": "worksheets/ws-06.html#identification-of-proxy-parameters",
    "title": "WS-6: Visualize and Compare Simulation runs",
    "section": "Identification of proxy parameters",
    "text": "Identification of proxy parameters\nFirst of all get familar with the boundary layer basic concept of cold air production see p.¬†693-705.\nThe simplest approach would be to use a directly calculated variables from the Envi-met simulation runs. Since the supply of fresh air depends on the wind vector and also represents a spatial and temporal integral of the cold air inflow area of Ockershausen, not only the temperature difference is crucial, but also the gravitative/synoptic transport component. However, since the core simulation domain does not cover the entire catchment area, the relative catchment area of the runoff line in the Heiligengrund must serve as a reference point.\nTherefore, according to the avove chapters, suitable parameters could be:\n\nTemperature\nWind direction / wind speed\n\nThe conceptual realisation of both the meteorological and data-technical implementation could be as follows\n\nto identify the appropriate existing variables from the Envi-met parameter list\nto create summary evaluation maps of the model runs and their differences\nto export suitable data layers for further processing and analysis with QGIS\nin QGIS\n\nto calculate the catchment area\nto calculate zonal statistics on the catchment area to quantitatively determine the air mass difference."
  },
  {
    "objectID": "worksheets/ws-02.html",
    "href": "worksheets/ws-02.html",
    "title": "WS-2: Simple world Hasenkopf",
    "section": "",
    "text": "The arguments of the citizens‚Äô initiative wirsindhasenkopf include the following:"
  },
  {
    "objectID": "worksheets/ws-02.html#goals",
    "href": "worksheets/ws-02.html#goals",
    "title": "WS-2: Simple world Hasenkopf",
    "section": "Goals",
    "text": "Goals\nThe function of the planned development area as a cold air production area is to be examined quantitatively and in situ by means of a physical modeling. For this purpose, there is an initial site inspection and a step-by-step introduction to the necessary data and techniques."
  },
  {
    "objectID": "worksheets/ws-02.html#things-you-need",
    "href": "worksheets/ws-02.html#things-you-need",
    "title": "WS-2: Simple world Hasenkopf",
    "section": "Things you need",
    "text": "Things you need\n\nWeatherproof and all-terrain clothing"
  },
  {
    "objectID": "worksheets/ws-02.html#assignment",
    "href": "worksheets/ws-02.html#assignment",
    "title": "WS-2: Simple world Hasenkopf",
    "section": "Assignment",
    "text": "Assignment\n\nCreate an initial sketch on paper that describes the terrain and special spatial features.\nDigitize this rough sketch with the help of an aerial image database in three classes: arable land , grassland, bushes/trees.\nImport these Shapefiles into Monde and assign class 0200LG from the Envi-met DB Manager for arable land, 0200LG for grassland and 0200LG for bushes/trees.\nRun a complete standard simulation with these values using your knowledge from the first tutorial.l"
  },
  {
    "objectID": "worksheets/ws-04.html",
    "href": "worksheets/ws-04.html",
    "title": "WS-4: Generating the model domain",
    "section": "",
    "text": "After the first attempts - specifically after the technical example simulations as well as a rough structuring of the research questions, it is now necessary to design a concrete approach."
  },
  {
    "objectID": "worksheets/ws-04.html#goals",
    "href": "worksheets/ws-04.html#goals",
    "title": "WS-4: Generating the model domain",
    "section": "Goals",
    "text": "Goals\nDesign and impementation of a concrete approach."
  },
  {
    "objectID": "worksheets/ws-04.html#things-you-need",
    "href": "worksheets/ws-04.html#things-you-need",
    "title": "WS-4: Generating the model domain",
    "section": "Things you need",
    "text": "Things you need\n\nCourse Data Server You will find here all kinds of data, literature and tutorials.\nFor specific project data see Download of the data\nENVI-met software\nCurrent LTR Qgis Installation\n\nInstallation of Plugins\n\nGeodata to ENVI-met\nOSMDownloader\nQuickOSM"
  },
  {
    "objectID": "worksheets/ws-04.html#assignment",
    "href": "worksheets/ws-04.html#assignment",
    "title": "WS-4: Generating the model domain",
    "section": "Assignment",
    "text": "Assignment\nDesign a concrete modeling approach and a suitable associated modeling concept to assess the performance of Envimet to simulate how are the effects of the Hasenkopf build up plans affecting the fresh air support of Marburg. Consider the following aspects: * abiotic endowment of the model domain (relief, soil, site location). * biotic features of the model domain (simple/3D vegetation) * technical model domain (x,y,z extent, time steps nesting) * appropriate meteorology for model initialization (ideal, real values) * Validation strategy"
  },
  {
    "objectID": "worksheets/ws-04.html#hands-on",
    "href": "worksheets/ws-04.html#hands-on",
    "title": "WS-4: Generating the model domain",
    "section": "Hands on",
    "text": "Hands on\nThe preparation of the modelling environment for an Envi_met model run can be as complex as desired, but the following criteria should always be kept in mind:\n\nthe size and desired resolution of the model domain (depending on the research question AND computing costs)\nscientific or planning level of detail of the research question\nfocus of the modelling (wind field, plant respiration, micrometeorological parameters).\n\nThe input data sources must be selected according to these factors. In hilly terrain, a high resolution digital terrain model or digital surface model is essential. In addition, at least a rough estimate of land use and soil type is required. In addition the three-dimensional structure of the model requires at least good estimates of vegetation and building heights in the selected model area.\nFor the modeling of cold air drainage (i.e.¬†fresh air production) in the Hasenkopf area, the terrain, land use and meteorologically critical situations are of central importance. If you do not want to collect all the data in the field manually (which may be a sensible approach), Open Street Map data and aerial images are particularly useful for land use and possible follow-up surveys. Terrain data is now available in high resolution in the 1m range for large parts of Europe and the world. This data must be downloaded and prepared accordingly (for the Envi_met logic). There is now a powerful and largely functional plugin for QGIS ‚ÄòGeodata to Envi_met‚Äô, which intuitively specifies how this data is to be organized.\n\n\n\n\n\n\nFor the above question of cold air production, the freely available data from the State of Hesse and the Hessian Administration for Land Management and Geoinformation, as well as the Openstreetmap data, are well suited. In addition, some planning maps have to be digitised manually.\n\n\n\n\nDownload of the data\n\nDigital Elevation Model DEM and Digital Surface Model DSM files relevant for Marburg can be downloaded from the GDS website of the Hessian Administration for Land Management and Geoinformation\nFor downloading the OSM data it is recommended to use the OSMDownloader extension to QGIS. It simply provides the ability to draw a rectangle and download the complete and currently available OSM data to a file named hasenkopf.osm.\nIf the data has to be digitised manually, it is advisable to use an up-to-date aerial photograph from Bing or Google. These can be easily integrated via XYZ tiles\nThe planning data for the development and sealing were taken from page 23 of the presentation of the winning design via screenshot."
  },
  {
    "objectID": "worksheets/ws-04.html#data-preprocessing",
    "href": "worksheets/ws-04.html#data-preprocessing",
    "title": "WS-4: Generating the model domain",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nStarting with the OSM base data. Open the downloaded OSM file using the vector import dialogue box in a new group called OSM.\n\nNow open the attribute table and the function editor and select all natural and land use areas.\nMain keys: landuse natural with the values:\n'allotments','farmland','farmyard','forest','grass','meadow','orchard','village_green','grassland','scrub','wood'\nThis can be done very easily with the following expression:\n\"landuse\" IN ('allotments','farmland','farmyard','forest','grass','meadow','orchard','village_green','grassland','scrub','wood')\n OR  \n\"natural\" IN ('allotments','farmland','farmyard','forest','grass','meadow','orchard','village_green','grassland','scrub','wood')\n\n\nPress Select Objects Button and Export selected Values only (do not forget to assign the correct projection EPSG:32632) and name it vegtypes.gpkg.\nNext do the same with the hasenkopf ‚Äî multilinestrings\nMain key: highway with the values:\nprimary','primary_link','residential','secondary','secondary_link','tertiary' 'tertiary_link','track'\nPress Select Objects Button and Export selected Values only (do not forget to assign the correct projection EPSG:32632) and name it surftypes_roads_ml.gpkg.\n\nPolygons to Envi_met vegetation\nIn the next step, Envimet IDs are assigned to the vegetation polygons, which are either taken from the Envimet database or created by the user. This is done very simply as follows: Open the vegtypes.gpkg attribute table and then the field calculator. Create a new field with 6 alphanumeric characters and the name ENVIMET_ID. Then process the following expression. This assigns the corresponding vegetation database identifier to the new ‚ÄòENVIMET_ID‚Äô field.\nCASE \nCASE \n  WHEN \"landuse\" =   'grass'       THEN '000000'\n    WHEN \"landuse\" =   'meadow'        THEN '000000'\n    WHEN \"landuse\" =   'farmyard'      THEN '0201H4'\n    WHEN \"landuse\" =   'forest'        THEN '0000SM'\n    WHEN \"landuse\" =   'allotments'    THEN '0201H4'\n    WHEN \"landuse\" =   'orchard'       THEN '000051'\n  WHEN \"natural\" =   'grassland'     THEN '000000'  \n  WHEN \"natural\" =   'wood'          THEN '0000SM'\n    WHEN \"natural\" =   'scrub'         THEN '0100H2'  \n    WHEN \"landuse\" =   'farmland'      THEN '02AGSS'\n    WHEN \"landuse\" =   'residental'    THEN '02AGSS'    \n    WHEN \"landuse\" =   'industrial'    THEN '0200AK'    \n    ELSE '000000'\nEND\n\nSave the file.\nOn the same file, we need to edit the non-vegetated surfaces in a corresponding way:\nCASE \n    WHEN \"landuse\" =   'farmland'      THEN '02AGSS'\n    WHEN \"landuse\" =   'residental'    THEN '02AGSS'    \n    WHEN \"landuse\" =   'industrial'    THEN '0200AK'\n  ELSE '0200AK'\nPress Select Objects Button and Export selected Values only (do not forget to assign the correct projection EPSG:32632) and name it polygons_surfaces.gpkg.\n\n\nLine surface types\nWe need polygon data for the spatial setup of the envimet model domain. Line data is one-dimensional, so a simple approach is to buffer roads according to their priority. Therefore we buffer the different road types with 8m (primary), 5m (secondary), 4m (tertiary) and 2.5m (tracks).\nThen process the following expression to assign the ENVIMET_IDs:\n\nCASE \n  WHEN \"highway\" =   'primary'        THEN '0200AK'\n  WHEN \"highway\" =   'primary_link'   THEN '0200AK'\n  WHEN \"highway\" =   'secondary'      THEN '0200AK'\n  WHEN \"highway\" =   'secondary_link' THEN '0200AK'\n  WHEN \"highway\" =   'tertiary'       THEN '0200AK'\n  WHEN \"highway\" =   'tertiary_link'  THEN '0200AK'  \n  WHEN \"surface\" =   'asphalt'        THEN '0200AK'\n    WHEN \"surface\" =   'ground'         THEN '0200TS'\n    WHEN \"surface\" =   'dirt'           THEN '0200TS'\n    WHEN \"surface\" =   'mud'            THEN '0200TS'\n    WHEN \"surface\" =   'fine_gravel'    THEN '0200BS'\n    WHEN \"surface\" =   'gravel'         THEN '0200BS'\n    WHEN \"surface\" =   'grass'          THEN '02AGSS'\n    WHEN \"surface\" =   'unpaved'        THEN '0200TS'\n    WHEN \"surface\" =   'compacted'      THEN '0200BS'\nELSE '0200TS'\nEND\nSave the file as line_surfaces.gpgk.\nNext merge polygons_surfaces.gpkg and line_surface.gpgk into all_surfaces.gpgk."
  },
  {
    "objectID": "worksheets/ws-04.html#buildings",
    "href": "worksheets/ws-04.html#buildings",
    "title": "WS-4: Generating the model domain",
    "section": "Buildings",
    "text": "Buildings\nUse the OSM polygon data again and select all buildings that do not have the value NULL.\n \"building\" is not NULL\nSave the file as buildings.gpgk.\nWe need the heights of the buildings, so we extract the data from the surface height model (SHM) for each building using the zonal statistics tool, which we previously calculated using the raster computer from the difference between the digital surface model (DSM) and the digital elevation model (DEM)."
  },
  {
    "objectID": "worksheets/ws-04.html#check-for-missing-data",
    "href": "worksheets/ws-04.html#check-for-missing-data",
    "title": "WS-4: Generating the model domain",
    "section": "Check for missing data",
    "text": "Check for missing data\nHide all data and activate only the generated vegetation, surface and building data. Check in the following order:\n\nis there still surface data without information?\nare there vegetation areas without information?\nare all buildings present?\n\n\nRegarding 1: It is likely that important information is missing, especially for the surfaces. All streets and sealed surfaces should be present here, but the surfaces under vegetation, etc. have no information. The easiest way is to assign a soil type code to this total area. This is most easily done by calculating a symmetric difference between the surface data and the model area; the resulting polygon is a negative of the existing surfaces. This polygon is then assigned a field ‚ÄòENVIMET_ID‚Äô and the corresponding soil value is entered. The file is then merged with the existing surface file (merge tool).\nRegarding 2: If areas are unclear, they must be digitized manual. To do this, open the Bing/Google aerial map and open the corresponding vegetation file, make it editable and re-digitize it. It is important that the correct ENVIMET_ID is assigned at the end of each polygon.\nRegarding 3: Simply compare the aerial image to see if all buildings are present in the model area. If not, digitize them again and then use the zonal statistics tool again."
  },
  {
    "objectID": "worksheets/ws-04.html#receptors",
    "href": "worksheets/ws-04.html#receptors",
    "title": "WS-4: Generating the model domain",
    "section": "Receptors",
    "text": "Receptors\nSo-called receptors can be set up to compare and locally measure continuous values. These work like complex measuring stations in the terrain. To do this, we use the tool [Vector-&gt;Research Tools-&gt;Regular Points] (https://youtu.be/ExgfFEEgeWA?si=nZWgiZR299VQBAR1). We can, for example, create a point every 100 meters. Points at the edge, in buildings, etc. can then be deleted manually, as they require a considerable amount of additional computing time during the simulation. There should not be many more than 50-60 points‚Ä¶ Save the file as receptors.gpkg."
  },
  {
    "objectID": "worksheets/ws-04.html#planning-data",
    "href": "worksheets/ws-04.html#planning-data",
    "title": "WS-4: Generating the model domain",
    "section": "Planning data",
    "text": "Planning data\nPlanning data is required to compare the production of fresh air between the actual and planned conditions. The available data can be found in the presentation linked above. We use the following screenshot to record the changes in land use, buildings and vegetation based on this. To do this, the map presentation image must be georeferenced. This is done using the tool Layer-&gt;Georeferencer.\nThe basic approach is to find points (so-called ground control points) in the draft plan that can also be identified in the Bing aerial photograph, for example. Using these points, the image is integrated into the geometry of the GIS data and can then be digitized accordingly.\n\nThe basic approach is to find points (so-called ground control points) in the draft plan that can also be identified in the Bing aerial photograph, for example. On the basis of these points, the image is integrated into the geometry of the GIS data and can then be digitized accordingly.\nAfter the georeferencing has been successfully carried out, the deviating structures are now integrated into copies of the respective inventory files by manual digitization. The number of floors is indicated for the buildings and can be adopted with a height of 3 m each. The trees were digitized as 3D plant points and assigned to different standard heights of a standard deciduous tree species, depending on their diameter. Paths are recorded as paved.\n\nSave the files under a unique name in each case, making it clear that the planning layers are meant."
  },
  {
    "objectID": "worksheets/ws-04.html#convert-geodata-to-envimet",
    "href": "worksheets/ws-04.html#convert-geodata-to-envimet",
    "title": "WS-4: Generating the model domain",
    "section": "Convert Geodata to envimet",
    "text": "Convert Geodata to envimet\nYou can now run the Convert Geodata to Envimet] plug-in. Of course, two different models have to be generated: one for the actual state and one for the planned state."
  },
  {
    "objectID": "worksheets/ws-04.html#help",
    "href": "worksheets/ws-04.html#help",
    "title": "WS-4: Generating the model domain",
    "section": "Help",
    "text": "Help\n\n\n\n\n\n\nAll files, GCP and the model files and simulation control files generated from it, are included in the Envi-met Hasenkopf GIS and Modeldata Archive file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Envi_Met TLS-tree-climate",
    "section": "",
    "text": "This course teaches how to use terrestrial laser scanning (TLS) to model individual trees and their effects on microclimate. You‚Äôll learn how to turn detailed 3D scans into leaf area density (LAD) profiles and use them in ENVI-met for realistic tree simulations.\nWhat you‚Äôll learn: What LAD means and why it matters for tree‚Äìclimate interaction\nHow to process TLS data into vertical tree profiles\nHow to create 3D tree objects from LAD for use in ENVI-met\nHow to choose between simple scaling and light-based LAD models\nThis course is hands-on, focused, and designed for clear outcomes: understanding tree structure, visualizing it, and using it in a climate model."
  },
  {
    "objectID": "mc_session/mcm1.html",
    "href": "mc_session/mcm1.html",
    "title": "Microclimate Modeling",
    "section": "",
    "text": "Microclimates, or small-scale local atmospheric conditions, play a critical role in ecosystems, human activities, and environmental processes of all kinds. Microclimates are defined as the set of climatic conditions typical of a given small area. Local variations, often influenced by terrain, vegetation, and human activities, form a complex web of microclimates that shape our immediate environment.\nThe study and modeling of microclimates is becoming increasingly important for understanding the complex dynamics of temperature, humidity, wind patterns, and other climate variables at fine spatial scales, especially in urban areas. As the critical importance of regional differences in the context of global climate change becomes more apparent, the need for robust and user-friendly microclimate models is growing.\nMicroclimate modeling is based on the collection and evaluation of physical, statistical, observational, and analytical data. It is a highly interdisciplinary field, with a core of meteorology, climatology, and computer science, but also with large overlaps with, for example, ecology and urban planning.\nIn this course, the microclimate model Envi-met is used to answer typical urban planning questions. The overall goal is to teach the basics of practical application, from data collection and processing to modeling, analysis, and scientific presentation.\nAdvances in sensor technology, including ground-based sensors, drones, and aerial photography, as well as freely available data sets, help to create a realistic and complex modeling base.\nReliable simulation of different planning scenarios requires at least a basic understanding of the most important meteorological processes. As an introduction we refer to the book Practical Meteorology by Roland Stull, especially the chapter Atmospheric Boundary Layer."
  },
  {
    "objectID": "worksheets/ws-03.html#goals",
    "href": "worksheets/ws-03.html#goals",
    "title": "WS-3: Abstract the complex sufficiently",
    "section": "Goals",
    "text": "Goals\nNow that the first steps have been taken - namely, the technical and simple hasenkopf example simulations and a rough structuring of the research questions - it is necessary to design a concrete approach."
  },
  {
    "objectID": "worksheets/ws-03.html#things-you-need",
    "href": "worksheets/ws-03.html#things-you-need",
    "title": "WS-3: Abstract the complex sufficiently",
    "section": "Things you need",
    "text": "Things you need\n\nCourse Data Server You will find here all kinds of data, literature and tutorials\nENVI-met software\nPlease have a look at the Monde Tutorial videos\nQGIS"
  },
  {
    "objectID": "worksheets/ws-03.html#assignment",
    "href": "worksheets/ws-03.html#assignment",
    "title": "WS-3: Abstract the complex sufficiently",
    "section": "Assignment",
    "text": "Assignment\nDesign a concrete modeling approach and a suitable associated modeling concept to assess the performance of Envimet to simulate how are the effects of the Hasenkopf build up plans affecting the fresh air support of Marburg.\nConsider the following aspects:\n\nabiotic endowment of the model domain (relief, soil, site location).\nbiotic features of the model domain (simple/3D vegetation)\nappropriate meteorology for model initialization (ideal, real values)\ntechnical model domain (x,y,z extent, time steps nesting)\nValidation strategy\n\nDesign the necessary work packages you need to divide your team into groups/single workers to achieve the goal.\n\nWP 1 data aquisition (DEM/DSM, vegetation, soil, build up areas, planned hasenkopf build up area, meteo data )\nWP 2 data manipulation using QGIS\n\nWP 2a Vegetation ‚Äúsimple\nWP 2b Vegetation ‚Äú3D\nWP 2c buildings\nWP 2d Terrain, soil etc.\n\nWP 3 Meteorological data\nWP 4 Model Setup\nWP 6 Simulation\nWP 7 Presentation\n\nThe task is then as follows:\nThe resulting concept should be prepared as a table (similar to the below example), also addressing the literature/data used as well as know shortcomings.\n\nAssignment 1\nFrom your knowledge now prepare a table containing the following information\n\n\n\n\n\n\n\n\n\n\n\nressources needed\nsolution\nreferences\nneeds manipulation\nknowledge available\nWho is doing it\n\n\n\n\nrelief\n1 m DOM\ndownload link etc.\nyes, what kind of\nno, what aditional knowledge do you need\nName(s)\n\n\nsoil properties\nsoil data\naccess has to be clarified\nwho knows\n?\n?\n\n\nsoil vertical structure\nfour levels temperature soil moisture build-in model\nenvi-met\n?\n?\n?\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\nAny written notes please put them on comments below.\n\n\nAssignment 2\nIdentify the critical shortcomings to solve these problems. State them clearly and try to offer a solution.\n\n\n\n\n\n\nIt is very important to understand what needs to be done and in which order by looking at the previous sessions and the tutorial.\nThe focus is on identifying the required data, the appropriate data preparation (also think about 3D problems!) and the standard initialisation of Envimet."
  },
  {
    "objectID": "worksheets/ws-05.html#goals",
    "href": "worksheets/ws-05.html#goals",
    "title": "WS-5: Simulation runs Hasenkopf",
    "section": "Goals",
    "text": "Goals\nAfter creating the modeling environment using OSM data, aerial image data and planning data, the QGIS plugin Converting Geodata to Envimet was used to create corresponding model environments for the planning and the actual situation. On this basis, idealized model runs are to be carried out. In this context, idealized means under simple meteorological conditions that represent an exchange-weak radiation situation."
  },
  {
    "objectID": "worksheets/ws-05.html#things-you-need",
    "href": "worksheets/ws-05.html#things-you-need",
    "title": "WS-5: Simulation runs Hasenkopf",
    "section": "Things you need",
    "text": "Things you need\n\nCourse Data Server You will find here all kinds of data, literature and tutorials\nENVI-met software\nCurrent LTR Qgis Installation\n\nInstallation of Plugins\n\nGeodata to ENVI-met\nOSMDownloader\nQuickOSM\n\n\nEnvi-met Hasenkopf GIS and Modeldata"
  },
  {
    "objectID": "worksheets/ws-05.html#assignment",
    "href": "worksheets/ws-05.html#assignment",
    "title": "WS-5: Simulation runs Hasenkopf",
    "section": "Assignment",
    "text": "Assignment\nSetup an run an full simulation for the Hasenkopf"
  },
  {
    "objectID": "worksheets/ws-05.html#hands-on---start-a-simulation",
    "href": "worksheets/ws-05.html#hands-on---start-a-simulation",
    "title": "WS-5: Simulation runs Hasenkopf",
    "section": "Hands on - Start a simulation",
    "text": "Hands on - Start a simulation\n\nUnzip the ZIP archive and open the included QGIS project (hasenkopf_core_plan_orig.qgz). We are working in the core_area_new area. See the corresponding grouped folders.\n\norig for the current situation\nplan for the planning\nraster for raster data\n\nFamiliarize yourself with the files. They are grouped according to the Envi-met logic. Each of them contains vegetation (simple/3D), buildings, surfaces/soils and the terrain model, in addition receptors that can be understood as measuring stations in the model area and the already mentioned model area itself.\nFor the first simulation, the Envimet Plugin is started and the data from the original folder is assigned. The DGM is used as the DEM. Note: Enter the ENVIMET_ID as a reference field for the library values to be read.\nSave the models and check it for errors using the Envimet Spaces module.\n\n\n\n\n\n\n\n\n\nCurrent situation at the Hasenkopf site\n\n\n\n\n\n\n\nPlanned situation at the Hasenkopf site\n\n\n\n\n\n\nFigure¬†1: Hasenkopf residential area expansion"
  },
  {
    "objectID": "worksheets/ws-05.html#everything-ok",
    "href": "worksheets/ws-05.html#everything-ok",
    "title": "WS-5: Simulation runs Hasenkopf",
    "section": "Everything OK?",
    "text": "Everything OK?\n\nThen start the Envi_met tool Envi-Guide and set up a simulation environment for July 21, 2024 that will run for at least 36 hours.\nSave and start the Envi-Core module. Open the created simulation and start it‚Ä¶\n\n\n\n\n\n\n\nIn the archive subfolder envimet_files you will find the simulation and model files for both runs. You can use these to compare with your own files."
  },
  {
    "objectID": "worksheets/ws-01.html",
    "href": "worksheets/ws-01.html",
    "title": "WS-1: Warm up - Climate Modeling",
    "section": "",
    "text": "ENVI-met V5.x is a three-dimensional, non-hydrostatic model for simulating surface-plant-air interactions, It is designed for the microscale with a typical horizontal resolution of 0.5 to 10 m and a typical time frame of 24 to 48 hours with a time step of 1 to 5 seconds. This resolution allows for the analysis of small-scale interactions between individual buildings, surfaces, and plants"
  },
  {
    "objectID": "worksheets/ws-01.html#goals",
    "href": "worksheets/ws-01.html#goals",
    "title": "WS-1: Warm up - Climate Modeling",
    "section": "Goals",
    "text": "Goals\nThis task involves three sub-areas:\n\nto get a first overview about non-hydrostatic 4D climate modeling.\nto get a first insight into the application areas of such simulations.\nto install the software and perform a first simple tutorial simulation"
  },
  {
    "objectID": "worksheets/ws-01.html#things-you-need",
    "href": "worksheets/ws-01.html#things-you-need",
    "title": "WS-1: Warm up - Climate Modeling",
    "section": "Things you need",
    "text": "Things you need\n\nCourse Data Server Tutorials\nCourse Data Server Literature\nENVI-met software"
  },
  {
    "objectID": "worksheets/ws-01.html#assignment",
    "href": "worksheets/ws-01.html#assignment",
    "title": "WS-1: Warm up - Climate Modeling",
    "section": "Assignment",
    "text": "Assignment\nThe studies are intended to provide a first overview of the possibilities of the application. It is a first overview about the subject\nThe tutorials are a selection from the Envimet download area. In particular session_1_apps.pdf and session_1_concepts.pdf are a compilation of the concepts of Envimet and the individual components for the workflow with the individual modules, respectively, created by me. You will also find the links to the Youtube channel if you prefer videos.\nThese two compilations from the Envimet help pages should be sufficient to perform the example modeling ‚ÄúPrecipitation‚Äù.\nIn the folder Literature you will find chapter1.pdf and chapter3.pdf. Both are reasonably understandable basics for climate modeling from a Belgian textbook. In case of more detailed questions they are worth a look.\nThe task is then as follows:\n\nInstallation of ENVI-met on your computer\nRead session_1_conpepts.pdf for a first introduction to the ENVI-met model concepts (chapter3.pdf could also be helpful here for supplementation and deepening) =&gt; If available, articulate questions problems\nRead session_1_apps.pdf as a basis for the example modeling ‚ÄúPrecipitation‚Äù. =&gt; If available, articulate questions, problems, etc.\nRun the precipitation simulation (check if it runs) =&gt; If available, articulate questions, problems etc.\nCross-reading of min 2 tutorials (What is the basic idea) =&gt; Prepare a short summary"
  },
  {
    "objectID": "worksheets/ws-00.html",
    "href": "worksheets/ws-00.html",
    "title": "WS-HowTo",
    "section": "",
    "text": "The Working Sheets will provide weekly assignments related to the general task of reaching out for the course goals.\n\nMandatory assignments (Studienleistung) will be marked as \nGraded examinations (Pr√ºfungsleistung) will be marked as"
  },
  {
    "objectID": "doc/helper_functions.html",
    "href": "doc/helper_functions.html",
    "title": "Helper Functions for Microclimate Predictor Stack",
    "section": "",
    "text": "1 Introduction\nThis document explains the custom helper functions used in the microclimate_predictor_stack.R script for preprocessing and analyzing LiDAR data in R. The functions support pixel-level metrics computation, raster template creation, VRT mosaicking, and tree hull extraction.\n\n\n\n2 .stdmetrics()\n#' @title .stdmetrics\n#' @description Berechnet Standardmetriken f√ºr LiDAR Rasterzellen\n.stdmetrics &lt;- function(z, i, ...) {\n  return(list(\n    zmax = max(z, na.rm = TRUE),            # Maximum height\n    zmean = mean(z, na.rm = TRUE),          # Mean height\n    zsd = sd(z, na.rm = TRUE),              # Standard deviation of heights\n    zkurto = moments::kurtosis(z, na.rm = TRUE), # Kurtosis (peakedness of distribution)\n    zskew = moments::skewness(z, na.rm = TRUE),  # Skewness (asymmetry)\n    zq25 = quantile(z, 0.25, na.rm = TRUE), # 25th percentile\n    zq50 = quantile(z, 0.5, na.rm = TRUE),  # Median height\n    zq75 = quantile(z, 0.75, na.rm = TRUE), # 75th percentile\n    zpulse = length(z)                      # Number of returns (pulse count)\n  ))\n}\nUsed to derive standard height-based metrics from LiDAR returns per raster cell using pixel_metrics().\n\n\n\n3 get_vrt_img()\n#' @title get_vrt_img\n#' @description Creates a VRT from multiple GeoTIFF files in a directory\nget_vrt_img &lt;- function(name, path, pattern) {\n  tifs &lt;- list.files(path = path, pattern = paste0(pattern, \".tif$\"), full.names = TRUE)\n  vrt &lt;- file.path(path, paste0(name, \".vrt\"))\n  if (file.exists(vrt)) file.remove(vrt)\n  gdal_utils(util = \"buildvrt\", source = tifs, destination = vrt)\n  return(vrt)\n}\nUsed to dynamically generate a VRT (virtual raster stack) from multiple .tif files with a matching pattern, e.g.¬†\"lad_metrics\".\n\n\n\n4 tree_fn()\n#' @title tree_fn\n#' @description Creates convex hulls from segmented trees in LAS catalogs\ntree_fn &lt;- function(las, ...) {\n  if (is.empty(las)) return(NULL)                   # Skip if empty\n  las &lt;- filter_poi(las, !is.na(treeID))            # Keep only trees\n  if (npoints(las) == 0) return(NULL)               # Skip if no points\n  dt &lt;- data.table::as.data.table(las@data)\n  dt &lt;- dt[, .(X = mean(X), Y = mean(Y)), by = treeID]  # Mean location per tree\n  points_sf &lt;- st_as_sf(dt, coords = c(\"X\", \"Y\"), crs = sf::st_crs(las))\n  hulls &lt;- st_convex_hull(st_union(points_sf))      # Create unified convex hull\n  return(hulls)\n}\nUsed with catalog_apply() to derive convex hull geometries from segmented tree point clouds.\n\n\n\n5 template_raster()\n#' @title template_raster\n#' @description Creates an empty raster template based on bounding box and resolution\ntemplate_raster &lt;- function(bbox, crs, res = 1.0) {\n  if (inherits(bbox, \"sf\")) bbox &lt;- st_bbox(bbox)\n  r &lt;- terra::rast(xmin = bbox[\"xmin\"], xmax = bbox[\"xmax\"],\n                   ymin = bbox[\"ymin\"], ymax = bbox[\"ymax\"],\n                   resolution = res, crs = crs)\n  return(r)\n}\nGenerates a blank terra::rast object for rasterizing vector geometries such as LAD polygons or tree hulls."
  },
  {
    "objectID": "doc/tls_v1_1.html#background-and-method",
    "href": "doc/tls_v1_1.html#background-and-method",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Background and Method",
    "text": "Background and Method\nThis section explains the theoretical principles of leaf area density (LAD) and describes how it can be determined using terrestrial laser scanning (TLS). Leaf area density is an important parameter in environmental modeling, for example for radiation balance and microclimate simulations. It indicates the leaf area per volume (m¬≤/m¬≥) and is therefore a decisive factor for microclimate simulations, radiation models, and energy flows in vegetation stands.\n\n\n\n\n\n\n\n\nApproach Type\nName / Description\nNature\n\n\n\n\nPulse-count based\nSimple linear normalization of return counts or voxel hits\nEmpirical, direct\n\n\nLinear normalization\nStraightforward normalization of pulse counts by voxel volume or max LAD\nEmpirical, basic\n\n\nPulse-density normalization\nAdjusts for occlusion and scan geometry\nSemi-empirical\n\n\nGap fraction models\nEstimate LAD/LAI from canopy openness statistics\nSemi-empirical\n\n\nBeer‚ÄìLambert conversion conversion\nUses exponential light attenuation to infer LAD\nPhysically-based\n\n\nVoxel-based inverse modeling\nOptimizes 3D LAD to match observed light attenuation or reflectance\nPhysically-based\n\n\nAllometric / geometric reconstruction\nReconstructs crown volume and distributes LAD using QSM or shape fitting\nGeometric, structural\n\n\n\n\nLinear normalization is a practical baseline: simple, fast, and reproducible.\nBeer‚ÄìLambert conversion introduces realism via physical light attenuation.\n\nMore advanced models (e.g.¬†voxel inverse or QSM-based) aim for higher biophysical fidelity at the cost of complexity.\nThe present analysis is based on TLS with a medium-range RIEGL scanner (e.g., VZ-400). This captures millions of 3D points of the vegetation structure with high angular resolution. The point cloud is divided into uniform voxels, from which the leaf area density is estimated in two ways.\n\nLinear normalization (straightforwad)\n\\[\n\\text{LAD}_i = \\frac{N_i}{N_{\\max}} \\cdot \\text{LAD}_{\\max}\n\\] - \\(N_i\\): Number of laser points in voxel \\(i\\)\n- \\(N_{\\max}\\): Maximum across all voxels\n- \\(\\text{LAD}_{\\max}\\): Maximum LAD value from the literature (e.g., 5 m¬≤/m¬≥)\n\n\n\nBeer‚ÄìLambert conversion\n\\[\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n\\]\n\n\\(k\\): Extinction coefficient (typically 0.3‚Äì0.5)\n\\(\\Delta z\\): vertical voxel height\n\n\n\nOverall Workflow\nWhat happens in the script?\n\n\n\n\n\n\n\n\nStep\nDescription\nRelevant Code\n\n\n\n\n1. Read & Filter LAS\nLoad TLS data, optionally crop and clean it\nreadLAS() and las = filter_poi(...)\n\n\n2. Voxel Grid Setup\nSet up 3D grid at defined grain.size\npassed to pixel_metrics(..., res = grain.size)\n\n\n3. Count Pulses\nCount returns in each voxel height bin\npointsByZSlice() function\n\n\n4. Normalise Pulse Counts\nDivide by global max (relative LAD)\nin convert_to_LAD(): lad = (count / max) * LADmax\n\n\n5. Export Raster\nConvert metrics to raster stack\nterra::rast() from voxel_df\n\n\n6. Visualization\nPlot LAD profiles\nsee plotting section\n\n\n7. Export to Plant3D\nExports the LAD to ENVI-met\nsee export section",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#implemetation",
    "href": "doc/tls_v1_1.html#implemetation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Implemetation",
    "text": "Implemetation\nTo use this ENVI-met tree modeling workflow in R, follow these steps to load and initialize the project correctly:\nProject Setup: Loading the R Project and Environment\n\nDownload and Unzip the Project Archive\n\nUnzip the folder to your desired location.\nThe folder should contain at least:\n\nAn *.Rproj file (e.g.¬†envimet_tree_workflow.Rproj)\nA data/ folder with input files like tree_08.las\nOne or more R/ scripts\n\n\n\n\nOpen the Project in RStudio\n\nGo to File ‚Üí Open Project\nSelect the *.Rproj file (e.g.¬†microclimate_TLS.Rproj)\nThis ensures that the project directory is treated as the root for all file paths.\n\n\nThe use of the {here} package depends on having a valid RStudio project. Without this, file paths may not resolve correctly.\n\n\n\nData Input Parameters and Paths\n\n\n\n\n\n\nThe input data set tree_08.las is a cleaned terrestrial laser scan of a single, isolated tree. All surrounding vegetation and ground points have been removed, so the file contains only the tree‚Äôs structure‚Äîtrunk, branches, and foliage. Stored in standard LAS format, it provides high-resolution 3D point data suitable for voxelization, LAD calculation, or input into microclimate and radiative models. This detailed structural data is essential for generating true 3D tree entities in ENVI-met; without it, only simplified vegetation (SimplePlants) can be used.\n\n\n\nSet global parameters for the workflow, such as file paths, voxel resolution, and maximum LAD value for normalization.\n\nlibrary(terra)\nlibrary(lidR)\nlibrary(sf)\nlibrary(here)\nlibrary(data.table)\n\nzmax &lt;- 40  \ngrain.size &lt;- 1  \nproject_root &lt;- here::here()  \n\n# Choose LAD method: \"linear\" or \"beer\"\n# Beer‚ÄìLambert conversion Notes:\n# - Avoids log(0) and 1 by clipping near-extreme values\n# - Use when cumulative light absorption or occlusion is relevant\n# - Suitable if extinction coefficient is known or estimated from prior studies\nlad_method &lt;- \"beer\"  # Set to \"linear\" or \"beer\"\n\n# Optional: extinction coefficient (used only for Beer‚ÄìLambert conversion)\nk_extinction &lt;- 0.25\n\n\nlas_file &lt;- file.path(project_root, \"data/TLS/tree_08.laz\")  \noutput_voxels &lt;- file.path(project_root, \"data/TLS/LAD_voxDF.rds\")  \noutput_array &lt;- file.path(project_root, \"data/TLS/lad_array_m2m3.rds\")  \noutput_profile_plot &lt;- file.path(project_root, \"data/TLS/lad_vertical_profile.pdf\")  \n\n\n\nVoxelization of TLS data\nVoxelisation turns a 3D TLS point cloud into a grid of cubes (voxels), where each voxel holds structural information. The number of points per voxel is used to estimate Leaf Area Density (LAD), typically normalized relative to the voxel with the most returns.\n\nEach voxel = a 1√ó1√ó1‚ÄØm¬≥ cube\nCount the laser hits per voxel\nNormalize to maximum\nMultiply by a literature-based LAD_max (e.g.¬†5‚ÄØm¬≤/m¬≥)\n\nThis gives a spatially distributed LAD profile suitable for further analysis or models like ENVI-met.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\n\n las &lt;- lidR::readLAS(las_file)  # Read the LAS/LAZ file (point cloud data)\n\n\n[=========================&gt;                        ] 51% ETA: 1s     \n[=========================&gt;                        ] 51% ETA: 1s     \n[=========================&gt;                        ] 51% ETA: 1s     \n[=========================&gt;                        ] 51% ETA: 1s     \n[=========================&gt;                        ] 51% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 52% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[==========================&gt;                       ] 53% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 54% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[===========================&gt;                      ] 55% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 56% ETA: 1s     \n[============================&gt;                     ] 57% ETA: 1s     \n[============================&gt;                     ] 57% ETA: 1s     \n[============================&gt;                     ] 57% ETA: 1s     \n[============================&gt;                     ] 57% ETA: 1s     \n[============================&gt;                     ] 57% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 58% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[=============================&gt;                    ] 59% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 60% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[==============================&gt;                   ] 61% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 62% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[===============================&gt;                  ] 63% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 64% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[================================&gt;                 ] 65% ETA: 1s     \n[=================================&gt;                ] 66% ETA: 1s     \n[=================================&gt;                ] 66% ETA: 1s     \n[=================================&gt;                ] 66% ETA: 1s     \n[=================================&gt;                ] 66% ETA: 1s     \n[=================================&gt;                ] 66% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[=================================&gt;                ] 67% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 68% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[==================================&gt;               ] 69% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 70% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[===================================&gt;              ] 71% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 72% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[====================================&gt;             ] 73% ETA: 1s     \n[=====================================&gt;            ] 74% ETA: 1s     \n[=====================================&gt;            ] 74% ETA: 1s     \n[=====================================&gt;            ] 74% ETA: 1s     \n[=====================================&gt;            ] 74% ETA: 0s     \n[=====================================&gt;            ] 74% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[=====================================&gt;            ] 75% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n                                                                                \n\n  las@data$Z &lt;- las@data$Z - min(las@data$Z, na.rm = TRUE)  \n  maxZ &lt;- min(floor(max(las@data$Z, na.rm = TRUE)), zmax)  \n  las@data$Z[las@data$Z &gt; maxZ] &lt;- maxZ  \npointsByZSlice = function(Z, maxZ){\n  heightSlices = as.integer(Z) # Round down\n  zSlice = data.table::data.table(Z=Z, heightSlices=heightSlices) # Create a data.table (Z, slices))\n  sliceCount = stats::aggregate(list(V1=Z), list(heightSlices=heightSlices), length) # Count number of returns by slice\n  \n  ##############################################\n  # Add columns to equalize number of columns\n  ##############################################\n  colRange = 0:maxZ\n  addToList = setdiff(colRange, sliceCount$heightSlices)\n  n = length(addToList)\n  if (n &gt; 0) {\n    bindDt = data.frame(heightSlices = addToList, V1=integer(n))\n    sliceCount = rbind(sliceCount, bindDt)\n    # Order by height\n    sliceCount = sliceCount[order(sliceCount$heightSlices),]\n  }\n  \n  colNames = as.character(sliceCount$heightSlices)\n  colNames[1] = \"ground_0_1m\"\n  colNames[-1] = paste0(\"pulses_\", colNames[-1], \"_\", sliceCount$heightSlices[-1]+1, \"m\")\n  metrics = list()\n  metrics[colNames] = sliceCount$V1\n  \n  return(metrics)\n  \n} #end function pointsByZSlice\n\n# --- Main function ---\npreprocess_voxels &lt;- function(normlas, grain.size = 1, maxP =zmax, normalize = TRUE, as_raster = TRUE) {  \n  las &lt;- normlas  \n  \n  # Filter height range\n  las &lt;- filter_poi(las, Z &gt;= 0 & Z &lt;= maxP)  \n  if (lidR::is.empty(las)) return(NULL)\n  # Determine Z-slices\n  maxZ &lt;- floor(max(las@data$Z))  \n  maxZ &lt;- min(maxZ, maxP)  \n  \n  \n  # Compute voxel metrics\n  func &lt;- formula(paste0(\"~pointsByZSlice(Z, \", maxZ, \")\"))  \n  voxels &lt;- pixel_metrics(las, func, res = grain.size)  # Calculate metrics in each voxel (3D grid cell)\n  \n  # Optionally normalize values by voxel volume\n  if (normalize) {\n    vvol &lt;- grain.size^3  \n    voxels &lt;- voxels / vvol  \n  }\n  \n  # Return as both terra::SpatRaster and data.frame\n  result &lt;- list()  \n  \n  if (as_raster) {\n    result$raster &lt;- voxels  \n  }\n  \n  # Convert to data.frame\n  xy &lt;- terra::xyFromCell(voxels, seq_len(ncell(voxels)))  \n  vals &lt;- terra::values(voxels)  \n  df &lt;- cbind(xy, vals)  \n  colnames(df)[1:2] &lt;- c(\"X\", \"Y\")  \n  result$df &lt;- df  \n  \n  return(result)\n}\n\n\n\n\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  \n\n\n\n\n\nConversion to LAD (m¬≤/m¬≥)\nThe conversion to LAD (Leaf Area Density, in m¬≤/m¬≥) from TLS-based voxel pulse counts is done using a relative normalization heuristic which is adopted as a practical approximation in voxel-based canopy structure analysis using TLS (Terrestrial Laser Scanning) data.:\nFor each voxel layer (e.g.¬†pulses_2_3m), the LAD is calculated as:\n\\[\n\\text{LAD}_{\\text{voxel}} = \\left( \\frac{\\text{pulse count in voxel}}{\\text{maximum pulse count over all voxels}} \\right) \\times \\text{LAD}_{\\text{max}}\n\\]\nWhere:\n\npulse count in voxel = number of returns in this voxel layer (from TLS)\nmax_pulse = the maximum pulse count found in any voxel (used for normalization)\nLAD_max = a fixed normalization constant (e.g.¬†5.0‚ÄØm¬≤/m¬≥) chosen from literature or calibration\n\n\n\n\n\n\n\nTypical LAD‚Çò‚Çê‚Çì Values by Species\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies / Structure Type\nLAD‚Çò‚Çê‚Çì (m¬≤/m¬≥)\nSource / Notes\n\n\n\n\nFagus sylvatica (European beech)\n3.5‚Äì5.5\nCalders et al.¬†(2015), Chen et al.¬†(2018)\n\n\nQuercus robur (English oak)\n3.0‚Äì6.0\nHosoi & Omasa (2006), field studies with TLS voxelization\n\n\nConiferous trees (e.g.¬†pine)\n4.0‚Äì7.0\nWilkes et al.¬†(2017), higher LAD due to needle density\n\n\nMixed broadleaf forest\n3.0‚Äì6.0\nFlynn et al.¬†(2023), canopy averaged estimates\n\n\nShrubs / understorey\n1.5‚Äì3.0\nChen et al.¬†(2018),lower vertical structure density\n\n\nUrban street trees\n2.0‚Äì4.0\nSimon et al.¬†(2020), depending on pruning and species\n\n\n\nLAD values refer to maximum expected per 1‚ÄØm vertical voxel. Values depend on species, seasonality, and scanning conditions.\n\n\n\nWhat this means conceptually\nYou‚Äôre not measuring absolute LAD, but instead:\n\nUsing the number of TLS returns per voxel as a proxy for leaf density\nThen normalization all voxels relatively to the most ‚Äúleaf-dense‚Äù voxel\nThe LAD_max defines what value the ‚Äúdensest‚Äù voxel should reach in terms of LAD\n\nThis is fast, simple, and works well when:\n\nYou want relative structure across the canopy\nYou don‚Äôt have absolute calibration (e.g.¬†with destructive sampling or hemispheric photos)\n\nCaveats and assumptions\n\nThis approach assumes the TLS beam returns are proportional to leaf area, which is a simplification\nIt‚Äôs sensitive to occlusion and TLS positioning\nThe choice of LAD_max is crucial‚Äîcommon values from literature range from 3‚Äì7‚ÄØm¬≤/m¬≥ for dense canopies\n\nThe LAD conversion in the following code is a relative, normalized mapping of TLS pulse counts to LAD values, normalized by the highest voxel return and normalized using a fixed LAD_max. This gives a plausible LAD field usable for analysis, visualization, or simulation input (e.g.¬†for ENVI-met).\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\nconvert_matrix_to_df &lt;- function(mat) {  \n  df &lt;- as.data.frame(mat)  \n  colnames(df) &lt;- attr(mat, \"dimnames\")[[2]]  \n  return(df)\n}\n\n# --- Preprocess LiDAR data into voxel metrics -------------------------------\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  # Calculate vertical pulse metrics\nvox_df &lt;- convert_matrix_to_df(vox_out$df)                      # Convert voxel array to data.frame\n\n#' Convert TLS voxel pulse data to LAD using Beer‚ÄìLambert conversion conversion with post-normalization\n#'\n#' @param df A data.frame with pulse columns (from TLS voxelization)\n#' @param grainsize Numeric, vertical voxel height (e.g., 1 m)\n#' @param k Extinction coefficient (default: 0.3)\n#' @param scale_factor Optional multiplicative scale factor (default: 1.2)\n#' @param lad_max Optional maximum LAD clamp (e.g. 2.5); set to NULL to disable\n#' @param lad_min Optional minimum LAD threshold (e.g. 0.05); set to NULL to disable\n#' @param keep_pulses Logical, whether to retain pulse columns (default: FALSE)\n#'\n#' @return Data.frame with LAD columns added\n#' @export\nconvert_to_LAD_beer &lt;- function(df,\n                                grainsize = 1,\n                                k = 0.3,\n                                scale_factor = 1.2,\n                                lad_max = 2.5,\n                                lad_min = 0.05,\n                                keep_pulses = FALSE) {\n  df_lad &lt;- df\n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)\n  \n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))\n    p_rel &lt;- df_lad[[col]] / max(df_lad[[col]], na.rm = TRUE)\n    \n    # Avoid log(0) and 1\n    p_rel[p_rel &gt;= 1] &lt;- 0.9999\n    p_rel[p_rel &lt;= 0] &lt;- 1e-5\n    \n    # Apply Beer‚ÄìLambert conversion\n    lad_vals &lt;- -log(1 - p_rel) / (k * grainsize)\n    \n    # Apply normalization\n    lad_vals &lt;- lad_vals * scale_factor\n    \n    # Clamp LAD values if needed\n    if (!is.null(lad_max)) {\n      lad_vals &lt;- pmin(lad_vals, lad_max)\n    }\n    if (!is.null(lad_min)) {\n      lad_vals &lt;- pmax(lad_vals, lad_min)\n    }\n    \n    df_lad[[lad_col]] &lt;- lad_vals\n    \n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL\n    }\n  }\n  \n  return(df_lad)\n}\n\n\n#' Convert TLS Pulse Counts to Leaf Area Density (LAD)\n#'\n#' Transforms vertically binned pulse counts (from voxelized TLS data) into Leaf Area Density (LAD, m¬≤/m¬≥)\n#' by normalizing pulse values to a specified LAD maximum.\n#'\n#' @param df A `data.frame` containing voxelized TLS pulse data. Must include columns starting with `\"pulses_\"`, \n#'           each representing pulse returns per vertical layer (e.g. `pulses_1_2m`, `pulses_2_3m`, ...).\n#' @param grainsize Numeric. The voxel edge length in meters (assumed cubic). Default is `1`.\n#' @param LADmax Numeric. The maximum LAD value in m¬≤/m¬≥ for relative normalization. Common values: `4.0`‚Äì`6.0`. Default is `5.0`.\n#' @param keep_pulses Logical. If `FALSE` (default), the original pulse columns are removed from the output. If `TRUE`, they are retained alongside the LAD columns.\n#'\n#' @return A modified `data.frame` with new LAD columns (`lad_1_2m`, `lad_2_3m`, ...) in m¬≤/m¬≥, normalized relatively to `LADmax`.\n#'\n#' @details\n#' - Each `pulses_*` column is linearly normalized by the overall maximum value across all vertical bins and locations.\n#' - The result is a relative LAD estimate, useful for ecological modeling, input to microclimate simulations (e.g., ENVI-met), or structural analysis.\n#' - Voxel volume is implicitly considered constant due to cubic assumption (via `grainsize`) but is not explicitly used here.\n#'\n#' @examples\n#' \\dontrun{\n#'   df_vox &lt;- readRDS(\"TLS/voxel_metrics.rds\")\n#'   lad_df &lt;- convert_to_LAD(df_vox, grainsize = 1, LADmax = 5)\n#'   head(names(lad_df))  # Should show lad_* columns\n#' }\n#'\n#' @export\nconvert_to_LAD &lt;- function(df, grainsize = 1, LADmax = 5.0, keep_pulses = FALSE) {  \n  # df: Data frame mit voxelisierten TLS-Daten\n# grainsize: Voxelgr√∂√üe in m (w√ºrfelf√∂rmig angenommen)\n# LADmax: maximaler LAD-Wert (Literaturbasiert, z.‚ÄØB. 5.0 m¬≤/m¬≥)\n  df_lad &lt;- df  \n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)  \n  \n  # Schichtanzahl = Anzahl Pulse-Spalten\n  n_layers &lt;- length(pulse_cols)  \n  \n  # Optional: originales Maximum zur linearen Skalierung (relativ)\n  max_pulse &lt;- max(df_lad[, pulse_cols], na.rm = TRUE)  \n  \n  # Umwandlung in LAD (m¬≤/m¬≥) ‚Äì Skaliert auf LADmax oder absolut (siehe Kommentar)\n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))  \n    \n    # Hier wird RELATIV zu max_pulse skaliert ‚Üí einfache Normalisierung\n    df_lad[[lad_col]] &lt;- (df_lad[[col]] / max_pulse) * LADmax  \n    \n    # Optional: l√∂schen der Pulse-Spalten\n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL  \n    }\n  }\n  \n  return(df_lad)\n}\n\n\n\n# method selection\nif (lad_method == \"beer\") {\n  message(\"‚úî Using Beer‚ÄìLambert conversion LAD conversion...\")\n  df_lad &lt;- convert_to_LAD_beer(\n    vox_df,\n    grainsize = 1,\n    k = k_extinction,\n    scale_factor = 0.4,\n    lad_max = 2.5,\n    lad_min = 0.0\n  )\n} else if (lad_method == \"linear\") {\n  message(\"Using linear LAD conversion...\")\n  df_lad &lt;- convert_to_LAD(\n    vox_df,\n    grainsize = 1,\n    LADmax = 5.0\n  )\n} else {\n  stop(\"Unknown LAD conversion method: choose 'linear' or 'beer'\")\n}\n\n\n\n\n\nDT::datatable(head(df_lad, 5))\n\n\n\n\n\n\n\nRaster Stack Representation of 3D Vegetation (Voxel-Based)\nWe represent 3D vegetation using a voxel-based raster stack:\n\nSpace is divided into cubic voxels (e.g.¬†1‚ÄØ√ó‚ÄØ1‚ÄØ√ó‚ÄØ1‚ÄØm).\nEach raster layer represents a height slice (e.g.¬†0‚Äì1‚ÄØm, 1‚Äì2‚ÄØm, ‚Ä¶).\nVoxels store values like pulse counts or Leaf Area Density (LAD).\n\nThis 2D stack structure enables:\n\nVertical profiling of vegetation per XY column.\nLayer-wise analysis (e.g.¬†median, entropy).\nIntegration with raster data like topography or irradiance.\nUse in raster-based ecological and microclimate models.\n\nIt supports both analysis and visualization of vertical structure with standard geospatial tools.\nENVI-met supports custom vegetation input via the SimplePlant method, which requires a vertical LAD profile per grid column. A raster stack derived from TLS data provides exactly this: each layer represents LAD in a specific height slice, and each XY cell corresponds to one vertical profile. This structure can be exported as CSV, ASCII rasters, or custom profile files.\nFor 3D vegetation parameterization in ENVI-met 5.8+, the raster stack enables preprocessing of spatially explicit LAD or LAI profiles, even if some reformatting is needed.\nThe raster stack also supports canopy clustering and prototyping. It allows classification of structural types, simplification of complex vegetation, and the creation of representative profiles for simulation.\n\nlibrary(terra)\n# In SpatRasterStack umwandeln\nxy &lt;- df_lad[, c(\"X\", \"Y\")]  \nlad_vals &lt;- df_lad[, grep(\"^lad_\", names(df_lad), value = TRUE)]  \n\nlad_raster &lt;- rast(cbind(xy, lad_vals), type = \"xyz\")  \nplot(lad_raster)\n\n\n\n\n\n\n\n\nIn a more 3D version it looks like below.\n\n# #| eval: false\n# #| include: false\n# library(terra)\n# library(rgl)\n# \n# # Threshold value for LAD\n# threshold &lt;- 0.1 # change as needed\n# \n# # Step 1: Convert raster to voxel data frame\n# rast_cube &lt;- lad_raster  # your raster stack\n# voxel_df &lt;- as.data.frame(rast_cube, xy = TRUE, na.rm = TRUE)\n# names(voxel_df) &lt;- c(\"x\", \"y\", paste0(\"z\", seq_len(nlyr(rast_cube))))\n# \n# # Step 2: Reshape to long format\n# voxel_long &lt;- reshape(\n#   voxel_df,\n#   direction = \"long\",\n#   varying = paste0(\"z\", seq_len(nlyr(rast_cube))),\n#   v.names = \"val\",\n#   timevar = \"z\",\n#   times = seq_len(nlyr(rast_cube))\n# )\n# \n# # Step 3: Clean up and filter by threshold\n# voxel_long &lt;- voxel_long[!is.na(voxel_long$val) & voxel_long$val &gt; threshold, ]\n# voxel_long$z &lt;- as.numeric(voxel_long$z)\n# \n# # Step 4: Normalize colors\n# colors &lt;- terrain.colors(100)[cut(voxel_long$val, breaks = 100)]\n# \n# # Step 5: Draw voxel cubes\n# open3d(useNULL = TRUE)\n# for (i in seq_len(nrow(voxel_long))) {\n#   shade3d(\n#     translate3d(cube3d(scale = 1), \n#                 voxel_long$x[i], \n#                 voxel_long$y[i], \n#                 voxel_long$z[i]),\n#     color = colors[i],\n#     alpha = 0.8\n#   )\n# }\n# \n# # Step 6: Render in browser\n# # Determine the bounds of your voxel space\n# xlim &lt;- range(voxel_long$x)\n# ylim &lt;- range(voxel_long$y)\n# zlim &lt;- range(voxel_long$z)\n# \n# # Draw bounding box\n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[1], zlim[1])\n# ), col = \"black\", lwd = 2)\n# \n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[1], zlim[2])\n# ), col = \"black\", lwd = 2)\n# \n# for (i in 1:4) {\n#   lines3d(\n#     rbind(\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[1]),\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[2])\n#     ), col = \"black\", lwd = 2\n#   )\n# }\n# \n# # Optional: Add coordinate axes\n# axes3d(edges = c(\"x--\", \"y--\", \"z--\"), col = \"gray40\")\n# title3d(xlab = \"X\", ylab = \"Y\", zlab = \"Z\")\n# widget &lt;- rglwidget()\n# htmlwidgets::saveWidget(widget, \"tree_voxel_viewer.html\", selfcontained = TRUE)\n\n\n\nVisualization\n\nLAD Profile Visualizations from TLS Data\nThe plot_lad_profiles() function visualizes vertical leaf area density (LAD) profiles derived from voxelized TLS (terrestrial laser scanning) data. LAD represents leaf surface area per unit volume (m¬≤/m¬≥). The function provides three main plot styles:\n\n\n1. XY Matrix Plot (plotstyle = \"each_median\")\n\nDisplays a grid of mini-profiles, each representing a 0.5‚ÄØ√ó‚ÄØ0.5‚ÄØm (x/y) ground column.\nWithin each cell, a normalized vertical LAD profile is plotted:\n\nY-axis (height) is normalized from 0 to 1 per column.\nX-axis shows LAD values normalized relative to the global LAD maximum.\n\nUseful for comparing structural patterns across space.\n\n\n\n2. Overall Median Profile (plotstyle = \"all_median\")\n\nAggregates LAD values across all (x/y) locations by height bin.\nProduces a typical vertical profile using the median and smoothed with a moving average.\nHeight is shown in absolute units (e.g.¬†meters).\nCaptures the dominant vertical canopy structure.\n\n\n\n3. Single Profile (plotstyle = \"single_profile\")\n\nExtracts and plots the LAD profile at a specific (x, y) coordinate.\nBoth LAD and height are shown in absolute units.\nPlots the true vertical structure at one location.\n\nThe matrix plot shows multiple vertical LAD profiles arranged in a grid, with each small plot corresponding to a specific spatial location. This allows the vertical vegetation structure to be viewed in relation to its position on the ground. To make the individual profiles comparable, both height and LAD values are normalized within the plot. A reference profile on the side shows the overall median LAD distribution by height, which helps interpret the scale and shape of the individual profiles.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\n# --- Reshape LAD data to long format ----------------------------------------\n\nlad_df &lt;- as.data.frame(lad_raster, xy = TRUE, na.rm = TRUE)     # Convert raster to data.frame\n\n# 1. Extract LAD columns and XY coordinates\npulse_cols &lt;- grep(\"^lad_\", names(lad_df), value = TRUE)\nxy_cols &lt;- c(\"x\", \"y\")  # Adjust to \"X\", \"Y\" if needed\n\n# 2. Reshape to long format (one row per LAD layer)\nlad_df &lt;- reshape(\n  data = lad_df[, c(xy_cols, pulse_cols)],\n  varying = pulse_cols,\n  v.names = \"LAD\",\n  timevar = \"layer\",\n  times = pulse_cols,\n  direction = \"long\"\n)\n\n# 3. Extract z-layer information from column names\nlad_df$z_low  &lt;- as.numeric(sub(\"lad_(\\\\d+)_.*\", \"\\\\1\", lad_df$layer))  \nlad_df$z_high &lt;- as.numeric(sub(\"lad_\\\\d+_(\\\\d+)m\", \"\\\\1\", lad_df$layer))  \n\n# 4. Compute mid-point height of each voxel layer\nlad_df$Height &lt;- (lad_df$z_low + lad_df$z_high) / 2  \n\n# 5. Round to whole meters to create height classes\nlad_df$Height_bin &lt;- round(lad_df$Height)  \n\n# --- Aggregate median LAD per 0.5 √ó 0.5 m column ----------------------------\nsetDT(lad_df)  # Use data.table for efficient aggregation\n\nlad_by_column &lt;- lad_df[  \n  , .(LAD_median = median(LAD, na.rm = TRUE)), \n  by = .(x, y, Height_bin)\n]\n\n# Convert back to regular data.frame\nlad_df &lt;- as.data.frame(lad_by_column)\n\nplot_lad_profiles &lt;- function(lad_df, plotstyle = c(\"each_median\", \"all_median\", \"single_profile\"),  \n                              single_coords = c(NA, NA)) {\n  plotstyle &lt;- match.arg(plotstyle)  \n  \n  # Combine x and y coordinates into a unique column ID\n  lad_df$col_id &lt;- paste(lad_df$x, lad_df$y, sep = \"_\")  \n  x_levels &lt;- sort(unique(lad_df$x))  \n  y_levels &lt;- sort(unique(lad_df$y))  \n  # Convert x/y coordinates to factor variables for matrix layout\n  lad_df$x_f &lt;- factor(lad_df$x, levels = x_levels)  \n  lad_df$y_f &lt;- factor(lad_df$y, levels = y_levels)  \n  n_x &lt;- length(x_levels)  \n  n_y &lt;- length(y_levels)  \n  \n  # Determine the maximum LAD value for relative normalization\n  lad_max &lt;- max(lad_df$LAD_median, na.rm = TRUE)  \n  height_range &lt;- range(lad_df$Height_bin, na.rm = TRUE)  \n  dx &lt;- 0.8  \n  dy &lt;- 0.8  \n  \n  par(mar = c(5, 5, 4, 5), xpd = TRUE)\n  \n \n\n  \n  # Differentiate by plot type: all profiles, overall profile, or single profile\n  if (plotstyle == \"each_median\") {\n # Load PNG legend\nlegend_img &lt;- png::readPNG(\"output.png\")\n\n# Define aspect-preserving image placement\nimg_height_units &lt;- 20\nimg_width_units &lt;- img_height_units * dim(legend_img)[2] / dim(legend_img)[1]  # preserve ratio\n\n# Define position\nimg_x_left &lt;- n_x + 1.5\nimg_x_right &lt;- img_x_left + img_width_units\nimg_y_bottom &lt;- 0\nimg_y_top &lt;- img_y_bottom + img_height_units\n\n# Begin plot\nplot(NA, xlim = c(1, n_x + img_width_units + 4), ylim = c(1, n_y),\n     type = \"n\", axes = FALSE, xlab = \"\", ylab = \"\",\n     main = \"Vertical LAD Profiles in XY Matrix\", asp = 1.2)\n\n\n# Draw all LAD profiles\nfor (i in seq_along(x_levels)) {\n  for (j in seq_along(y_levels)) {\n    profile &lt;- subset(lad_df, x == x_levels[i] & y == y_levels[j])\n    if (nrow(profile) == 0) next\n    lad_scaled &lt;- profile$LAD_median / lad_max\n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)\n    lines(x = lad_scaled * dx + i,\n          y = height_scaled * dy + j,\n          col = \"darkgreen\", lwd = 1)\n  }\n}\n\n# Axis labels for ground position\naxis(1, at = 1:n_x, labels = round(x_levels, 1), las = 2)\naxis(2, at = 1:n_y, labels = round(y_levels, 1), las = 2)\n\n# Add the image\nrasterImage(legend_img,\n            xleft = img_x_left,\n            xright = img_x_right,\n            ybottom = img_y_bottom,\n            ytop = img_y_top)\n\n    \n  } else if (plotstyle == \"all_median\") {\n    unique_heights &lt;- sort(unique(lad_df$Height_bin))  \n    lad_median &lt;- numeric(length(unique_heights))  \n    for (i in seq_along(unique_heights)) {\n      h &lt;- unique_heights[i]  \n      lad_median[i] &lt;- median(lad_df$LAD[lad_df$Height_bin == h], na.rm = TRUE)  \n    }\n    lad_smooth &lt;- stats::filter(lad_median, rep(1/3, 3), sides = 2)  \n    \n    plot(\n      lad_smooth, unique_heights,\n      type = \"l\",\n      col = \"darkgreen\",\n      lwd = 2,\n      xlab = \"Leaf Area Density (m¬≤/m¬≥)\",\n      ylab = \"Height (m)\",\n      main = \"Vertical LAD Profile (smoothed)\",\n      xlim = c(0, max(lad_smooth, na.rm = TRUE)),\n      ylim = range(unique_heights)\n    )\n    \n    text(\n      x = as.numeric(lad_smooth),\n      y = unique_heights,\n      labels = round(as.numeric(lad_smooth), 1),\n      pos = 4,\n      cex = 0.7,\n      col = \"black\"\n    )\n    grid()\n    \n    \n  } else if (plotstyle == \"single_profile\") {\n    x_target &lt;- single_coords[1]  \n    y_target &lt;- single_coords[2]  \n    tol &lt;- 1e-6  \n    \n    profile &lt;- subset(lad_df, abs(x - x_target) &lt; tol & abs(y - y_target) &lt; tol)  \n    \n    if (nrow(profile) == 0) {\n      # Show warning if no profile exists for selected coordinates\n      warning(\"No data for the selected coordinates.\")\n      plot.new()\n      title(main = paste(\"No profile at\", x_target, \"/\", y_target))\n      return(invisible(NULL))\n    }\n    \n    # Normalize height and LAD\n    height_range &lt;- range(profile$Height_bin, na.rm = TRUE)  \n    # Determine the maximum LAD value for relative normalization\n    lad_max &lt;- max(profile$LAD_median, na.rm = TRUE)  \n    \n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)  \n    height_unscaled &lt;- profile$Height_bin\n    # Determine the maximum LAD value for relative normalization\n    lad_scaled &lt;- profile$LAD_median / lad_max  \n    \n    plot(\n      x = lad_scaled,\n      y = height_unscaled, #height_scaled,\n      type = \"l\",\n      lwd = 2,\n      col = \"darkgreen\",\n      xlab = \"LAD (normalized)\",\n      ylab = \"Height (m)\",\n      main = paste(\"Profile at\", x_target, \"/\", y_target)\n    )\n  }\n}\n# --- Visualize LAD profiles -------------------------------------------------\n\n\n\n\n\n# Option 1: Profile in each column\nplot_lad_profiles(lad_df, plotstyle = \"each_median\")\n\n\n\n\n\n\n\n# Option 2: Overall vertical LAD profile (median of all)\nplot_lad_profiles(lad_df, plotstyle = \"all_median\")\n\n\n\n\n\n\n\n# Option 3: Single profile at specified coordinates\nplot_lad_profiles(lad_df, plotstyle = \"single_profile\", single_coords = c(57.5, -94.5))",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#envi-met-3d-tree-export",
    "href": "doc/tls_v1_1.html#envi-met-3d-tree-export",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "ENVI-met 3D Tree Export",
    "text": "ENVI-met 3D Tree Export\nThe next section describes more detailed how the key input values in the R function export_lad_to_envimet3d() are computed, derived or selected, and provides the rationale for each. The function converts a voxel-based Leaf Area Density (LAD) profile, typically obtained from Terrestrial Laser Scanning (TLS) data, into a structured XML file compatible with ENVI-met‚Äôs 3D tree model (.pld or PLANT3D).\nGiven the sensitivity of ENVI-met simulations to tree morphology and LAD distribution, the function ensures that the spatial dimensions, vertical layering and LAD intensity values are all correctly represented. Some parameters are optional, but can be derived from the data if not explicitly set.\nThe table below details each argument of the function, including its purpose, how it is determined and its necessity.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nlad_df &lt;-lad_df[!is.na(lad_df$LAD_median), ]\nRemoves entries with missing LAD values\nEnsures only valid data is used in the LAD calculation and XML export\n\n\nlad_df$i &lt;-as.integer(factor(lad_df$x))\nConverts x-coordinates to integer voxel column indices (i)\nRequired for ENVI-met LAD matrix indexing\n\n\nlad_df$j &lt;-as.integer(factor(lad_df$y))\nConverts y-coordinates to integer voxel row indices (j)\nSame as above, for the y-direction\n\n\nz_map &lt;-setNames( ...)\nMaps unique height bins to sequential vertical indices (k)\nTranslates height levels into voxel layers compatible with ENVI-met\n\n\nlad_df$k &lt;-z_map[as.character(lad_df$Height_bin)]\nApplies the vertical index to the LAD data\nAligns LAD values with ENVI-met vertical layer system\n\n\nlad_df$lad_value &lt;-round(lad_df$LAD_median * scale_factor, 5)\nScales LAD values and rounds to 5 digits\nBrings LAD values to a usable range for ENVI-met and ensures precision\n\n\ndataI &lt;-max(lad_df$i)\nGets the number of horizontal grid cells in i-direction (width)\nRequired as matrix size input for ENVI-met\n\n\ndataJ &lt;-max(lad_df$j)\nGets the number of horizontal grid cells in j-direction (depth)\nRequired as matrix size input for ENVI-met\n\n\nzlayers &lt;-max(lad_df$k)\nGets the number of vertical layers\nSets the height resolution of the LAD matrix",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#automatic-grid-dimensions-transformation",
    "href": "doc/tls_v1_1.html#automatic-grid-dimensions-transformation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Automatic Grid Dimensions transformation",
    "text": "Automatic Grid Dimensions transformation\nCalculates the voxel grid dimensions in X, Y, and Z from the TLS-derived LAD profile.\nThe table below outlines how the core spatial and structural parameters of the tree model are computed from the input LAD_DF data frame. These derived values define the three-dimensional structure of the tree in terms of its horizontal extent, vertical layering and canopy dimensions.\nData I and data J represent the size of the voxel grid in the i and j dimensions, respectively, based on unique horizontal (x and y) and vertical (height bin) bins in the LAD profile.\n‚ÄòWidth‚Äô and ‚ÄòDepth‚Äô describe the physical spread of the tree crown, inferred from the voxel grid extent if not manually set.\nHeight is computed by multiplying the number of vertical layers (zlayers) by the voxel resolution (cellSize), providing the total modelled height of the canopy.\nThese computed values are essential for correctly normalization and locating the 3D LAD matrix within the ENVI-met simulation domain to ensure visual and physiological realism.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nWidth  &lt;- if (is.null(Width)) dataI else Width\nUses the number of i-cells if Width is not provided\nAutomatically estimates tree width from voxel spread in x-direction\n\n\nDepth  &lt;- if (is.null(Depth)) dataJ else Depth\nUses the number of j-cells if Depth is not provided\nAutomatically estimates tree depth from voxel spread in y-direction\n\n\nHeight &lt;- zlayers * cellsize\nConverts number of vertical layers to metric height using cellsize\nComputes physical tree height in meters for ENVI-met\n\n\n\n# 1. Remove NA values from the LAD column\nlad_df &lt;- lad_df[!is.na(lad_df$LAD_median), ]\n\n# 2. Create discrete i and j indices for the horizontal position\n# (converts x and y coordinates into consecutive index values)\nlad_df$i &lt;- as.integer(factor(lad_df$x))\nlad_df$j &lt;- as.integer(factor(lad_df$y))\n\n# 3. Assign each Height_bin (z direction) a consecutive layer ID k\n# (z_map assigns an index layer to each unique height)\nz_map &lt;- setNames(seq_along(sort(unique(lad_df$Height_bin))), sort(unique(lad_df$Height_bin)))\nlad_df$k &lt;- z_map[as.character(lad_df$Height_bin)]\n\n# 4. Scale LAD values, e.g. to get from 0.02 to more realistic values such as 0.5‚Äì1.5\nlad_df$lad_value &lt;- round(lad_df$LAD_median * scale_factor, 5)\n\n# 5. Calculate the maximum dimensions of the grid (for XML specifications)\ndataI &lt;- max(lad_df$i) # Width in cells (x-direction)\ndataJ &lt;- max(lad_df$j) # Depth in cells (y-direction)\nzlayers &lt;- max(lad_df$k) # Number of vertical layers (z-direction)",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#transmittance-and-albedo",
    "href": "doc/tls_v1_1.html#transmittance-and-albedo",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Transmittance and Albedo",
    "text": "Transmittance and Albedo\nAlbedo = 0.18\nTransmittance = 0.3\nAlbedo = 0.18: Albedo is the fraction of incoming solar radiation reflected by the canopy surface. For deciduous trees, values usually range between 0.15 and 0.20. 0.18 is a commonly used default for broadleaved species like Fagus sylvatica or Quercus robur in many ecological models (e.g., ENVI-met, MAESPA). It affects surface energy balance and radiation reflection in ENVI-met simulations.\nTransmittance = 0.3: Transmittance represents the proportion of shortwave radiation that passes through the canopy without being absorbed or reflected. Deciduous trees in full leaf have transmittance values between 0.1 and 0.4 depending on species and LAI. 0.3 reflects moderate canopy density, consistent with empirical observations for mid-summer crowns. It controls how much light reaches the ground and sub-canopy vegetation; affects microclimate and shading.\nBoth values can be adjusted to match field measurements or literature for specific species or leaf phenology. However you can use them as robust fallback defaults when exact species traits are unavailable.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#season-profile",
    "href": "doc/tls_v1_1.html#season-profile",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Season-Profile",
    "text": "Season-Profile\nDefines monthly LAD normalization.\nSeasonProfile = c(0.2, 0.2, 0.4, 0.7, 1.0, 1.0, 1.0, 0.8, 0.6, 0.3, 0.2, 0.2)\nThe SeasonProfile is a vector of 12 numeric values (one per month) weighting the relative Leaf Area Density (LAD) throughout the year. It models seasonal leaf development and senescence, controlling how much foliage is present in each month:\n\nValues range from 0.0 (no foliage) to 1.0 (full foliage).\nFor deciduous trees like Fagus sylvatica or Quercus robur, foliage develops in spring (April‚ÄìMay), peaks in summer (June‚ÄìAugust), and declines in autumn (September‚ÄìOctober).\n\nProfile Breakdown:\n\n\n\nMonths\nValue\nInterpretation\n\n\n\n\nJan‚ÄìFeb, Nov‚ÄìDec\n0.2\nDormant / leafless\n\n\nMarch\n0.4\nBudburst begins\n\n\nApril\n0.7\nLeaf expansion\n\n\nMay‚ÄìJuly\n1.0\nFull canopy\n\n\nAugust\n0.8\nLeaf maturity decline\n\n\nSeptember\n0.6\nSenescence onset\n\n\nOctober\n0.3\nStrong senescence\n\n\n\nThe SeasonProfile directly influences LAD in ENVI-met‚Äôs dynamic vegetation simulation ‚Äî affecting transpiration, shading, and energy balance across the simulation year. Adjusting this vector allows tailoring of phenology to site-specific or species-specific data.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#l-systembased-trees-in-envi-met-experimetal",
    "href": "doc/tls_v1_1.html#l-systembased-trees-in-envi-met-experimetal",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "L-SystemBased trees in ENVI-met (Experimetal)",
    "text": "L-SystemBased trees in ENVI-met (Experimetal)\nENVI-met optionally allows procedural generation of tree architecture using Lindenmayer Systems (L-Systems) ‚Äî a formal grammar originally used to simulate plant growth patterns. When L-SystemBased = 1, the geometry of the tree is not derived from a static LAD matrix alone, but supplemented or replaced by rule-based 3D branching structures which supplement or replace the matrix. This is independent of the LAD profile but may affect shading and visualisation in the Albero interface of ENVI-met.\nL-SystemBased = 1\nAxiom = \"F(2)V\\V\\\\V/////B\"\nIterationDepth = 3\n\nExplanation of Key Parameters\n\n\n\n\n\n\n\nParameter\nMeaning\n\n\n\n\nL-SystemBased\nIf 1, enables L-system generation (uses rules to grow plant structure)\n\n\nAxiom\nStarting string (‚Äúseed‚Äù) for the L-system; defines base growth\n\n\nIterationDepth\nHow many times to apply production rules; higher means more detail\n\n\nTermLString\nOptional: Final symbol to be drawn/rendered (e.g.¬†‚ÄúL‚Äù)\n\n\nApplyTermLString\nIf 1, interprets the TermLString; otherwise, renders entire string\n\n\n\n\n\nDefault Settings\n\n\n\nL-System Branching as implemented by default\n\n\n&lt;L-SystemBased&gt;1&lt;/L-SystemBased&gt;\n&lt;Axiom&gt;F(2)V\\V\\\\V/////B&lt;/Axiom&gt;\n&lt;IterationDepth&gt;3&lt;/IterationDepth&gt;\n&lt;TermLString&gt;L&lt;/TermLString&gt;\n&lt;ApplyTermLString&gt;1&lt;/ApplyTermLString&gt;\n\nF(2): Move forward with length 2 (main trunk)\nV\\\\V/////B: Branching pattern with rotations (backslashes and slashes encode rotation commands); B may denote a terminal leaf or bud\nIterationDepth = 3: The production rules (if defined) will be applied 3 times to this axiom, generating a fractal-like tree structure.\n\n\nNote: In ENVI-met, the actual grammar rules are hard-coded and not customizable in .pld ‚Äî only the axiom and iteration depth are user-defined. It is highly experimental and poorly documented\n\nUse L-SystemBased = 1 if:\n\nYou want visual structure added to otherwise sparse or low-resolution LAD matrices\nThe tree lacks realistic shape (for Albero visualization)\nUse L-SystemBased = 0 (default) if:\n\nYou already provide a dense voxel-based LAD (from TLS or similar)\nYou want strict control over the 3D structure via LAD profile only\n\n\n\n\nImport TLS-based .pld into ENVI-met via Albero Clipboard\nRequirements\n- ENVI-met 5.8+\n- .pld file (e.g.¬†oak_tls_envimet.pld)\n- Albero editor (via Leonardo)\nSteps\n1. Open Albero\n‚Üí Leonardo ‚Üí Database ‚Üí Plant Database\n2. Open Clipboard\n‚Üí Click Clipboard (top-right)\n3. Import .pld\n‚Üí Clipboard ‚Üí Import ‚Üí Load file\n4. Edit (optional)\n‚Üí Adjust LAD, albedo, transmittance, name, etc.\n5. Send to Library\n‚Üí Click ‚ÄúSend to Library‚Äù\n6. Use in ENVI-met\n‚Üí In Leonardo/Spaces assign plant to your 3D model\nNotes\n- .pld contains LAD(z) values (m¬≤/m¬≥)\n- Use Advanced Settings to fine-tune visualization\n- Custom plants stored in your personal Albero library",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#key-benefits",
    "href": "doc/tls_v1_1.html#key-benefits",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Key Benefits",
    "text": "Key Benefits\n\nEfficient and scalable: The method avoids destructive sampling by using TLS return counts as proxies for leaf density. This makes it suitable for large-scale or repeated surveys without the need for time-consuming ground calibration.\nCaptures structural patterns: Normalizing the LAD values retains the vertical and spatial structure of vegetation, enabling meaningful comparison of crown shape, canopy layering, and vegetation density across space or time.\nDirectly usable in ENVI-met: The output is structured as a raster stack with height-specific layers, aligning with the input requirements of ENVI-met‚Äôs SimplePlant or 3D vegetation modules. This enables seamless integration into microclimate simulations.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#limitations",
    "href": "doc/tls_v1_1.html#limitations",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Limitations",
    "text": "Limitations\n\nSimplified assumptions: The linear mapping of TLS returns to LAD assumes a proportional relationship, which simplifies the complex interaction between laser pulses and vegetation surfaces.\nScan geometry dependency: Occlusion, scan angle, and varying point densities can distort the return distribution, especially in dense or multi-layered vegetation.\nGeneric LAD normalization: The maximum LAD value used for normalization is taken from literature-based estimates rather than site-specific measurements, which can introduce bias in absolute LAD magnitudes.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#conclusion",
    "href": "doc/tls_v1_1.html#conclusion",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "Conclusion",
    "text": "Conclusion\nThis workflow offers a robust and accessible approach for analyzing vegetation structure and generating model-ready LAD profiles from TLS data. It is especially useful for relative comparisons and ecological modeling, but is not intended for absolute LAD quantification without additional calibration.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "doc/tls_v1_1.html#references",
    "href": "doc/tls_v1_1.html#references",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants.",
    "section": "References",
    "text": "References\n\nCalders et al.¬†(2015). Nondestructive biomass estimation via TLS. Methods Ecol Evol, 6:198‚Äì208.https://doi.org/10.1111/2041-210X.12301\nChen et al.¬†(2018): Estimation of LAI in open-canopy forests using TLS and path length models. Agric. For. Meteorol. 263, 323‚Äì333. https://doi.org/10.1016/j.agrformet.2018.09.006\nENVI-met PLANT3D specification: https://www.envi-met.net/documents/papers/overview30.pdf\nENVI-met Albero overview: https://envi-met.com/tutorials/albero-overview\nENVI-met KB ‚Äì Obtaining Leaf Area Density: https://envi-met.info/doku.php?id=kb:lad#obtaining_leaf_area_density_data\nENVI-met dbmanager documentation: https://envi-met.info/doku.php?id=apps:dbmanager:start\nENVI-met Vegetation Tutorial (YouTube): https://www.youtube.com/watch?v=KGRLnXAXZds\nFlynn et al.¬†(2023) ‚Äì TLS-based vegetation index estimation; compares methods and highlights complexities in Mediterranean forest. Biogeosciences, 20(13), 2769‚Äì2784. doi:10.5194/bg-20-2769-2023\nHosoi & Omasa (2006). Voxel-based 3D tree modeling. IEEE TGRS, 44(12), 3610‚Äì3618. https://doi.org/10.1109/TGRS.2006.881743\nPrusinkiewicz & Lindenmayer (1990). The Algorithmic Beauty of Plants. Springer. https://doi.org/10.1007/978-1-4613-8476-2\nOshio & Asawa (2016). Solar transmittance of urban trees. IEEE TGRS, 54(9), 5483‚Äì5492. https://doi.org/10.1109/TGRS.2016.2565699\nSimon, Sinsel & Bruse (2020). Fractal trees in ENVI-met. Forests, 11(8), 869. https://doi.org/10.3390/f11080869\nWilkes et al.¬†(2017). TLS acquisition strategies. Remote Sens Environ, 196, 140‚Äì153. https://doi.org/10.1016/j.rse.2017.04.030\nChen et al.¬†(2018). LAI from TLS. Agr Forest Meteorol, 263, 323‚Äì333. https://doi.org/10.1016/j.agrformet.2018.09.006\nYin et al.¬†(2019). Shading and thermal comfort. Sustainability, 11(5), 1355. https://doi.org/10.3390/su11051355\nZhang (2024). Green layouts in ENVI-met. Informatica, 48(23). https://doi.org/10.31449/inf.v48i23.6881 Certainly. Here‚Äôs the reference adapted to match your current compact style:",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants."
    ]
  },
  {
    "objectID": "base/faq.html",
    "href": "base/faq.html",
    "title": "Frequently asked Questions",
    "section": "",
    "text": "This is a senseless question to meet a meaningfull answer\n\n\n\n\n\n\n\n\n\nThis is a meaningful answer to a senseless question\n\n\n\n\n\n\n\n\n\nLearn More‚Ä¶\n\n\n\n\n\nThis is a even more meaningful answer to a senseless question"
  },
  {
    "objectID": "base/faq.html#make-sense-topic",
    "href": "base/faq.html#make-sense-topic",
    "title": "Frequently asked Questions",
    "section": "",
    "text": "This is a senseless question to meet a meaningfull answer\n\n\n\n\n\n\n\n\n\nThis is a meaningful answer to a senseless question\n\n\n\n\n\n\n\n\n\nLearn More‚Ä¶\n\n\n\n\n\nThis is a even more meaningful answer to a senseless question"
  },
  {
    "objectID": "templates/slides-template.html#section",
    "href": "templates/slides-template.html#section",
    "title": "YOUR TITLE",
    "section": "",
    "text": "This is a slide with a background image"
  },
  {
    "objectID": "templates/slides-template.html#bullets",
    "href": "templates/slides-template.html#bullets",
    "title": "YOUR TITLE",
    "section": "Bullets",
    "text": "Bullets\nRemove the incremental ::: bracketed div for plain lists\n\nthe quick\nbrown fox\njumps over\nthe lazy dog"
  },
  {
    "objectID": "templates/slides-template.html#columns",
    "href": "templates/slides-template.html#columns",
    "title": "YOUR TITLE",
    "section": "Columns",
    "text": "Columns\n\n\nSome text on the left of the slide\n\nSome text on the right of the slide"
  },
  {
    "objectID": "templates/slides-template.html#smaller-slide",
    "href": "templates/slides-template.html#smaller-slide",
    "title": "YOUR TITLE",
    "section": "Smaller Slide",
    "text": "Smaller Slide\nThe text on this slide will be, um, smaller."
  },
  {
    "objectID": "templates/slides-template.html#sneaky-info-asides-bootnotes",
    "href": "templates/slides-template.html#sneaky-info-asides-bootnotes",
    "title": "YOUR TITLE",
    "section": "Sneaky Info (Asides & Bootnotes)",
    "text": "Sneaky Info (Asides & Bootnotes)\nThis is cool! 1\nAdd reference-location: document to the YAML for end notes.\n\n\nI am at the bottom of the slide\nNo it is not"
  },
  {
    "objectID": "templates/slides-template.html#scrolly-slide",
    "href": "templates/slides-template.html#scrolly-slide",
    "title": "YOUR TITLE",
    "section": "Scrolly Slide",
    "text": "Scrolly Slide\nOverflowed content will be scrollable on this slide."
  },
  {
    "objectID": "templates/slides-template.html#bootnotes",
    "href": "templates/slides-template.html#bootnotes",
    "title": "YOUR TITLE",
    "section": "Bootnotes",
    "text": "Bootnotes"
  },
  {
    "objectID": "templates/slides-template.html#a-slide-with-a-plot",
    "href": "templates/slides-template.html#a-slide-with-a-plot",
    "title": "YOUR TITLE",
    "section": "A slide with a plot",
    "text": "A slide with a plot\n\n\n# ^^ could be fragment, slide, column, column-fragment\nggplot() +\n  geom_point(\n    data = mtcars,\n    aes(wt, mpg),\n    color = \"goldenrod\"\n  ) +\n  labs(\n    title = \"Some Dots\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nthe incredible talk about making sense scales"
  },
  {
    "objectID": "assessment/slidelist.html",
    "href": "assessment/slidelist.html",
    "title": "Assessments",
    "section": "",
    "text": "Basic Exercise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit, GitHub & Rstudio [DE]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit, GitHub & Rstudio [EN]\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "modeling/modeling-material.html",
    "href": "modeling/modeling-material.html",
    "title": "Data and Software",
    "section": "",
    "text": "Please find all Data Downloads at the Course Data Server Data folder for any file exchange and data related purposes."
  },
  {
    "objectID": "modeling/modeling-material.html#data-set-for-training-purposes",
    "href": "modeling/modeling-material.html#data-set-for-training-purposes",
    "title": "Data and Software",
    "section": "",
    "text": "Please find all Data Downloads at the Course Data Server Data folder for any file exchange and data related purposes."
  },
  {
    "objectID": "modeling/modeling-material.html#specific-modeling-software",
    "href": "modeling/modeling-material.html#specific-modeling-software",
    "title": "Data and Software",
    "section": "Specific modeling software",
    "text": "Specific modeling software\nPlease find all Downloads according to ENVI-met at the ENVI-met landing page"
  },
  {
    "objectID": "modeling/modeling-material.html#common-software",
    "href": "modeling/modeling-material.html#common-software",
    "title": "Data and Software",
    "section": "Common Software",
    "text": "Common Software\nShell ‚Äî any command line environment will do for the exercises. For Linux we recommend the bash shell. For Windows the Windows command line can be used.\n\nQGIS has become one of the most promising and most integrative open source GIS systems over the last years. Through the processing plugin, it additionally integrates modules from the other leading free GIS solutions. We will need it (if necessary) to prepare or manipulate some of the data.\n\nRegarding installation, for Ubuntu Linux, the Ubuntu GIS package is a good choice. For Windows, we strongly recommend installing everything via the OSGeo4W environment and not the standalone QGIS installation tool.\nFor most of the data pre and postprocessing, we will use the statistical scripting language R and we highly recommend the Rstudio integrated developing environment.\nPlease follow the instructions according to your operating system."
  },
  {
    "objectID": "modeling/modeling-material.html#additional-data-sources",
    "href": "modeling/modeling-material.html#additional-data-sources",
    "title": "Data and Software",
    "section": "Additional data sources",
    "text": "Additional data sources\nYou can find information about the ‚ÄúZukunftsquartier Hasenkopf‚Äù in various places:\n\nCity of Marburg Zukunftsquartier Hasenkopf\nSlides including the winning design\nCitizens‚Äô initiative wirsindhasenkopf Flyer and here ‚ÄúWe argue‚Äù\nEnvi-met Hasenkopf GIS and Modeldata\nDigital Elevation Model DEM and Digital Surface Model DSM files relevant for Marburg can be downloaded from the GDS website of the Hessian Administration for Land Management and Geoinformation\nFor downloading the OSM data it is recommended to use the OSMDownloader extension to QGIS. It simply provides the ability to draw a rectangle and download the complete and currently available OSM data to a file named hasenkopf.osm.\nIf the data has to be digitised manually, it is advisable to use an up-to-date aerial photograph from Bing or Google. These can be easily integrated via XYZ tiles\nThe planning data for the development and sealing were taken from page 23 of the presentation of the winning design via screenshot."
  }
]